---
title: NAACL 2022 - A Summarization of Summarization Papers.
updated: 2022-07-18
---


- [FactPEGASUS: Factuality-Aware Pre-training and Fine-tuning for Abstractive Summarization](https://aclanthology.org/2022.naacl-main.74)
  - **Problem**: Summarization models can generate factually incorrect information.
  - **Approach**: Propose to extend pretraining objective of PEGASUS with FactCC during the pseudo-summary selection process.

- [An Exploration of Post-Editing Effectiveness in Text Summarization](https://aclanthology.org/2022.naacl-main.35)
  - **Problem**: Human-machine hybrid approach for summarization is understudied.
  - **Approach**: By experiments with 72 people on two summarization datasets, they show that when a person doesn't know the domain, post-editing approach helps but otherwise not much.

- [TSTR: Too Short to Represent, Summarize with Details! Intro-Guided Extended Summary Generation](https://aclanthology.org/2022.naacl-main.25)
  - **Problem**: Abstract-long sumamries are not informative enough for documents like scholarly documents.
  - **Approach**: Propose a model which uses introduction text as pointer feature to the main text to select salient information.

- [What Makes a Good and Useful Summary? Incorporating Users in Automatic Summarization Research](https://aclanthology.org/2022.naacl-main.4)
  - **Problem**: We don't quite know that current direction of summarization research can actually help users.
  - **Approach**: Designed a survey, and collected answers from students, and propose some understudied aspects required by them.

- [Falsesum: Generating Document-level NLI Examples for Recognizing Factual Inconsistency in Summarization](https://aclanthology.org/2022.naacl-main.199)
  - **Problem**: Using NLI models to compare input document and hypothesis is not straighforward.
  - **Approach**: Propose a pipeline to generate pairs of documents and hypothesis to train NLI models for factual incosistency detection.

- [Exploring Neural Models for Query-Focused Summarization](https://aclanthology.org/2022.findings-naacl.109)
  - **Problem**: Contributions to query-focused summarization is increasing but there is no comprehensive study on models.
  - **Approach**: Systematic study on two approaches, two-stage extractive-abstract and end-to-end, and also the effectiveness of transfer learning, and two extensions.

- [Reference-free Summarization Evaluation via Semantic Correlation and Compression Ratio](https://aclanthology.org/2022.naacl-main.153)
  - **Problem**: Shannon score, by generate source document w/ or w/o summary as prompt, to computes information and compare to evaluate summaries but ignores saliency and token position.
  - **Approach**: Propose to extend Shannon score to compute the correlation of distributions w/ or w/o summary prompt to take saliency adn token position into account.

- []()
  - **Problem**: 
  - **Approach**: 

- []()
  - **Problem**: 
  - **Approach**: 

- []()
  - **Problem**: 
  - **Approach**: 

- []()
  - **Problem**: 
  - **Approach**: 

- []()
  - **Problem**: 
  - **Approach**: 

- []()
  - **Problem**: 
  - **Approach**: 

- []()
  - **Problem**: 
  - **Approach**: 

- []()
  - **Problem**: 
  - **Approach**: 

- []()
  - **Problem**: 
  - **Approach**: 

- []()
  - **Problem**: 
  - **Approach**: 

- []()
  - **Problem**: 
  - **Approach**: 

- []()
  - **Problem**: 
  - **Approach**: 

- []()
  - **Problem**: 
  - **Approach**: 

- []()
  - **Problem**: 
  - **Approach**: 

- []()
  - **Problem**: 
  - **Approach**: 
