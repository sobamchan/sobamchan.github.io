2020-10-01

- 朝 6 am 起きた
  - [Go] s3 の画像を取得して image.Image 型に変換する
  - を書くことにした．
  - 書ききった．
- ◉ テキストベースの bookmark

## buildit
redash からデータを取得し，commune ai の api を叩き，スプレッドシート展開をするのを docker 上で作る．
https://github.com/BuildItInc/core-report/issues/3184
- [x] make docker image
- [x] test scaffold
- [x] get posts
https://kwmt27.net/index.php/2013/10/13/how-to-convert-from-map-to-struct/
https://qiita.com/someone7140/items/06159652a000e08e06ec
https://qiita.com/nayuneko/items/2ec20ba69804e8bf7ca3
https://qiita.com/sh-tatsuno/items/0c32c01eaeaf2d726fdf

commune ai でのロジックをどうするか．
本番 api を叩くか，別に立てるか．
→ とりあえず staging 叩く

- [x] posts から数字のみのものを除外する．
- [x] cai staging に投げる, 英語のサンプルにしていたら，cai 側で入力データ 0 件になって 500 帰ってきた．


---


2020-10-02

- 朝は起きれなかった．目は覚めたが起き上がれなかった

## buildit
作りたい csv
post_id, value (text), score
https://qiita.com/katsumic/items/a7984afca2d4522f60ac


---


2020-10-05

午前中とかした
adapter modules に関しての説明を related work に対してみたが，ここで本当に良いか，コンテキストに合わせる，ってことから後からやる．

Multimodal Language Models as Multimodal Knowledge Bases?
の手法を書くことに着手しようとしたのだが，内容が煮詰まっていなくて始める事ができなかった．

noam chomsky の lex youtube 見始めた
動画録画し損ねたらしい，相当後悔しただろうな


---


2020-10-06
listin api 大体完成した．


---


2020-10-07

lex a day
mantra
  - 5y 越しのゴール
  - 今年のゴール
  - visualize the day
4h * 2 deepwork
4h * 1 shallow work
2h * 1 reading, paper and book
2h * 1 workout

今日は午前中 2h 集中して作業してみる
そのために最初にタスクの整理を丁寧にする

## proposal
新手法はたすのやめよう．

## buildit
- [x] y academia 投稿率変化の調査
  - 8 月末から開始のグループ，9 月末からシステム不調 → group id: 189
  - is_coach is false and viewable_report is false の user が 40 人
  - 結果として投稿率に影響があっていそうか調査．
  - form ごとの投稿率の遷移を出せばいいかな．
  - → 特に投稿率に問題は起きていなさそう

- [x] 各モジュールの動作確認
  - 各関数をみてちゃんと実装されていそうか
  - 既存の test 内容が reasonable か確認
- [x] 関数・実装の整理
  - ファイルとか命名とかがカオスっているので，その整理
- [x] 重要ステップでのエラーハンドリング
  - ちゃんと err を補足する実装
- [x] 実行可能なコマンドを用意する
  - http request based で関数を実行できるように最終的にすればいいかな
  - mux 使って request 受けれるようにして，api 叩かれたら非同期で main 関数実行できるようにする
  - 一回手元で実行して `token.json` を生成する必要がある．運用としてどうするか．
  - → CLI ベースで良い by tomita-san
- [x] commune.ai が定期的に s3 のファイル (/view_classification/) 以下を消しているのを修正．
  - https://github.com/BuildItInc/commune-ai-v2/pull/243/commits/fa9530ca13d19c05465b7a0a9f616c4cc18245ff

dropout prediction
- [x] 前の実験の結果を見てみる
  - 直前の投稿の，tfidf, svc + thread 開始からの経過時点
- [x] base となるデータの取得
  - (previous post -> bool) のフォーマットね
    - http://54.238.184.238/queries/434
    - http://54.238.184.238/queries/435
    - http://54.238.184.238/queries/477
    - [ ] これらに `group_form.starts_at` を付与する必要があるね．
  - csv で download して，repo に置いておく．
  - あと，`posts.csv`  が必要 → 実際の text データのために


---


2020-10-08

## buildit

- [x] データセットの構築, 20min
  - (thread posts: string, timedelta.days: int, has next post: bool)
  - のフォーマットに整形する関数 `data.build` の実装
  - 実行に時間がかかりすぎるようなら file cache する
- [x] feature の作成, 15min
  - (thread posts: string, timedelta.days: int) から特徴量ベクトルに変換する関数
  - text を tfidf に変換して，その末尾に days を append する．
- [x] train ロジックの実装, 15min
  - train, test split
  - train
  - score
  - ここは簡単なはず
- [x] undersampling
  - train label count:  [(False, 1339), (True, 317)]
  - test label count:  [(False, 335), (True, 79)]
  - 結構ムラがある
精度 50%．これは低い．


黒い羊
https://ja.stateofaiguides.com/20200914-future-of-nlp/


---


2020-10-09


## buildit
dropout prediction の精度が低いので向上
データを増やす方向
  - [x] 現状 1to2, 2to3 の thread しか利用していないので，それを 5to6 まで増やす．
  - [x] で実験 データ倍になった
- [x] classification report を出力する
  - → 別に精度向上せず，50%
特徴量の工夫
  - 形態素解析してなかったわ, tinysegmenter 使ってみた．結構早いみたい．
  - 現状 timedelta 使わない方が精度が良い．
  - [ ] 品詞しぼりこみする
model の工夫
- MLP 使う

cai, dropout prediction 実験．
いくつかの特徴量実装して試していた．

来週
mlp も試したい．
grid search 用のパラメータパターンとモデルクラスを返す関数を用意して，


---

2020-10-12

https://slideslive.com/38922547
管理職 あなたのやること チェスですか
形態論 意味論 比較言語学
https://ja.stateofaiguides.com/20200914-future-of-nlp/


---

2020-10-13

https://www.coursera.org/learn/human-language#about
https://www.coursera.org/learn/philosophy
https://www.coursera.org/learn/children-literacy#syllabus


---

2020-10-14

朝早く起きた時に何をやるのか．
毎回同じことをやるようにしておいた方が起きやすい気がする．
執筆かな

iphone 発表
12 と 12 mini サイズの違いだけなんだったら，mini 一択な気がする．
大画面が必要でない限り．
だが，自分は ipad 持っているし，ご時世的に外出しないので，se でいい．
自分は se にしてゆりなのを 12 -> pro にした方がカメラへの投資としていい気がする．

## buildit
dropout 予測の実験引き続き．
今日使ってうまくいかなかったら方針を再考する
murara 起承転結 に関しての相談があるかも

- debug
  - 精度がほぼ 1/2 はちょっと怪し
  - [x] kfold class を使うように実装の改変
  - [x] 入力の確認，前処理後，数値変換後
    - 単語数が少ない投稿もあり，その辺はだいぶ sparse なベクトルになっている．
  - train データでも 50% 程度しか出ないのは変
  - [ ] model pred を直接観測
- [x] mlp で gridsearch, cv
  - grid search 用のパラメータパターン: []dict とモデルクラスを返す関数
- [ ] timedelta を連結する, feature
- [x] sister embedding 利用, 20min
- [x] 日本語分類 repo をどっから取ってきて利用してみる, 30min
  - https://github.com/sobamchan/ja_classification_pytorch/tree/master/baseline RNN 実装，CPU で動くのか？
  - 変わらなかった


カスタムエラーはこうすれば簡単なのか
```go
func findLinks(url string) ([]string, error) {
...
    return nil, fmt.Errorf("my error message.")
...
}
```




---

2020-10-15

朝一発で起きれた．
ほぼぴったり7h 睡眠．寝る前に動画見ていたけど，夜中にあまり目も覚めず
サクッと起きてブログを進めれた．

[tmux の window の順番を変える](https://superuser.com/a/343574)
```
swap-window -t 0
```


## buildit
午前，あと少し実験
午後，うまくいけば実装，うまくいかなければ次の方針を考える

データを少なくしたらうまくいった
```python
train_texts = texts[:100]
train_labels = labels[:100]
test_texts = texts[-20:]
test_labels = labels[-20:]
```
結果は (train, test) → (0.97, 0.4)

完全にか学習しているが，少なくとも train で精度は出ている．
全データで cv やったときは，学習直後の train データでも半分の精度しか出なかった．
つまり，データからモデルまでのパイプラインに関してはちゃんと実装できていそう．
→ 実装に問題はない感じ．

train を 300 件に増やして，test は同じデータにしたところ，test: 65% まで出た．
400 件で 55%
500 で (0.888, 0.55)

データを増やしても精度が全然出ない．

考えられる原因としては，
- そもそも分類がテキスト特徴量だけでは可能ではない．
- データ量がテストデータのために一般化するためは不足している
- dropout 率がグループに強く依存しているとすると，データにノイズが載っている可能性が高い．
  - グループごとに継続率にばらつきがあって，人ごとではない場合，テキストから予測することは不可能
  - グループごとの投稿継続率を調べて，グループごとにばらつきがないか調査
  - 継続率が例外的に高い (or 低い) グループはデータから除外する，とかの対処がある．
  - が，これをしたときに完成したモデルに価値があるのか？
  - → グループとしての投稿率が"普通"な時に，dropout が少し予測できるモデル
  - になる．
  - むしろグループ単位で，投稿率が落ち込みそうなものを検出した方がいいのか？

考えられない原因としては，
- モデルがしょぼい．
  - train には fit しているので十分間に合っている．むしろでかい？
- 実装ミス．
  - train ではちゃんと学習できているし，test データの切り方によっては精度でる．

次の方針としては，
1. テキスト以外の特徴量を集めてくる
2. データを増やす
が考えられる．
が，2 に関しては時間が経ってより多くの投稿が集まるのを待つしかない．
ので，1 になるが，これをやると api としての独立性が薄くなる．
し，データを送信する core 側のロジックに負担をかけることになる．
複数 table からデータを集めて整形して
とか，segment から行動履歴を集めてきて，とかまで必要になる

この行動決定をする前に回答が必要な質問
- 思いっきり core に結合する形になるが，それでいいのか？
- 良いとしたら，どの特徴量までは現実的な形で client (core) 側で収集・整形できるのか？
- または，redash に直接接続する commune.ai 以外のサーバーを立てて，そこでロジックを吸収するのが良いのか？

とりあえず，有効そうな特徴量を上げるところから進めておくか
締め切り一週間前までの ga events 情報は使っていいことにするか？
- [ ] 考えられる特徴量をあげる
  - login history, 開始からの経過時間，(終了した threads n で正規化の必要あるね)
  - これまでの threads に対する投稿率
  - もらった / 書いたコメントの数
  - もらった / 発行したリアクションの数 
  - profile image を設定しているかどうか


m 社の資料確認

p 9
この評価基準だと人間ですら自由記述テキストから採点するのはむずそうだけど
時間軸に関してアノテーション時の方向性とは全然違う
自動化できそうな箇所
see に関してやったことに尽きるかな
評価基準の具体化 & アノテート


---


2020-10-16

起きれなさそうだったのだが，協力もありなんとか起きれた．
これは気合をも少し感が張れば習慣化されるのだろうか

博士課程ってのは学生数による相乗効果がある。すでに博士がいるラボじゃないと入りたくない。たくさんいればおもろい人たちなので入りたくなる。
