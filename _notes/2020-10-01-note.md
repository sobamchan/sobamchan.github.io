2020-10-01

- 朝 6 am 起きた
  - [Go] s3 の画像を取得して image.Image 型に変換する
  - を書くことにした．
  - 書ききった．
- ◉ テキストベースの bookmark

## buildit
redash からデータを取得し，commune ai の api を叩き，スプレッドシート展開をするのを docker 上で作る．
https://github.com/BuildItInc/core-report/issues/3184
- [x] make docker image
- [x] test scaffold
- [x] get posts
https://kwmt27.net/index.php/2013/10/13/how-to-convert-from-map-to-struct/
https://qiita.com/someone7140/items/06159652a000e08e06ec
https://qiita.com/nayuneko/items/2ec20ba69804e8bf7ca3
https://qiita.com/sh-tatsuno/items/0c32c01eaeaf2d726fdf

commune ai でのロジックをどうするか．
本番 api を叩くか，別に立てるか．
→ とりあえず staging 叩く

- [x] posts から数字のみのものを除外する．
- [x] cai staging に投げる, 英語のサンプルにしていたら，cai 側で入力データ 0 件になって 500 帰ってきた．


---


2020-10-02

- 朝は起きれなかった．目は覚めたが起き上がれなかった

## buildit
作りたい csv
post_id, value (text), score
https://qiita.com/katsumic/items/a7984afca2d4522f60ac


---


2020-10-05

午前中とかした
adapter modules に関しての説明を related work に対してみたが，ここで本当に良いか，コンテキストに合わせる，ってことから後からやる．

Multimodal Language Models as Multimodal Knowledge Bases?
の手法を書くことに着手しようとしたのだが，内容が煮詰まっていなくて始める事ができなかった．

noam chomsky の lex youtube 見始めた
動画録画し損ねたらしい，相当後悔しただろうな


---


2020-10-06
listin api 大体完成した．


---


2020-10-07

lex a day
mantra
  - 5y 越しのゴール
  - 今年のゴール
  - visualize the day
4h * 2 deepwork
4h * 1 shallow work
2h * 1 reading, paper and book
2h * 1 workout

今日は午前中 2h 集中して作業してみる
そのために最初にタスクの整理を丁寧にする

## proposal
新手法はたすのやめよう．

## buildit
- [x] y academia 投稿率変化の調査
  - 8 月末から開始のグループ，9 月末からシステム不調 → group id: 189
  - is_coach is false and viewable_report is false の user が 40 人
  - 結果として投稿率に影響があっていそうか調査．
  - form ごとの投稿率の遷移を出せばいいかな．
  - → 特に投稿率に問題は起きていなさそう

- [x] 各モジュールの動作確認
  - 各関数をみてちゃんと実装されていそうか
  - 既存の test 内容が reasonable か確認
- [x] 関数・実装の整理
  - ファイルとか命名とかがカオスっているので，その整理
- [x] 重要ステップでのエラーハンドリング
  - ちゃんと err を補足する実装
- [x] 実行可能なコマンドを用意する
  - http request based で関数を実行できるように最終的にすればいいかな
  - mux 使って request 受けれるようにして，api 叩かれたら非同期で main 関数実行できるようにする
  - 一回手元で実行して `token.json` を生成する必要がある．運用としてどうするか．
  - → CLI ベースで良い by tomita-san
- [x] commune.ai が定期的に s3 のファイル (/view_classification/) 以下を消しているのを修正．
  - https://github.com/BuildItInc/commune-ai-v2/pull/243/commits/fa9530ca13d19c05465b7a0a9f616c4cc18245ff

dropout prediction
- [x] 前の実験の結果を見てみる
  - 直前の投稿の，tfidf, svc + thread 開始からの経過時点
- [x] base となるデータの取得
  - (previous post -> bool) のフォーマットね
    - http://54.238.184.238/queries/434
    - http://54.238.184.238/queries/435
    - http://54.238.184.238/queries/477
    - [ ] これらに `group_form.starts_at` を付与する必要があるね．
  - csv で download して，repo に置いておく．
  - あと，`posts.csv`  が必要 → 実際の text データのために


---


2020-10-08

## buildit

- [x] データセットの構築, 20min
  - (thread posts: string, timedelta.days: int, has next post: bool)
  - のフォーマットに整形する関数 `data.build` の実装
  - 実行に時間がかかりすぎるようなら file cache する
- [x] feature の作成, 15min
  - (thread posts: string, timedelta.days: int) から特徴量ベクトルに変換する関数
  - text を tfidf に変換して，その末尾に days を append する．
- [x] train ロジックの実装, 15min
  - train, test split
  - train
  - score
  - ここは簡単なはず
- [x] undersampling
  - train label count:  [(False, 1339), (True, 317)]
  - test label count:  [(False, 335), (True, 79)]
  - 結構ムラがある
精度 50%．これは低い．


黒い羊
https://ja.stateofaiguides.com/20200914-future-of-nlp/


---


2020-10-09


## buildit
dropout prediction の精度が低いので向上
データを増やす方向
  - [x] 現状 1to2, 2to3 の thread しか利用していないので，それを 5to6 まで増やす．
  - [x] で実験 データ倍になった
- [x] classification report を出力する
  - → 別に精度向上せず，50%
特徴量の工夫
  - 形態素解析してなかったわ, tinysegmenter 使ってみた．結構早いみたい．
  - 現状 timedelta 使わない方が精度が良い．
  - [ ] 品詞しぼりこみする
model の工夫
- MLP 使う

cai, dropout prediction 実験．
いくつかの特徴量実装して試していた．

来週
mlp も試したい．
grid search 用のパラメータパターンとモデルクラスを返す関数を用意して，


---

2020-10-12

https://slideslive.com/38922547
管理職 あなたのやること チェスですか
形態論 意味論 比較言語学
https://ja.stateofaiguides.com/20200914-future-of-nlp/


---

2020-10-13

https://www.coursera.org/learn/human-language#about
https://www.coursera.org/learn/philosophy
https://www.coursera.org/learn/children-literacy#syllabus


---

2020-10-14

朝早く起きた時に何をやるのか．
毎回同じことをやるようにしておいた方が起きやすい気がする．
執筆かな

iphone 発表
12 と 12 mini サイズの違いだけなんだったら，mini 一択な気がする．
大画面が必要でない限り．
だが，自分は ipad 持っているし，ご時世的に外出しないので，se でいい．
自分は se にしてゆりなのを 12 -> pro にした方がカメラへの投資としていい気がする．

## buildit
dropout 予測の実験引き続き．
今日使ってうまくいかなかったら方針を再考する
murara 起承転結 に関しての相談があるかも

- debug
  - 精度がほぼ 1/2 はちょっと怪し
  - [x] kfold class を使うように実装の改変
  - [x] 入力の確認，前処理後，数値変換後
    - 単語数が少ない投稿もあり，その辺はだいぶ sparse なベクトルになっている．
  - train データでも 50% 程度しか出ないのは変
  - [ ] model pred を直接観測
- [x] mlp で gridsearch, cv
  - grid search 用のパラメータパターン: []dict とモデルクラスを返す関数
- [ ] timedelta を連結する, feature
- [x] sister embedding 利用, 20min
- [x] 日本語分類 repo をどっから取ってきて利用してみる, 30min
  - https://github.com/sobamchan/ja_classification_pytorch/tree/master/baseline RNN 実装，CPU で動くのか？
  - 変わらなかった


カスタムエラーはこうすれば簡単なのか
```go
func findLinks(url string) ([]string, error) {
...
    return nil, fmt.Errorf("my error message.")
...
}
```




---

2020-10-15

朝一発で起きれた．
ほぼぴったり7h 睡眠．寝る前に動画見ていたけど，夜中にあまり目も覚めず
サクッと起きてブログを進めれた．

[tmux の window の順番を変える](https://superuser.com/a/343574)
```
swap-window -t 0
```


## buildit
午前，あと少し実験
午後，うまくいけば実装，うまくいかなければ次の方針を考える

データを少なくしたらうまくいった
```python
train_texts = texts[:100]
train_labels = labels[:100]
test_texts = texts[-20:]
test_labels = labels[-20:]
```
結果は (train, test) → (0.97, 0.4)

完全にか学習しているが，少なくとも train で精度は出ている．
全データで cv やったときは，学習直後の train データでも半分の精度しか出なかった．
つまり，データからモデルまでのパイプラインに関してはちゃんと実装できていそう．
→ 実装に問題はない感じ．

train を 300 件に増やして，test は同じデータにしたところ，test: 65% まで出た．
400 件で 55%
500 で (0.888, 0.55)

データを増やしても精度が全然出ない．

考えられる原因としては，
- そもそも分類がテキスト特徴量だけでは可能ではない．
- データ量がテストデータのために一般化するためは不足している
- dropout 率がグループに強く依存しているとすると，データにノイズが載っている可能性が高い．
  - グループごとに継続率にばらつきがあって，人ごとではない場合，テキストから予測することは不可能
  - グループごとの投稿継続率を調べて，グループごとにばらつきがないか調査
  - 継続率が例外的に高い (or 低い) グループはデータから除外する，とかの対処がある．
  - が，これをしたときに完成したモデルに価値があるのか？
  - → グループとしての投稿率が"普通"な時に，dropout が少し予測できるモデル
  - になる．
  - むしろグループ単位で，投稿率が落ち込みそうなものを検出した方がいいのか？

考えられない原因としては，
- モデルがしょぼい．
  - train には fit しているので十分間に合っている．むしろでかい？
- 実装ミス．
  - train ではちゃんと学習できているし，test データの切り方によっては精度でる．

次の方針としては，
1. テキスト以外の特徴量を集めてくる
2. データを増やす
が考えられる．
が，2 に関しては時間が経ってより多くの投稿が集まるのを待つしかない．
ので，1 になるが，これをやると api としての独立性が薄くなる．
し，データを送信する core 側のロジックに負担をかけることになる．
複数 table からデータを集めて整形して
とか，segment から行動履歴を集めてきて，とかまで必要になる

この行動決定をする前に回答が必要な質問
- 思いっきり core に結合する形になるが，それでいいのか？
- 良いとしたら，どの特徴量までは現実的な形で client (core) 側で収集・整形できるのか？
- または，redash に直接接続する commune.ai 以外のサーバーを立てて，そこでロジックを吸収するのが良いのか？

とりあえず，有効そうな特徴量を上げるところから進めておくか
締め切り一週間前までの ga events 情報は使っていいことにするか？
- [ ] 考えられる特徴量をあげる
  - login history, 開始からの経過時間，(終了した threads n で正規化の必要あるね)
  - これまでの threads に対する投稿率
  - もらった / 書いたコメントの数
  - もらった / 発行したリアクションの数 
  - profile image を設定しているかどうか
  - 締め切り 1 週間前までのイベント履歴


m 社の資料確認

p 9
この評価基準だと人間ですら自由記述テキストから採点するのはむずそうだけど
時間軸に関してアノテーション時の方向性とは全然違う
自動化できそうな箇所
see に関してやったことに尽きるかな
評価基準の具体化 & アノテート


---


2020-10-16

起きれなさそうだったのだが，協力もありなんとか起きれた．
これは気合をも少し感が張れば習慣化されるのだろうか

博士課程ってのは学生数による相乗効果がある。
すでに博士がいるラボじゃないと入りたくない。たくさんいればおもろい人たちなので入りたくなる。

> いま提供してくれている価値に対して評価をして、それに見合った報酬を出す、という考え方です。会社は「社員に成長してほしい」と位置づけないほうがいいと思っているからです。無理やり目標を設定させて、それを達成させよう、という考え方は持っていません。誰もが成長するべきだ、と思った瞬間に窮屈になる。
https://diamond.jp/articles/-/251002?page=2
評価コストが高くなりそうな気がするがうまく機能すればストレスレスな優しいシステムになりそう．

> 人間がものごとの因果関係を推論できるのは、起こってもいない「反事実」を想像する力があるからだ
https://note.com/tuttlemori/n/n936bd9419b13
人が日常的に理解した気になっているんだけど本当はそんなことない因果関係ってどれくらいあるんだろう．
意外とたくさんありそうで怖い．
確信を持って因果関係が成り立っていると思える事象ってどれくらいんあるんだろう．
日常から少し考えてみるか．
自分の意思決定や思考に関しても，実は間違った因果を因果だと思っている，思いたいがため自分を偽っていることはたくさんありそうだな．
自分が博士に行きたい理由，行きたいと思った原因，を正直に考えることは少し怖いかもしれない．


buildit
dropout 予測をテキスト以外の情報を使ってやる時にどんな特徴量があるか上げる
また，それを実現するために現状のシステムではどんなデータ収集の操作が必要なのか

- [x] 特徴量あげる, 15min, https://github.com/BuildItInc/core-report/issues/2555#issuecomment-709681187
- [x] ↑ を実現するためのデータ収集プロセスをまとめる, 30min, 
- [x] tomita-san に相談するために issue 書く, 10min
相談のパスまではした．
meanwhile グループ単位での活性度遷移の調査するか？
- [ ] group 活性度予想の方針を決める on noteshelf
  - 参考: https://github.com/BuildItInc/core-report/issues/2927

dropout 予測が簡単にはうまくいかなそうな結果を受けて，今後の方針を考えていた．
グループごとに活性化度合いを推定する方向に向かい始めた．
どうすれば，hr とか研修会社が嬉しいか


---


2020-10-17

結論・理由・詳細
アベックラーメンとダブルラーメン


---


2020-10-19

ダウンを着て散歩したらあったかかった．

奨学金の書類を完成させる
先生から最悪返信がなくても提出できる状態にする．

毎日の小さな苦痛を取り除いたみることで生まれる生産性がある。
ダウンベストを買った。
寒くても快適に散歩ができる。

普通にエンターテイメントになり得る。
自然に囲まれた場所で毎日散歩すると風景が毎日変わっているので何時でも飽きることがないそれに朝起きてからニュースを見てから散歩開始することで、特に携帯とかがなくても考え事に集中できることが楽しい。


---

2020-10-20

- 奨学金書類スキャンしてポータル
- freeter の完成

夕方に goran から書類が来るはず．ドイツ時間 10am までにくれるらしい
英語の技術系の記事とか，自分が読んだやつに概要日本語をつけてニュースレター作ってみるか？

伊勢原自動車学校
0463-95-2130
スケジュールコース．火曜水曜土曜受講したらどれくらいで完了できるか → 
通常コースだったら火曜水曜はどれくらい混んでいるか

今混んでいて 12 月からじゃないと車が開かない


---


2020-10-21

- 奨学金 submission done
- 「書くのがしんどい」，読み終わった
- > なんとしてでも楽観的でいなければならない
  - https://practical-scheme.net/trans/early-j.html
  - 意味不明だけどかっこいいな
- spotify → youtube music (premium) に乗り換えると広告が消えるのか

buildit
グループ活性度予想の有用な落とし所・その達成の方針を考える
https://github.com/BuildItInc/core-report/issues/2555#issuecomment-713365644
↑ な感じで進めていく
明日: 欲しい最終出力を考える．
ex. 「あなたのグループは，良いグループと比較してリアクション数が 10 個ほど不足しています．参加者に利用するように働きかけましょう」


---


2020-10-22

kindle は積読を軽減する．本当に読み始めるまで買う必要がないから．読もうと思った時に読める．

buildit
グループ活性度分析器実験
- [x] どんな感じの最終出力だったら便利か，考える．
- [x] 出力できそうな情報を gh issue にリストアップ, 20min
- [ ] 良いグループの定義を考える, 20min 今日は wip
- [ ] 良いグループを探し始める，

午後は勉強会の用意, 2h

勉強会用意
グループ状況分析，問題の定義
使えそうな情報の整理


---

2020-10-23

スマホを持たなくても良い生活を構築する方法
LINE とかは諦めれるのだが，電話番号を持たないことのリスク
電話だけできるガラケーを持つ，という選択肢はあるが，一年に一回使うかどうかな端末を持つのも変．

[pandashでRedashのAPIが返す結果をPandasのDataFrameとして取得する](https://ariarijp.hatenablog.com/entry/introduction-to-pandash)
便利そうだが，[redash-dynamic-query](https://github.com/toritori0318/redash-dynamic-query) が動かない．
dqHJgKW87LPG520LlUIEVOKYn8urymxZc5eFbKJA

grant 通ったら acl 2021 に向けて実験始めていいかも
gh actions とかでテストの自動化したほうがいい
独自のメトリクスはテストを書く
spreadsheet とかで結果の一元管理できたほうがいい
先生との mtg を 1w で設定しておいて，それドリブンで進める


buildit

core 分析
「良いグループ」を定義して，その数値を sql，python を書いて取り出す．
- [x] 良いグループの定義を考える
  - HR, 管理者からの干渉があるグループをどう考えるか．
  - [ ] course を通しての post rate と最終 form の post rate (完走率) に関連があるか調べる
    - http://54.238.184.238/queries/416/source#796 group ごと投稿率, rate 1.5 とかある
    - [x] post rates by groups SQL を書く, 30min
  - [x] user id: 1236 (北垣さん) が関与しているグループと，そうでないグループに投稿率に大きな違いがあるか調べる．, 20min
    - 関与あり: 0.8967086834733893
    - 関与なし: 0.5765299771761689
  - → 北垣さんのグループも含めて，投稿率の高いグループを「良い」グループとする．
  - → 厳密には投稿率 0.9 以上のグループ (現時点で 14 / 80 グループ)
- [x] 良いグループを探し始める，
  - http://54.238.184.238/queries/488/source#877
  - 以下の group_id
    - 34 40 41 58 93 94 134 141 150 153 189 191 195 196
- [ ] 「良い」グループ平均値データの作成
  - どう作るか．個別で SQL 書く？ → python が必要な時に情報が散乱する

来週: 必要なデータの可視化をしていく


---


2020-10-26

- 寝るときに少しカーテンを開けておいて，朝日が入るようにしておくか
