2020-10-01

- 朝 6 am 起きた
  - [Go] s3 の画像を取得して image.Image 型に変換する
  - を書くことにした．
  - 書ききった．
- ◉ テキストベースの bookmark

## buildit
redash からデータを取得し，commune ai の api を叩き，スプレッドシート展開をするのを docker 上で作る．
https://github.com/BuildItInc/core-report/issues/3184
- [x] make docker image
- [x] test scaffold
- [x] get posts
https://kwmt27.net/index.php/2013/10/13/how-to-convert-from-map-to-struct/
https://qiita.com/someone7140/items/06159652a000e08e06ec
https://qiita.com/nayuneko/items/2ec20ba69804e8bf7ca3
https://qiita.com/sh-tatsuno/items/0c32c01eaeaf2d726fdf

commune ai でのロジックをどうするか．
本番 api を叩くか，別に立てるか．
→ とりあえず staging 叩く

- [x] posts から数字のみのものを除外する．
- [x] cai staging に投げる, 英語のサンプルにしていたら，cai 側で入力データ 0 件になって 500 帰ってきた．


---


2020-10-02

- 朝は起きれなかった．目は覚めたが起き上がれなかった

## buildit
作りたい csv
post_id, value (text), score
https://qiita.com/katsumic/items/a7984afca2d4522f60ac


---


2020-10-05

午前中とかした
adapter modules に関しての説明を related work に対してみたが，ここで本当に良いか，コンテキストに合わせる，ってことから後からやる．

Multimodal Language Models as Multimodal Knowledge Bases?
の手法を書くことに着手しようとしたのだが，内容が煮詰まっていなくて始める事ができなかった．

noam chomsky の lex youtube 見始めた
動画録画し損ねたらしい，相当後悔しただろうな


---


2020-10-06
listin api 大体完成した．


---


2020-10-07

lex a day
mantra
  - 5y 越しのゴール
  - 今年のゴール
  - visualize the day
4h * 2 deepwork
4h * 1 shallow work
2h * 1 reading, paper and book
2h * 1 workout

今日は午前中 2h 集中して作業してみる
そのために最初にタスクの整理を丁寧にする

## proposal
新手法はたすのやめよう．

## buildit
- [x] y academia 投稿率変化の調査
  - 8 月末から開始のグループ，9 月末からシステム不調 → group id: 189
  - is_coach is false and viewable_report is false の user が 40 人
  - 結果として投稿率に影響があっていそうか調査．
  - form ごとの投稿率の遷移を出せばいいかな．
  - → 特に投稿率に問題は起きていなさそう

- [x] 各モジュールの動作確認
  - 各関数をみてちゃんと実装されていそうか
  - 既存の test 内容が reasonable か確認
- [x] 関数・実装の整理
  - ファイルとか命名とかがカオスっているので，その整理
- [x] 重要ステップでのエラーハンドリング
  - ちゃんと err を補足する実装
- [x] 実行可能なコマンドを用意する
  - http request based で関数を実行できるように最終的にすればいいかな
  - mux 使って request 受けれるようにして，api 叩かれたら非同期で main 関数実行できるようにする
  - 一回手元で実行して `token.json` を生成する必要がある．運用としてどうするか．
  - → CLI ベースで良い by tomita-san
- [x] commune.ai が定期的に s3 のファイル (/view_classification/) 以下を消しているのを修正．
  - https://github.com/BuildItInc/commune-ai-v2/pull/243/commits/fa9530ca13d19c05465b7a0a9f616c4cc18245ff

dropout prediction
- [x] 前の実験の結果を見てみる
  - 直前の投稿の，tfidf, svc + thread 開始からの経過時点
- [x] base となるデータの取得
  - (previous post -> bool) のフォーマットね
    - http://54.238.184.238/queries/434
    - http://54.238.184.238/queries/435
    - http://54.238.184.238/queries/477
    - [ ] これらに `group_form.starts_at` を付与する必要があるね．
  - csv で download して，repo に置いておく．
  - あと，`posts.csv`  が必要 → 実際の text データのために


---


2020-10-08

## buildit

- [x] データセットの構築, 20min
  - (thread posts: string, timedelta.days: int, has next post: bool)
  - のフォーマットに整形する関数 `data.build` の実装
  - 実行に時間がかかりすぎるようなら file cache する
- [x] feature の作成, 15min
  - (thread posts: string, timedelta.days: int) から特徴量ベクトルに変換する関数
  - text を tfidf に変換して，その末尾に days を append する．
- [x] train ロジックの実装, 15min
  - train, test split
  - train
  - score
  - ここは簡単なはず
- [x] undersampling
  - train label count:  [(False, 1339), (True, 317)]
  - test label count:  [(False, 335), (True, 79)]
  - 結構ムラがある
精度 50%．これは低い．


黒い羊
https://ja.stateofaiguides.com/20200914-future-of-nlp/


---


2020-10-09


## buildit
dropout prediction の精度が低いので向上
データを増やす方向
  - [x] 現状 1to2, 2to3 の thread しか利用していないので，それを 5to6 まで増やす．
  - [x] で実験 データ倍になった
- [x] classification report を出力する
  - → 別に精度向上せず，50%
特徴量の工夫
  - 形態素解析してなかったわ, tinysegmenter 使ってみた．結構早いみたい．
  - 現状 timedelta 使わない方が精度が良い．
  - [ ] 品詞しぼりこみする
model の工夫
- MLP 使う

cai, dropout prediction 実験．
いくつかの特徴量実装して試していた．

来週
mlp も試したい．
grid search 用のパラメータパターンとモデルクラスを返す関数を用意して，


---

2020-10-12

https://slideslive.com/38922547
管理職 あなたのやること チェスですか
形態論 意味論 比較言語学
https://ja.stateofaiguides.com/20200914-future-of-nlp/


---

2020-10-13

https://www.coursera.org/learn/human-language#about
https://www.coursera.org/learn/philosophy
https://www.coursera.org/learn/children-literacy#syllabus


---

2020-10-14

朝早く起きた時に何をやるのか．
毎回同じことをやるようにしておいた方が起きやすい気がする．
執筆かな

iphone 発表
12 と 12 mini サイズの違いだけなんだったら，mini 一択な気がする．
大画面が必要でない限り．
だが，自分は ipad 持っているし，ご時世的に外出しないので，se でいい．
自分は se にしてゆりなのを 12 -> pro にした方がカメラへの投資としていい気がする．

## buildit
dropout 予測の実験引き続き．
今日使ってうまくいかなかったら方針を再考する
murara 起承転結 に関しての相談があるかも

- debug
  - 精度がほぼ 1/2 はちょっと怪し
  - [x] kfold class を使うように実装の改変
  - [x] 入力の確認，前処理後，数値変換後
    - 単語数が少ない投稿もあり，その辺はだいぶ sparse なベクトルになっている．
  - train データでも 50% 程度しか出ないのは変
  - [ ] model pred を直接観測
- [x] mlp で gridsearch, cv
  - grid search 用のパラメータパターン: []dict とモデルクラスを返す関数
- [ ] timedelta を連結する, feature
- [x] sister embedding 利用, 20min
- [x] 日本語分類 repo をどっから取ってきて利用してみる, 30min
  - https://github.com/sobamchan/ja_classification_pytorch/tree/master/baseline RNN 実装，CPU で動くのか？
  - 変わらなかった


カスタムエラーはこうすれば簡単なのか
```go
func findLinks(url string) ([]string, error) {
...
    return nil, fmt.Errorf("my error message.")
...
}```
