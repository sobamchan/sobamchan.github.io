

## 前年 proposal

### RQs

- UP models から欠落している commonsense knowledge を profile できるか
- 欠落している commonsense knowledge の中から，visual datasets に入っているものはないか
- visual datasets から UP models にどう inject できるか

### Methods

- CSK の taxonomies の作成，アノテーション
  - モデルが知識として持っていない情報を炙り出すことができる
- MMM, unpaired
- MMM w/ Visual UP model
- Image Caption Matching, ICM
- caption to object
- object relation learning
  - image は使わずに，(word a - relation - word b) の triplet から masked lm をやる

#### Components

- Textual/Visual UP model (eg, RoBERTa)
- Matching

### 役立ちそうな論文等

- Parameter-Efficient Transfer Learning for NLP.
  - 概要: 新しいタスクがどんどん，stream で来る．タスクごとに adapter module を差し替えるだけで，効率的に前の学習結果を忘れずに適応できる．
  - csr は他のタスクから知識を獲得する必要がある．→ タスクの形式は似ている？
    - adapter module は task specific なので，それと同時に UP model に追加で，cross-task な module を用意することで他タスクからの知識の transfer を狙う．
  - csr taxonomies を作成できれば，category ごとに adapter を用意することもできるのか．必要とされる知識が違うのだとしたら有効に働きそう．
  - adapter module を差し替えて，bert 自体は froze しているので，forgetting の問題は task 間で無い
    - これは他でも使えそう

- Common Sense or World Knowledge? Investigating Adapter-Based Knowledge Injection into Pretrained Transformers
  - 概要: CSK injection w/ conceptnet を adapter module を使って実現．efficient に forgetting を回避
    2 つの konwledge base から文を構成して，bert w/ adapters を作成．各種 csr タスクで評価した．
  - ConceptNet, OMCS には commonsense question instances を得ための知識は包含されていなかった．(解けるようにならなかった)
    - ならどこにあるの？
  - タスク / インスタンス によって，有効な adapters が異なる
    - 複数 adapters で予測して，ensemble (eg, 多数決) できそう -> AdapterFusion

- AdapterHub: A Framework for Adapting Transformers
  - hugginface の interface にのっとって，adapters を共有しやすい web app の提供．
  - proposal を書くにあたっての用語を探すには良い論文かも

- Masking as an Efficient Alternative to Finetuning for Pretrained Language Models
  - adapter module と似たことの違うアプローチ，finetune 時に pretrained model のパラメータを binary mask するように学習．
  - パラメーター量は抑えつつ，finetune ができる．
  - 必要なパラメーターは 1 で通して，関係ないものは 0 で消す．というマスクを finetuning ときに学習する

- Toward General Scene Graph: Integration of Visual Semantic Knowledge with Entity Synset Alignment
  - この論文というよりも "scene graph datasets" が便利そう
    - Visual Genome 200
    - Visually Relevant Relationship (VrR-VG)

- Temporal Common Sense Acquisition with Minimal Supervision
  - duration, frequency of events に関しての cs
  - これらに関しての mention を利用するモデルの提案

- AdapterFusion: Non-Destructive Task Composition for Transfer Learning
  - 概要: multi-task 用の adapter module を使った学習方法
    複数の adapter をタスクごとに学習し，それらをまとめて使えるように fusion

- BERT and PALs: Projected Attention Layers for Efficient Adaptation in Multi-Task Learning
  - AdapterFusion に似たもの．追加の parallel layer を transformer block に追加
  - BERT のパラメータも同時に更新する → より良い精度が出る．

- K-ADAPTER: Infusing Knowledge into Pre-Trained Models with Adapters
  - 最終的な目標が似ている．
  - 2 種類の knowledge を BERT は傷つけずに adapter を使って付与
  - adapters 間の連携はなし．が，同時利用はありそう

- SenseBERT: Driving Some Sense into BERT
  - bert に wordnet knowledge を注入
  - これは adapter ではなくて，sequential learning

- Intermediate-Task Transfer Learning with Pretrained Models for Natural Language Understanding: When and Why Does It Work?
  - いろんなパターンの sequential finetuning を試した．
  - 難しいとされている問題で finetuning してから target task に適応した方が良い結果になる．

- Knowledge Enhanced Contextual Word Representations (2019, Oct)
  - 文中に entity (span) を見つけたら，外部 KB embedding を足し込む

- Contextual Lensing of Universal Sentence Representations, (2020, Feb, Kiros)
  - 面白そうな雰囲気だがよくわからん．

- MAD-X: An Adapter-based Framework for Multi-task Cross-lingual Transfer
  - 構造的に新しいのは "invertible adapters"

- VisualCOMET: Reasoning about the Dynamic Context of a Still Image
  - 画像の現状・過去・未来に関する説明のついたデータセット

- ERNIE-ViL: Knowledge Enhanced Vision-Language Representations Through Scene Graph, (2020, Jul)
  - caption を scene graph に parse → 要素を mask → MLM
  - で，multi modal model の pretraining


### New Methodology

#### stacking adapter

- 目的
  - vision knowledge injection phase (p1), final finetuning phase (p2) それぞれで，catastrophic forgetting を回避する
- 概要
  - p1, p2 と段階的に，adapter modules (AM) を追加していく．
  - p1 でいくつか追加して，UP model は固定して，p1 を visual knowledge 用に最適化
  - p2 で新しくいくつか固定して，UP model & p1 adapter は固定して，downstream task 用に最適化
- memo
  - 元 proposal はどう inject するかの framework
    これは，inject する知識をどう保持するかのモデル提案
  - 段階的に AM を追加するのは，他の intermediate learning を行うモデルに適応することができる．

#### adapters ensembling

- 目的
  - knowledge base (提案学習 fw) ごとに adapters を学習してみたときに，問題インスタンスごとに有効な adapter が変わりそう
- 概要
  - この問題を吸収するために，推論時は複数 adapters で予測を立てて多数決をとる
- memo
  - これは AdapterFusion と同じか．
    - → AdapterFusion を Multimodal or CSK 向けにさらに改造する手法を考える．

#### [task] color term ranking evaluation

- 目的
  - 視覚情報を付与された UP models が本当に，視覚的な知識を保持しているか評価したい．
- 概要
  - MLM による色単語推定だと，BERT がそもそも強いの比較にならない．
  - 色の距離を推定してランキングするタスクだと，そのバイアスが入りずらそう．
  - 色の距離 (正解データ) は RGB から作成できる．
  - Up models は color term (eg, red) を受け取って，candidate terms (eg, pink, blue, purple) を類似度で sort

#### WIP, [probing] adapter-based ability probing


### idea note

- visual knowledge を knowledge graph 的に保持する方法はないか？
  - visual info に match する knowledge sub-graph を抽出して利用
- csqa の問題ごとに，visual genome の knowledge graph から情報抽出して，予測に利用する．
- 色単語 (blue, red, ...) をマスクして，MLM での予測ってうまくいくのだろうか？
  - 行かないとしたら，lxmert ではうまくいくのだろうか？
  - 他に視覚情報の必要な masking ってどうできるだろうか？ → あればデータセット構築できる
