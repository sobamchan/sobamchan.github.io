---
title: self-training秘密兵器にないうるか
updated: 2020-07-08
---

窓から見たら晴天だったので，カメラも携えて散歩に出てみたら実は雨が降っており断念した．
着替えたりマスクをしたりとしての中断だったのでプチショック．

昨日返事が来ないな，とか書いていた論文読み会の方からの返事が来て，slack に入れてもらった．

semi-supervised learning, self-learning に関して少しだけ調べた．
[有名人 ruder 氏のブログポスト](https://ruder.io/semi-supervised/)が非常によくまとまっている．

semi-supervised learning の内の 1 手法が self-learning / training というものだが，
少量の教師データで学習したモデルで，ラベルのついていないデータに対して予測を行い，confidence score が高いものはその値をそのまま教師ラベルとし，
学習データのプールに加え再度，モデルを学習，というイテレーションを繰り返す．

氏の投稿では，この手法では間違った予測があったとしたら，その傾向が amplify されてしまうという問題点が言及されていた．
これは非常に危険ではあるが，少量データを扱いたいタスクは現実にはたくさんあるし，この問題も dev data / test data を丁寧に用意して評価をきちんとできるようにしておけば，
危険な状態は回避できるように感じる．

最近のモデルをベースとして日本語の分類とかで実験している例が見つけれなかったので自分でそのうちやってみよう．
