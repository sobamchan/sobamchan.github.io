---
title: auto evaluation for mt
updated: 2019-02-05 11:52
---
今日は、前回の文生成関連の調査が一段落したので
自動翻訳の性能を自動的に評価するための手法に関して調査していた。

参考になったのはWMT 2018にmetrics taskってのがあって、
そこでshared taskとして同じ問題が扱われていたので
そこから文献を漁っていた。

自分が予想していたように、dialog systemで昔触ったみたいな
dual encoderdual encoderみたいなノリで人間の評価値を推定するのが
一般的な感じぽい。

なんか追加で実験できることがないか少しずつアイディアがあるので、
温めて行きたい。
