- [AligNART: Non-autoregressive Neural Machine Translation by Jointly Learning to Estimate Alignment and Translate](https://aclanthology.org/2021.emnlp-main.1)
  - Jongyoon Song, Sungwon Kim, Sungroh Yoon
  - **TLDR**: We propose a novel non-autoregressive neural machine translation model that leverages full alignment information to explicitly reduce the modality of the target distribution.

- [Zero-Shot Cross-Lingual Transfer of Neural Machine Translation with Multilingual Pretrained Encoders](https://aclanthology.org/2021.emnlp-main.2)
  - Guanhua Chen, Shuming Ma, Yun Chen, Li Dong, Dongdong Zhang, Jia Pan, Wenping Wang, Furu Wei
  - **TLDR**: We propose a novel multilingual cross-lingual transfer model for NMT, which significantly outperforms mBART on zero-shot cross-shot any-to-English test sets across 14 source languages.

- [ERNIE-M: Enhanced Multilingual Representation by Aligning Cross-lingual Semantics with Monolingual Corpora](https://aclanthology.org/2021.emnlp-main.3)
  - Xuan Ouyang, Shuohuan Wang, Chao Pang, Yu Sun, Hao Tian, Hua Wu, Haifeng Wang
  - **TLDR**: We propose Ernie-M, a new training method that encourages the model to align the representation of multiple languages with monolingual corpora, to overcome the constraint that the parallel corpus size places on the model performance.

- [Cross Attention Augmented Transducer Networks for Simultaneous Translation](https://aclanthology.org/2021.emnlp-main.4)
  - Dan Liu, Mengge Du, Xiaoxi Li, Ya Li, Enhong Chen
  - **TLDR**: We propose a novel architecture for simultaneous translation that optimizes the policy and translation models for speech-to-text translation.

- [Translating Headers of Tabular Data: A Pilot Study of Schema Translation](https://aclanthology.org/2021.emnlp-main.5)
  - Kunrui Zhu, Yan Gao, Jiaqi Guo, Jian-Guang Lou
  - **TLDR**: We propose a schema translation model augmented with schema context and a neural machine translation model for schema translation.

- [Towards Making the Most of Dialogue Characteristics for Neural Chat Translation](https://aclanthology.org/2021.emnlp-main.6)
  - Yunlong Liang, Chulun Zhou, Fandong Meng, Jinan Xu, Yufeng Chen, Jinsong Su, Jie Zhou
  - **TLDR**: We propose to promote the chat translation by introducing the modeling of dialogue characteristics into the NCT model.

- [Low-Resource Dialogue Summarization with Domain-Agnostic Multi-Source Pretraining](https://aclanthology.org/2021.emnlp-main.7)
  - Yicheng Zou, Bolin Zhu, Xingwu Hu, Tao Gui, Qi Zhang
  - **TLDR**: We propose a multi-source pretraining paradigm for dialogue summarization that leverages large-scale in-domain non-summary data to better leverage the external summary data.

- [Controllable Neural Dialogue Summarization with Personal Named Entity Planning](https://aclanthology.org/2021.emnlp-main.8)
  - Zhengyuan Liu, Nancy Chen
  - **TLDR**: We propose a controllable neural generation framework that can flexibly guide dialogue summarization with personal named entity planning.

- [Fine-grained Factual Consistency Assessment for Abstractive Summarization Models](https://aclanthology.org/2021.emnlp-main.9)
  - Sen Zhang, Jianwei Niu, Chuyuan Wei
  - **TLDR**: We propose a novel method for summarization models that uses inference to identify subtle clues to identify whether a model-generated summary is consistent with the original document.

- [Decision-Focused Summarization](https://aclanthology.org/2021.emnlp-main.10)
  - Chao-Chun Hsu, Chenhao Tan
  - **TLDR**: We propose a novel problem, decision-focused summarization, where the goal is to summarize relevant information for a decision.

- [Multiplex Graph Neural Network for Extractive Text Summarization](https://aclanthology.org/2021.emnlp-main.11)
  - Baoyu Jing, Zeyu You, Tao Yang, Wei Fan, Hanghang Tong
  - **TLDR**: We propose a novel Multiplex Graph Convolutional Network for extractive text summarization and a novel Multi-GraS model for extractively summarizing text.

- [A Thorough Evaluation of Task-Specific Pretraining for Summarization](https://aclanthology.org/2021.emnlp-main.12)
  - Sascha Rothe, Joshua Maynez, Shashi Narayan
  - **TLDR**: We compare three summarization specific pretraining objectives with the task agnostic corrupted span prediction pretraining in controlled study.

- [HETFORMER: Heterogeneous Transformer with Sparse Attention for Long-Text Extractive Summarization](https://aclanthology.org/2021.emnlp-main.13)
  - Ye Liu, Jianguo Zhang, Yao Wan, Congying Xia, Lifang He, Philip Yu
  - **TLDR**: We propose a Transformer-based pre-trained model for long-text extractive summarization that achieves state-of-the-art performance in Rouge F1 while using less memory and fewer parameters.

- [Unsupervised Keyphrase Extraction by Jointly Modeling Local and Global Context](https://aclanthology.org/2021.emnlp-main.14)
  - Xinnian Liang, Shuangzhi Wu, Mu Li, Zhoujun Li
  - **TLDR**: We propose a novel method for unsupervised keyphrase extraction using local and global context for unstructured keyphrase extractions.

- [Distantly Supervised Relation Extraction using Multi-Layer Revision Network and Confidence-based Multi-Instance Learning](https://aclanthology.org/2021.emnlp-main.15)
  - Xiangyu Lin, Tianyi Liu, Weijia Jia, Zhiguo Gong
  - **TLDR**: We propose a novel Multi-Layer Revision Network (MLRN) which alleviates the effects of word-level noise by emphasizing inner-sentence correlations before extracting relevant information within sentences.

- [Logic-level Evidence Retrieval and Graph-based Verification Network for Table-based Fact Verification](https://aclanthology.org/2021.emnlp-main.16)
  - Qi Shi, Yu Zhang, Qingyu Yin, Ting Liu
  - **TLDR**: We propose a novel evidence retrieval and reasoning framework for table-based fact verification task, which can help to detect spurious programs and prove the validity of the given statement.

- [A Partition Filter Network for Joint Entity and Relation Extraction](https://aclanthology.org/2021.emnlp-main.17)
  - Zhiheng Yan, Chong Zhang, Jinlan Fu, Qi Zhang, Zhongyu Wei
  - **TLDR**: We propose a partition filter network to model two-way interaction between tasks properly, where feature encoding is decomposed into two steps: partition and filter.

- [TEBNER: Domain Specific Named Entity Recognition with Type Expanded Boundary-aware Network](https://aclanthology.org/2021.emnlp-main.18)
  - Zheng Fang, Yanan Cao, Tai Li, Ruipeng Jia, Fang Fang, Yanmin Shang, Yuhai Lu
  - **TLDR**: We propose a novel dictionary extension method which extracts new entities through the type expanded model.

- [Beta Distribution Guided Aspect-aware Graph for Aspect Category Sentiment Analysis with Affective Knowledge](https://aclanthology.org/2021.emnlp-main.19)
  - Bin Liang, Hang Su, Rongdi Yin, Lin Gui, Min Yang, Qin Zhao, Xiaoqi Yu, Ruifeng Xu
  - **TLDR**: We propose a novel approach to construct graphs for leveraging the aspect-related contextual sentiment dependencies in ACSA based on external knowledge.

- [DILBERT: Customized Pre-Training for Domain Adaptation with Category Shift, with an Application to Aspect Extraction](https://aclanthology.org/2021.emnlp-main.20)
  - Entony Lekhtman, Yftah Ziser, Roi Reichart
  - **TLDR**: We present a novel domain invariant learning scheme for domain adaptation in the unsupervised domain adaptation setting.

- [Improving Multimodal fusion via Mutual Dependency Maximisation](https://aclanthology.org/2021.emnlp-main.21)
  - Pierre Colombo, Emile Chapuis, Matthieu Labeau, Chloé Clavel
  - **TLDR**: We propose a multimodal sentiment analysis system that combines different unimodal representations into a synthetic one.

- [Learning Implicit Sentiment in Aspect-based Sentiment Analysis with Supervised Contrastive Pre-Training](https://aclanthology.org/2021.emnlp-main.22)
  - Zhengyan Li, Yicheng Zou, Chong Zhang, Qi Zhang, Zhongyu Wei
  - **TLDR**: We propose a novel approach to learn implicit sentiment in reviews by aligning the representation of implicit sentiment expressions to those with the same sentiment label.

- [Progressive Self-Training with Discriminator for Aspect Term Extraction](https://aclanthology.org/2021.emnlp-main.23)
  - Qianlong Wang, Zhiyuan Wen, Qin Zhao, Min Yang, Ruifeng Xu
  - **TLDR**: We use progressive self-training to alleviate the noise in the pseudo-labels in the aspect term extraction pseudo-label.

- [Reinforced Counterfactual Data Augmentation for Dual Sentiment Classification](https://aclanthology.org/2021.emnlp-main.24)
  - Hao Chen, Rui Xia, Jianfei Yu
  - **TLDR**: We propose an end-to-end reinforcement learning framework for sentiment classification, which jointly performs counterfactual data generation and dual sentiment classification.

- [Idiosyncratic but not Arbitrary: Learning Idiolects in Online Registers Reveals Distinctive yet Consistent Individual Styles](https://aclanthology.org/2021.emnlp-main.25)
  - Jian Zhu, David Jurgens
  - **TLDR**: We propose a novel approach to studying idiolects through a massive cross-author comparison to identify and encode stylistic features.

- [Narrative Theory for Computational Narrative Understanding](https://aclanthology.org/2021.emnlp-main.26)
  - Andrew Piper, Richard Jean So, David Bamman
  - **TLDR**: We introduce the dominant theoretical frameworks for NLP and argue that linking computational work in NLP to theory opens up a range of new empirical questions that would both help advance our understanding of narrative and open up new practical applications.

- [(Mis)alignment Between Stance Expressed in Social Media Data and Public Opinion Surveys](https://aclanthology.org/2021.emnlp-main.27)
  - Kenneth Joseph, Sarah Shugars, Ryan Gallagher, Jon Green, Alexi Quintana Mathé, Zijian An, David Lazer
  - **TLDR**: We show that the accuracy of stance detection models is variable and that the data can be misleading.

- [How Does Counterfactually Augmented Data Impact Models for Social Computing Constructs?](https://aclanthology.org/2021.emnlp-main.28)
  - Indira Sen, Mattia Samory, Fabian Flöck, Claudia Wagner, Isabelle Augenstein
  - **TLDR**: We investigate the benefits of counterfactually augmented data for social NLP models by focusing on three social computing constructs — sentiment, sexism, and hate speech.

- [Latent Hatred: A Benchmark for Understanding Implicit Hate Speech](https://aclanthology.org/2021.emnlp-main.29)
  - Mai ElSherief, Caleb Ziems, David Muchlinski, Vaishnavi Anupindi, Jordyn Seybolt, Munmun De Choudhury, Diyi Yang
  - **TLDR**: We present a theoretically-justified taxonomy of implicit hate speech and a benchmark corpus with fine-grained labels for each message and its implication.

- [Distilling Linguistic Context for Language Model Compression](https://aclanthology.org/2021.emnlp-main.30)
  - Geondo Park, Gyeongman Kim, Eunho Yang
  - **TLDR**: We present a new knowledge distillation objective for language representation learning that transfers the contextual knowledge via two types of relationships across representations: Word Relation and Layer Transforming Relation.

- [Dynamic Knowledge Distillation for Pre-trained Language Models](https://aclanthology.org/2021.emnlp-main.31)
  - Lei Li, Yankai Lin, Shuhuai Ren, Peng Li, Jie Zhou, Xu Sun
  - **TLDR**: We explore the dynamical adjustments on three aspects of knowledge distillation that can boost the student performance and learning efficiency.

- [Few-Shot Text Generation with Natural Language Instructions](https://aclanthology.org/2021.emnlp-main.32)
  - Timo Schick, Hinrich Schütze
  - **TLDR**: We present a novel method for text generation that combines textual instructions with example-based learning for text classification tasks.

- [SOM-NCSCM : An Efficient Neural Chinese Sentence Compression Model Enhanced with Self-Organizing Map](https://aclanthology.org/2021.emnlp-main.33)
  - Kangli Zi, Shi Wang, Yu Liu, Jicun Li, Yanan Cao, Cungen Cao
  - **TLDR**: We propose a neural Chinese sentence compression model enhanced with a Self-Organizing Map (SOM-NCSCM), to gain a valuable insight from the data and improve the performance of the whole neural Chinese SC model in a valid manner.

- [Efficient Multi-Task Auxiliary Learning: Selecting Auxiliary Data by Feature Similarity](https://aclanthology.org/2021.emnlp-main.34)
  - Po-Nien Kung, Sheng-Siang Yin, Yi-Cheng Chen, Tse-Hsuan Yang, Yun-Nung Chen
  - **TLDR**: We propose a time-efficient sampling method for multi-task auxiliary learning that outperforms random sampling and ST-DNN on three benchmark datasets.

- [GOLD: Improving Out-of-Scope Detection in Dialogues using Data Augmentation](https://aclanthology.org/2021.emnlp-main.35)
  - Derek Chen, Zhou Yu
  - **TLDR**: We propose GOLD, a novel method for training OOS detectors that outperforms all existing methods on all key metrics.

- [Graph Based Network with Contextualized Representations of Turns in Dialogue](https://aclanthology.org/2021.emnlp-main.36)
  - Bongseok Lee, Yong Suk Choi
  - **TLDR**: We propose a novel approach to dialogue-based relation extraction based on the way people understand dialogues.

- [Automatically Exposing Problems with Neural Dialog Models](https://aclanthology.org/2021.emnlp-main.37)
  - Dian Yu, Kenji Sagae
  - **TLDR**: We propose two methods including reinforcement learning to automatically trigger a dialog model into generating problematic responses.

- [Event Coreference Data (Almost) for Free: Mining Hyperlinks from Online News](https://aclanthology.org/2021.emnlp-main.38)
  - Michael Bugert, Iryna Gurevych
  - **TLDR**: We automatically extract event coreference data from hyperlinks in online news and show that models trained on small subsets of HyperCoref are highly competitive, with performance similar to models trained in gold-standard data.

- [Inducing Stereotypical Character Roles from Plot Structure](https://aclanthology.org/2021.emnlp-main.39)
  - Labiba Jahan, Rahul Mittal, Mark Finlayson
  - **TLDR**: We present a fully unsupervised k-means clustering approach for learning stereotypical roles given only structural plot information.

- [Multitask Semi-Supervised Learning for Class-Imbalanced Discourse Classification](https://aclanthology.org/2021.emnlp-main.40)
  - Alexander Spangher, Jonathan May, Sz-Rung Shiang, Lingjia Deng
  - **TLDR**: We show that a multitask learning approach can combine discourse datasets from similar and diverse domains to improve discourse classification.

- [Low Frequency Names Exhibit Bias and Overfitting in Contextualizing Language Models](https://aclanthology.org/2021.emnlp-main.41)
  - Robert Wolfe, Aylin Caliskan
  - **TLDR**: We use a dataset of U.S. first names with labels based on predominant gender and racial group to examine the effect of training corpus frequency on tokenization, contextualization, similarity to initial representation, and bias in BERT, GPT-2, T5, and XLNet.

- [Mitigating Language-Dependent Ethnic Bias in BERT](https://aclanthology.org/2021.emnlp-main.42)
  - Jaimeen Ahn, Alice Oh
  - **TLDR**: We propose two methods for mitigating ethnic bias in monolingual BERT for English, German, Spanish, Korean, Korean and Chinese.

- [Adversarial Scrubbing of Demographic Information for Text Classification](https://aclanthology.org/2021.emnlp-main.43)
  - Somnath Basu Roy Chowdhury, Sayan Ghosh, Yiyuan Li, Junier Oliva, Shashank Srivastava, Snigdha Chaturvedi
  - **TLDR**: We present an adversarial learning framework to debias contextual representations and learn fair representations while maintaining performance on the target task.

- [Open-domain clarification question generation without question examples](https://aclanthology.org/2021.emnlp-main.44)
  - Julia White, Gabriel Poesia, Robert Hawkins, Dorsa Sadigh, Noah Goodman
  - **TLDR**: We propose a visually grounded question-asking model capable of producing polar (yes-no) clarification questions to resolve misunderstandings in dialogue.

- [Improving Sequence-to-Sequence Pre-training via Sequence Span Rewriting](https://aclanthology.org/2021.emnlp-main.45)
  - Wangchunshu Zhou, Tao Ge, Canwen Xu, Ke Xu, Furu Wei
  - **TLDR**: In this paper, we propose 

- [Coarse2Fine: Fine-grained Text Classification on Coarsely-grained Annotated Data](https://aclanthology.org/2021.emnlp-main.46)
  - Dheeraj Mekala, Varun Gangal, Jingbo Shang
  - **TLDR**: We propose a novel text classification problem that uses generative models to perform fine-grained classification on coarsely annotated data.

- [Text2Mol: Cross-Modal Molecule Retrieval with Natural Language Queries](https://aclanthology.org/2021.emnlp-main.47)
  - Carl Edwards, ChengXiang Zhai, Heng Ji
  - **TLDR**: We propose a new task, Text2Mol, to retrieve molecules using natural language descriptions as queries.

- [Classification of hierarchical text using geometric deep learning: the case of clinical trials corpus](https://aclanthology.org/2021.emnlp-main.48)
  - Sohrab Ferdowsi, Nikolay Borissov, Julien Knafou, Poorya Amini, Douglas Teodoro
  - **TLDR**: We propose a novel graph neural network that can learn to classify clinical trial protocols into completed and terminated categories.

- [The Devil is in the Detail: Simple Tricks Improve Systematic Generalization of Transformers](https://aclanthology.org/2021.emnlp-main.49)
  - Róbert Csordás, Kazuki Irie, Juergen Schmidhuber
  - **TLDR**: We show that by revisiting model configurations as basic as scaling of embeddings, early stopping, relative positional embedding, and Universal Transformer variants, we can drastically improve the performance of Transformers on systematic generalization.

- [Artificial Text Detection via Examining the Topology of Attention Maps](https://aclanthology.org/2021.emnlp-main.50)
  - Laida Kushnareva, Daniil Cherniavskii, Vladislav Mikhailov, Ekaterina Artemova, Serguei Barannikov, Alexander Bernstein, Irina Piontkovskaya, Dmitri Piontkovski, Evgeny Burnaev
  - **TLDR**: We propose three novel types of interpretable topological features for text detection based on Topological Data Analysis (TDA) which are most robust towards unseen GPT-style generation models as opposed to existing methods.

- [Active Learning by Acquiring Contrastive Examples](https://aclanthology.org/2021.emnlp-main.51)
  - Katerina Margatina, Giorgos Vernikos, Loïc Barrault, Nikolaos Aletras
  - **TLDR**: We propose a novel active learning acquisition function that uses contrastive examples to select difficult and diverse data points from the pool of unlabeled data, and show that it outperforms the best performing baseline across all tasks and datasets.

- [Conditional Poisson Stochastic Beams](https://aclanthology.org/2021.emnlp-main.52)
  - Clara Meister, Afra Amini, Tim Vieira, Ryan Cotterell
  - **TLDR**: We propose a new method for beam search that uses conditional sampling to generate efficient estimators and sample diverse sets from sequence models.

- [Building Adaptive Acceptability Classifiers for Neural NLG](https://aclanthology.org/2021.emnlp-main.53)
  - Soumya Batra, Shashank Jain, Peyman Heidari, Ankit Arun, Catharine Youngs, Xintong Li, Pinar Donmez, Shawn Mei, Shiunzu Kuo, Vikas Bhardwaj, Anuj Kumar, Michael White
  - **TLDR**: We propose a novel framework to train models to classify acceptability of responses generated by natural language generation (NLG) models, improving upon existing sentence transformation and model-based approaches.

- [Moral Stories: Situated Reasoning about Norms, Intents, Actions, and their Consequences](https://aclanthology.org/2021.emnlp-main.54)
  - Denis Emelin, Ronan Le Bras, Jena D. Hwang, Maxwell Forbes, Yejin Choi
  - **TLDR**: We investigate whether language generation models can serve as behavioral priors for systems deployed in social settings, and propose decoding strategies that combine multiple expert models to significantly improve the quality of generated actions, consequences, and norms compared to strong baselines.

- [Truth-Conditional Captions for Time Series Data](https://aclanthology.org/2021.emnlp-main.55)
  - Harsh Jhamtani, Taylor Berg-Kirkpatrick
  - **TLDR**: We propose a computational model for automatically generating natural language descriptions of salient patterns in a time series, such as stock prices of a company over a week.

- [Injecting Entity Types into Entity-Guided Text Generation](https://aclanthology.org/2021.emnlp-main.56)
  - Xiangyu Dong, Wenhao Yu, Chenguang Zhu, Meng Jiang
  - **TLDR**: We propose a novel neural generation model that injects entity types into the neural generation process to generate contextual words accurately.

- [Smelting Gold and Silver for Improved Multilingual AMR-to-Text Generation](https://aclanthology.org/2021.emnlp-main.57)
  - Leonardo F. R. Ribeiro, Jonas Pfeiffer, Yue Zhang, Iryna Gurevych
  - **TLDR**: We investigate different techniques for automatically generating multilingual AMR-to-text annotations, where we aim to study which source of information yields better multilingual results.

- [Learning Compact Metrics for MT](https://aclanthology.org/2021.emnlp-main.58)
  - Amy Pu, Hyung Won Chung, Ankur Parikh, Sebastian Gehrmann, Thibault Sellam
  - **TLDR**: We show that large multilingual language models are inefficient for cross-lingual transfer and show how distillation can help address this bottleneck.

- [The Impact of Positional Encodings on Multilingual Compression](https://aclanthology.org/2021.emnlp-main.59)
  - Vinit Ravishankar, Anders Søgaard
  - **TLDR**: We show that while positional encodings in transformer architectures are useful for monolingual language models, they are not useful for multilingual models.

- [Disentangling Representations of Text by Masking Transformers](https://aclanthology.org/2021.emnlp-main.60)
  - Xiongyi Zhang, Jan-Willem van de Meent, Byron Wallace
  - **TLDR**: We learn binary masks over transformer weights or hidden units to uncover subsets of features that correlate with a specific factor of variation in BERT.

- [Exploring the Role of BERT Token Representations to Explain Sentence Probing Results](https://aclanthology.org/2021.emnlp-main.61)
  - Hosein Mohebbi, Ali Modarressi, Mohammad Taher Pilehvar
  - **TLDR**: We provide a more in-depth analysis on the representation space of BERT in search for distinct and meaningful subspaces that can explain the reasons behind these probing results.

- [Do Long-Range Language Models Actually Use Long-Range Context?](https://aclanthology.org/2021.emnlp-main.62)
  - Simeng Sun, Kalpesh Krishna, Andrew Mattarella-Micke, Mohit Iyyer
  - **TLDR**: We provide a fine-grained analysis of two long-range Transformer language models that can process long-sequence input sequences and show that providing long-term context to these models only improves their predictions on a small set of tokens.

- [The World of an Octopus: How Reporting Bias Influences a Language Model’s Perception of Color](https://aclanthology.org/2021.emnlp-main.63)
  - Cory Paik, Stéphane Aroca-Ouellette, Alessandro Roncone, Katharina Kann
  - **TLDR**: We show that reporting bias is one of the causes of text-only pretraining, and show that multimodal training can mitigate this issue.

- [SELFEXPLAIN: A Self-Explaining Architecture for Neural Text Classifiers](https://aclanthology.org/2021.emnlp-main.64)
  - Dheeraj Rajagopal, Vidhisha Balachandran, Eduard H Hovy, Yulia Tsvetkov
  - **TLDR**: We introduce SelfExplain, a novel self-explaining model that explains a text classifier’s predictions using phrase-based concepts.

- [Memory and Knowledge Augmented Language Models for Inferring Salience in Long-Form Stories](https://aclanthology.org/2021.emnlp-main.65)
  - David Wilmot, Frank Keller
  - **TLDR**: We improve the standard transformer language model by incorporating an external knowledgebase (derived from Retrieval Augmented Generation) and adding a memory mechanism to enhance performance on longer works.

- [Semantic Novelty Detection in Natural Language Descriptions](https://aclanthology.org/2021.emnlp-main.66)
  - Nianzu Ma, Alexander Politowicz, Sahisnu Mazumder, Jiahua Chen, Bing Liu, Eric Robertson, Scott Grigsby
  - **TLDR**: We propose a novel semantic novelty detection algorithm that outperforms 11 baselines by large margins.

- [Jump-Starting Item Parameters for Adaptive Language Tests](https://aclanthology.org/2021.emnlp-main.67)
  - Arya D. McCarthy, Kevin P. Yancey, Geoffrey T. LaFlair, Jesse Egbert, Manqian Liao, Burr Settles
  - **TLDR**: We present a novel method for estimating item difficulty estimates for high-stakes language assessments without piloting.

- [Voice Query Auto Completion](https://aclanthology.org/2021.emnlp-main.68)
  - Raphael Tang, Karun Kumar, Kendra Chalkley, Ji Xin, Liming Zhang, Wenyan Li, Gefei Yang, Yajie Mao, Junho Shin, Geoffrey Craig Murray, Jimmy Lin
  - **TLDR**: We propose to condition QAC approaches on intermediate transcriptions to complete voice queries.

- [CoPHE: A Count-Preserving Hierarchical Evaluation Metric in Large-Scale Multi-Label Text Classification](https://aclanthology.org/2021.emnlp-main.69)
  - Matúš Falis, Hang Dong, Alexandra Birch, Beatrice Alex
  - **TLDR**: We propose a new metric for hierarchical evaluation of the predictions of neural LMTC models based on the depth of the ontology.

- [Learning Universal Authorship Representations](https://aclanthology.org/2021.emnlp-main.70)
  - Rafael A. Rivera-Soto, Olivia Elizabeth Miano, Juanita Ordonez, Barry Y. Chen, Aleem Khan, Marcus Bishop, Nicholas Andrews
  - **TLDR**: We study the transfer of authorship representations learned in a particular domain to other domains and show that it is not so successful between certain domains.

- [Predicting emergent linguistic compositions through time: Syntactic frame extension via multimodal chaining](https://aclanthology.org/2021.emnlp-main.71)
  - Lei Yu, Yang Xu
  - **TLDR**: We develop a framework that exploits the cognitive mechanisms of chaining and multimodal knowledge to predict emergent compositional expressions through time.

- [Frequency Effects on Syntactic Rule Learning in Transformers](https://aclanthology.org/2021.emnlp-main.72)
  - Jason Wei, Dan Garrette, Tal Linzen, Ellie Pavlick
  - **TLDR**: We show that language models that are pre-trained on English subject–verb agreement are capable of generalizing to pairs that never occurred in training, suggesting a degree of rule-governed behavior.

- [A surprisal–duration trade-off across and within the world’s languages](https://aclanthology.org/2021.emnlp-main.73)
  - Tiago Pimentel, Clara Meister, Elizabeth Salesky, Simone Teufel, Damián Blasi, Ryan Cotterell
  - **TLDR**: We show that surprising languages produce faster phones than less surprising languages, and vice versa.

- [Revisiting the Uniform Information Density Hypothesis](https://aclanthology.org/2021.emnlp-main.74)
  - Clara Meister, Tiago Pimentel, Patrick Haller, Lena Jäger, Ryan Cotterell, Roger Levy
  - **TLDR**: We investigate the role of surprisal in the uniform information density hypothesis and show that it is predictive of language comprehension and acceptability.

- [Condenser: a Pre-training Architecture for Dense Retrieval](https://aclanthology.org/2021.emnlp-main.75)
  - Luyu Gao, Jamie Callan
  - **TLDR**: We propose to pre-train a novel Transformer language model for dense text representation encoders by training it on DENSE Representation.

- [Monitoring geometrical properties of word embeddings for detecting the emergence of new topics.](https://aclanthology.org/2021.emnlp-main.76)
  - Clément Christophe, Julien Velcin, Jairo Cugliari, Manel Boumghar, Philippe Suignard
  - **TLDR**: We propose to monitor the behavior of words representation in an embedding space and use one of its geometrical properties to characterize the emergence of topics.

- [Contextualized Query Embeddings for Conversational Search](https://aclanthology.org/2021.emnlp-main.77)
  - Sheng-Chieh Lin, Jheng-Hong Yang, Jimmy Lin
  - **TLDR**: We propose a compact and effective model for low-latency passage retrieval in conversational search based on learned dense representations.

- [Ultra-High Dimensional Sparse Representations with Binarization for Efficient Text Retrieval](https://aclanthology.org/2021.emnlp-main.78)
  - Kyoung-Rok Jang, Junmo Kang, Giwon Hong, Sung-Hyon Myaeng, Joohee Park, Taewon Yoon, Heecheol Seo
  - **TLDR**: We propose an ultra-high dimensional (UHD) representation scheme equipped with directly controllable sparsity.

- [IR like a SIR: Sense-enhanced Information Retrieval for Multiple Languages](https://aclanthology.org/2021.emnlp-main.79)
  - Rexhina Blloshmi, Tommaso Pasini, Niccolò Campolungo, Somnath Banerjee, Roberto Navigli, Gabriella Pasi
  - **TLDR**: We present SIR (Sense-enhanced Information Retrieval) to mitigate both problems by leveraging word sense information.

- [Neural Attention-Aware Hierarchical Topic Model](https://aclanthology.org/2021.emnlp-main.80)
  - Yuan Jin, He Zhao, Ming Liu, Lan Du, Wray Buntine
  - **TLDR**: We propose a novel neural topic model that combines bag-of-words and semantic embeddings for sentence and document word counts and a variational autoencoder for document-level word count reconstruction.

- [Relational World Knowledge Representation in Contextual Language Models: A Review](https://aclanthology.org/2021.emnlp-main.81)
  - Tara Safavi, Danai Koutra
  - **TLDR**: We propose to organize knowledge representation strategies in deep contextual language models by the level of KB supervision provided, from no KB supervision at all to entity- and relation-level supervision.

- [Certified Robustness to Programmable Transformations in LSTMs](https://aclanthology.org/2021.emnlp-main.82)
  - Yuhao Zhang, Aws Albarghouthi, Loris D’Antoni
  - **TLDR**: We present an approach to certify robustness of neural networks to intractably large perturbation spaces defined programmatically in a language of string transformations.

- [ReGen: Reinforcement Learning for Text and Knowledge Base Generation using Pretrained Language Models](https://aclanthology.org/2021.emnlp-main.83)
  - Pierre Dognin, Inkit Padhi, Igor Melnyk, Payel Das
  - **TLDR**: We present ReGen, a bidirectional generation of text and graph leveraging Reinforcement Learning to improve performance.

- [Contrastive Out-of-Distribution Detection for Pretrained Transformers](https://aclanthology.org/2021.emnlp-main.84)
  - Wenxuan Zhou, Fangyu Liu, Muhao Chen
  - **TLDR**: We develop an unsupervised OOD detection method for Transformers that outperforms baselines.

- [MindCraft: Theory of Mind Modeling for Situated Dialogue in Collaborative Tasks](https://aclanthology.org/2021.emnlp-main.85)
  - Cristian-Paul Bara, Sky CH-Wang, Joyce Chai
  - **TLDR**: We present theory of mind modeling in Minecraft and present results on computational models for several theory of minds in situated language communication.

- [Detecting Speaker Personas from Conversational Texts](https://aclanthology.org/2021.emnlp-main.86)
  - Jia-Chen Gu, Zhenhua Ling, Yu Wu, Quan Liu, Zhigang Chen, Xiaodan Zhu
  - **TLDR**: We propose a new task for speaker Persona Detection which aims to detect speaker personas based on the plain conversational text.

- [Cross-lingual Intermediate Fine-tuning improves Dialogue State Tracking](https://aclanthology.org/2021.emnlp-main.87)
  - Nikita Moghe, Mark Steedman, Alexandra Birch
  - **TLDR**: We use parallel and conversational movie subtitles datasets to design cross-lingual intermediate tasks suitable for downstream dialogue tasks.

- [ConvFiT: Conversational Fine-Tuning of Pretrained Language Models](https://aclanthology.org/2021.emnlp-main.88)
  - Ivan Vulić, Pei-Hao Su, Samuel Coope, Daniela Gerz, Paweł Budzianowski, Iñigo Casanueva, Nikola Mrkšić, Tsung-Hsien Wen
  - **TLDR**: We present ConvFiT, a novel ConvFi-based language model transformation framework for conversational sentence encoders.

- [We’ve had this conversation before: A Novel Approach to Measuring Dialog Similarity](https://aclanthology.org/2021.emnlp-main.89)
  - Ofer Lavi, Ella Rabinovich, Segev Shlomov, David Boaz, Inbal Ronen, Ateret Anaby Tavor
  - **TLDR**: We propose a novel adaptation of the edit distance metric to the scenario of dialog similarity.

- [Towards Incremental Transformers: An Empirical Analysis of Transformer Models for Incremental NLU](https://aclanthology.org/2021.emnlp-main.90)
  - Patrick Kahardipraja, Brielen Madureira, David Schlangen
  - **TLDR**: We show that recurrent Transformer with recurrent input prefixes can improve incremental processing in dialogue agents.

- [Feedback Attribution for Counterfactual Bandit Learning in Multi-Domain Spoken Language Understanding](https://aclanthology.org/2021.emnlp-main.91)
  - Tobias Falke, Patrick Lehnen
  - **TLDR**: We study the feedback attribution problem that arises when using counterfactual bandit learning for multi-domain spoken language understanding.

- [Label Verbalization and Entailment for Effective Zero and Few-Shot Relation Extraction](https://aclanthology.org/2021.emnlp-main.92)
  - Oscar Sainz, Oier Lopez de Lacalle, Gorka Labaka, Ander Barrena, Eneko Agirre
  - **TLDR**: We reformulate relation extraction as an entailment task, with simple, hand-made, verbalizations of relations produced in less than 15 min per relation.

- [Extend, don’t rebuild: Phrasing conditional graph modification as autoregressive sequence labelling](https://aclanthology.org/2021.emnlp-main.93)
  - Leon Weber, Jannes Münchmeyer, Samuele Garda, Ulf Leser
  - **TLDR**: We propose a graph extension algorithm for scene graph modification based on autoregressive sequence labelling and show that it improves graph extension accuracy by between 13 and 24 percentage points.

- [Zero-Shot Information Extraction as a Unified Text-to-Triple Translation](https://aclanthology.org/2021.emnlp-main.94)
  - Chenguang Wang, Xiao Liu, Zui Chen, Haoyun Hong, Jie Tang, Dawn Song
  - **TLDR**: We present a novel text-to-triple translation framework for information extraction tasks that is competitive with fully supervised methods.

- [Learning Logic Rules for Document-Level Relation Extraction](https://aclanthology.org/2021.emnlp-main.95)
  - Dongyu Ru, Changzhi Sun, Jiangtao Feng, Lin Qiu, Hao Zhou, Weinan Zhang, Yong Yu, Lei Li
  - **TLDR**: We propose LogiRE, a novel probabilistic model for document-level relation extraction by learning logic rules.

- [A Large-Scale Dataset for Empathetic Response Generation](https://aclanthology.org/2021.emnlp-main.96)
  - Anuradha Welivita, Yubo Xie, Pearl Pu
  - **TLDR**: We present a large-scale empathetic dataset consisting of 1M dialogues annotated with 32 fine-grained emotions, eight empatathetic response intents, and the Neutral category.

- [The Perils of Using Mechanical Turk to Evaluate Open-Ended Text Generation](https://aclanthology.org/2021.emnlp-main.97)
  - Marzena Karpinska, Nader Akoury, Mohit Iyyer
  - **TLDR**: We show that even with strict qualification filters, AMT workers (unlike teachers) fail to distinguish between model-generated text and human-generated references.

- [Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus](https://aclanthology.org/2021.emnlp-main.98)
  - Jesse Dodge, Maarten Sap, Ana Marasović, William Agnew, Gabriel Ilharco, Dirk Groeneveld, Margaret Mitchell, Matt Gardner
  - **TLDR**: We provide some of the first documentation for a large text corpora created by scraping a snapshot of Common Crawl and filtering it using blocklist filtering.

- [AfroMT: Pretraining Strategies and Reproducible Benchmarks for Translation of 8 African Languages](https://aclanthology.org/2021.emnlp-main.99)
  - Machel Reid, Junjie Hu, Graham Neubig, Yutaka Matsuo
  - **TLDR**: We propose AfroMT, a standardized, clean, and reproducible machine translation benchmark for eight widely spoken African languages.

- [Evaluating the Evaluation Metrics for Style Transfer: A Case Study in Multilingual Formality Transfer](https://aclanthology.org/2021.emnlp-main.100)
  - Eleftheria Briakou, Sweta Agrawal, Joel Tetreault, Marine Carpuat
  - **TLDR**: We present a multilingual evaluation of automatic metrics for style transfer in formality style transfer and identify several models that correlate well with human judgments and are robust across languages.

- [MS-Mentions: Consistently Annotating Entity Mentions in Materials Science Procedural Text](https://aclanthology.org/2021.emnlp-main.101)
  - Tim O’Gorman, Zach Jensen, Sheshera Mysore, Kevin Huang, Rubayyat Mahbub, Elsa Olivetti, Andrew McCallum
  - **TLDR**: We present a new corpus of entity mention annotations over 595 Material Science synthesis procedural texts (157,488 tokens), which greatly expands the training data available for the Named Entity Recognition task.

- [Understanding Politics via Contextualized Discourse Processing](https://aclanthology.org/2021.emnlp-main.102)
  - Rajkumar Pujari, Dan Goldwasser
  - **TLDR**: We propose a novel compositional reader model that captures and leverages contextualized information from multiple entities and events to generate more effective representations for entities, issues, and events.

- [Conundrums in Event Coreference Resolution: Making Sense of the State of the Art](https://aclanthology.org/2021.emnlp-main.103)
  - Jing Lu, Vincent Ng
  - **TLDR**: We present an empirical analysis of a state-of-the-art span-based event reference system with the goal of providing the general NLP audience with a better understanding of the state of the art and reference researchers with directions for future research.

- [Weakly supervised discourse segmentation for multiparty oral conversations](https://aclanthology.org/2021.emnlp-main.104)
  - Lila Gravellier, Julie Hunter, Philippe Muller, Thomas Pellegrini, Isabelle Ferrané
  - **TLDR**: We develop a weak supervision approach to adapt, using minimal annotation, a state of the art discourse segmenter trained on written text to French conversation transcripts.

- [Narrative Embedding: Re-Contextualization Through Attention](https://aclanthology.org/2021.emnlp-main.105)
  - Sean Wilner, Daniel Woolridge, Madeleine Glick
  - **TLDR**: We present a novel approach for narrative event representation using attention to re-contextualize events across the whole story.

- [Focus on what matters: Applying Discourse Coherence Theory to Cross Document Coreference](https://aclanthology.org/2021.emnlp-main.106)
  - William Held, Dan Iter, Dan Jurafsky
  - **TLDR**: Performing event and entity coreference resolution across documents vastly increases the number of candidate mentions, making it intractable to do the full 

- [Salience-Aware Event Chain Modeling for Narrative Understanding](https://aclanthology.org/2021.emnlp-main.107)
  - Xiyang Zhang, Muhao Chen, Jonathan May
  - **TLDR**: We propose novel methods for extracting the critical event chains of narrative text from natural language text and show that these chains are important for narrative prediction and temporal question answering.

- [Asking It All: Generating Contextualized Questions for any Semantic Role](https://aclanthology.org/2021.emnlp-main.108)
  - Valentina Pyatkin, Paul Roit, Julian Michael, Yoav Goldberg, Reut Tsarfaty, Ido Dagan
  - **TLDR**: We propose a new task for role question generation that uses a two-stage model to generate diverse and well-formed questions for a large, broad-coverage ontology of predicates and roles.

- [Fast, Effective, and Self-Supervised: Transforming Masked Language Models into Universal Lexical and Sentence Encoders](https://aclanthology.org/2021.emnlp-main.109)
  - Fangyu Liu, Ivan Vulić, Anna Korhonen, Nigel Collier
  - **TLDR**: We show that it is possible to turn MLMs into effective universal lexical and sentence encoders without any additional data, relying simply on self-supervision.

- [RuleBERT: Teaching Soft Rules to Pre-Trained Language Models](https://aclanthology.org/2021.emnlp-main.110)
  - Mohammed Saeed, Naser Ahmadi, Preslav Nakov, Paolo Papotti
  - **TLDR**: We present a new method for training language models to reason with soft rules and show that the resulting models can learn to predict probabilities for hypotheses.

- [Stepmothers are mean and academics are pretentious: What do pretrained language models learn about you?](https://aclanthology.org/2021.emnlp-main.111)
  - Rochelle Choenni, Ekaterina Shutova, Robert van Rooij
  - **TLDR**: We present a method to elicit stereotypical attributes encoded by pretrained language models in an unsupervised fashion and show how emotions and stereotypes can shift at the fine-tuning stage.

- [ConSeC: Word Sense Disambiguation as Continuous Sense Comprehension](https://aclanthology.org/2021.emnlp-main.112)
  - Edoardo Barba, Luigi Procopio, Roberto Navigli
  - **TLDR**: We propose CONtinuous SEnse Comprehension, a novel approach to word sense disambiguation that uses a feedback loop to learn to disambigenize words based on their explicit senses.

- [Shortcutted Commonsense: Data Spuriousness in Deep Learning of Commonsense Reasoning](https://aclanthology.org/2021.emnlp-main.113)
  - Ruben Branco, António Branco, João António Rodrigues, João Ricardo Silva
  - **TLDR**: We investigate whether Transformer neural language models are learning transferable generalizations intrinsic to the problem at stake or just taking advantage of incidental shortcuts in the data items.

- [When differential privacy meets NLP: The devil is in the detail](https://aclanthology.org/2021.emnlp-main.114)
  - Ivan Habernal
  - **TLDR**: We provide a formal analysis of ADePT, a differentially private auto-encoder for text rewriting, and show that it is not differentially privacy-efficient.

- [Achieving Model Robustness through Discrete Adversarial Training](https://aclanthology.org/2021.emnlp-main.115)
  - Maor Ivgi, Jonathan Berant
  - **TLDR**: We propose a new online adversarial attack for online augmentation, which improves robustness and speedup over offline augmentation.

- [Debiasing Methods in Natural Language Understanding Make Bias More Accessible](https://aclanthology.org/2021.emnlp-main.116)
  - Michael Mendelson, Yonatan Belinkov
  - **TLDR**: We show that the more a language model is pushed towards a debiased regime, the more bias is actually encoded in its inner representations.

- [Evaluating the Robustness of Neural Language Models to Input Perturbations](https://aclanthology.org/2021.emnlp-main.117)
  - Milad Moradi, Matthias Samwald
  - **TLDR**: We investigate the ability of high-performance language models such as BERT, XLNet, RoBERTa, and ELMo in handling different types of input perturbations.

- [How much pretraining data do language models need to learn syntax?](https://aclanthology.org/2021.emnlp-main.118)
  - Laura Pérez-Mayos, Miguel Ballesteros, Leo Wanner
  - **TLDR**: We explore the impact of pretraining data size on the syntactic capabilities of transformers-based language models and show that while models pretrained on more data encode more syntactic knowledge and perform better on downstream applications, they do not always offer a better performance across the different syntactic phenomena and come at a higher financial and environmental cost.

- [Sorting through the noise: Testing robustness of information processing in pre-trained language models](https://aclanthology.org/2021.emnlp-main.119)
  - Lalchand Pandia, Allyson Ettinger
  - **TLDR**: We present models with cloze tasks requiring use of critical context information, and introduce distracting content to test how robustly the models retain and use that critical information for prediction.

- [Contrastive Explanations for Model Interpretability](https://aclanthology.org/2021.emnlp-main.120)
  - Alon Jacovi, Swabha Swayamdipta, Shauli Ravfogel, Yanai Elazar, Yejin Choi, Yoav Goldberg
  - **TLDR**: We propose a method to produce contrastive explanations in the latent space, via a projection of the input representation, such that only the features that differentiate two potential decisions are captured.

- [On the Transferability of Adversarial Attacks against Neural Text Classifier](https://aclanthology.org/2021.emnlp-main.121)
  - Liping Yuan, Xiaoqing Zheng, Yi Zhou, Cho-Jui Hsieh, Kai-Wei Chang
  - **TLDR**: We present the first study to systematically investigate the transferability of adversarial examples for text classification models and explore how various factors, including network architecture, tokenization scheme, word embedding, and model capacity, affect the transferable of adversariant examples.

- [Conditional probing: measuring usable information beyond a baseline](https://aclanthology.org/2021.emnlp-main.122)
  - John Hewitt, Kawin Ethayarajh, Percy Liang, Christopher Manning
  - **TLDR**: We propose conditional probing of neural representations to measure usable information that is contained in the representation but not in the baseline.

- [GFST: Gender-Filtered Self-Training for More Accurate Gender in Translation](https://aclanthology.org/2021.emnlp-main.123)
  - Prafulla Kumar Choubey, Anna Currey, Prashant Mathur, Georgiana Dinu
  - **TLDR**: Gender-filtered self-training improves gender translation accuracy on unambiguously gendered inputs.

- [“Wikily” Supervised Neural Translation Tailored to Cross-Lingual Tasks](https://aclanthology.org/2021.emnlp-main.124)
  - Mohammad Sadegh Rasooli, Chris Callison-Burch, Derry Tanti Wijaya
  - **TLDR**: We present a simple but effective approach for leveraging Wikipedia for neural machine translation as well as cross-lingual tasks of image captioning and dependency parsing without using any direct supervision from external parallel data or supervised models in the target language.

- [mT6: Multilingual Pretrained Text-to-Text Transformer with Translation Pairs](https://aclanthology.org/2021.emnlp-main.125)
  - Zewen Chi, Li Dong, Shuming Ma, Shaohan Huang, Saksham Singhal, Xian-Ling Mao, Heyan Huang, Xia Song, Furu Wei
  - **TLDR**: We improve multilingual text-to-text transfer Transformer with translation pairs and propose a partially non-autoregressive objective for text- to-text pre-training.

- [Improving Zero-Shot Cross-Lingual Transfer Learning via Robust Training](https://aclanthology.org/2021.emnlp-main.126)
  - Kuan-Hao Huang, Wasi Ahmad, Nanyun Peng, Kai-Wei Chang
  - **TLDR**: We propose a robust multilingual language encoder that can tolerate noise in the contextual embedding spaces and improve zero-shot cross-lingual transfer on text classification tasks.

- [Speechformer: Reducing Information Loss in Direct Speech Translation](https://aclanthology.org/2021.emnlp-main.127)
  - Sara Papi, Marco Gaido, Matteo Negri, Marco Turchi
  - **TLDR**: We propose Speechformer, an architecture that, thanks to reduced memory usage in the attention layers, avoids the initial lossy compression and aggregates information only at a higher level according to more informed linguistic criteria.

- [Is “moby dick” a Whale or a Bird? Named Entities and Terminology in Speech Translation](https://aclanthology.org/2021.emnlp-main.128)
  - Marco Gaido, Susana Rodríguez, Matteo Negri, Luisa Bentivogli, Marco Turchi
  - **TLDR**: We present a new benchmark for speech translation systems that measures the performance of state-of-the-art systems on named entities and domain-specific terms.

- [HintedBT: Augmenting Back-Translation with Quality and Transliteration Hints](https://aclanthology.org/2021.emnlp-main.129)
  - Sahana Ramnath, Melvin Johnson, Abhirut Gupta, Aravindan Raghuveer
  - **TLDR**: We propose a novel method of using both high and low quality BT data for cross-script translation and show that using these hints improves translation quality and leads to state-of-the-art performance in all three language pairs in corresponding bilingual settings.

- [Translation-based Supervision for Policy Generation in Simultaneous Neural Machine Translation](https://aclanthology.org/2021.emnlp-main.130)
  - Ashkan Alinejad, Hassan S. Shavarani, Anoop Sarkar
  - **TLDR**: We propose a novel supervised learning approach for training an agent that can detect the minimum number of reads required for generating each target token by comparing simultaneous translations against full-sentence translations during training to generate oracle action sequences.

- [Nearest Neighbour Few-Shot Learning for Cross-lingual Classification](https://aclanthology.org/2021.emnlp-main.131)
  - M Saiful Bari, Batool Haider, Saab Mansour
  - **TLDR**: We investigate cross-lingual adaptation using a simple nearest-neighbor few-shot method and show that it can improve cross-language NLP performance.

- [Cross-Attention is All You Need: Adapting Pretrained Transformers for Machine Translation](https://aclanthology.org/2021.emnlp-main.132)
  - Mozhdeh Gheini, Xiang Ren, Jonathan May
  - **TLDR**: We study the power of cross-attention in the Transformer architecture within the context of transfer learning for machine translation, and extend the findings of studies into cross-tuning when training from scratch.

- [Effects of Parameter Norm Growth During Transformer Training: Inductive Bias from Gradient Descent](https://aclanthology.org/2021.emnlp-main.133)
  - William Merrill, Vivek Ramanujan, Yoav Goldberg, Roy Schwartz, Noah A. Smith
  - **TLDR**: We study the tendency for transformer parameters to grow in magnitude (

- [Foreseeing the Benefits of Incidental Supervision](https://aclanthology.org/2021.emnlp-main.134)
  - Hangfeng He, Mingyuan Zhang, Qiang Ning, Dan Roth
  - **TLDR**: We propose a unified PAC-Bayesian motivated informativeness measure, PABI, that characterizes the uncertainty reduction provided by incidental supervision signals.

- [Competency Problems: On Finding and Removing Artifacts in Language Data](https://aclanthology.org/2021.emnlp-main.135)
  - Matt Gardner, William Merrill, Jesse Dodge, Matthew Peters, Alexis Ross, Sameer Singh, Noah A. Smith
  - **TLDR**: We formalize the notion of "competency problems" in NLP and show that all simple feature correlations are spurious, and show how to identify and address them.

- [Knowledge-Aware Meta-learning for Low-Resource Text Classification](https://aclanthology.org/2021.emnlp-main.136)
  - Huaxiu Yao, Ying-xin Wu, Maruan Al-Shedivat, Eric Xing
  - **TLDR**: We propose a meta-learning algorithm that bridges the gap between meta-training and meta-testing tasks by leveraging the external knowledge bases.

- [Sentence Bottleneck Autoencoders from Transformer Language Models](https://aclanthology.org/2021.emnlp-main.137)
  - Ivan Montero, Nikolaos Pappas, Noah A. Smith
  - **TLDR**: We propose a sentence-level autoencoder that learns sentence representations from a pretrained, frozen transformer language model.

- [Efficient Contrastive Learning via Novel Data Augmentation and Curriculum Learning](https://aclanthology.org/2021.emnlp-main.138)
  - Seonghyeon Ye, Jiseon Kim, Alice Oh
  - **TLDR**: We introduce EfficientCL, a memory-efficient continual pretraining method that applies contrastive learning with novel data augmentation and curriculum learning.

- [CR-Walker: Tree-Structured Graph Reasoning and Dialog Acts for Conversational Recommendation](https://aclanthology.org/2021.emnlp-main.139)
  - Wenchang Ma, Ryuichi Takanobu, Minlie Huang
  - **TLDR**: We propose CR-Walker, a new approach to tree-structured reasoning in conversational recommendation systems, which can generate informative dialog acts to guide language generation.

- [DIALKI: Knowledge Identification in Conversational Systems through Dialogue-Document Contextualization](https://aclanthology.org/2021.emnlp-main.140)
  - Zeqiu Wu, Bo-Ru Lu, Hannaneh Hajishirzi, Mari Ostendorf
  - **TLDR**: We present a knowledge identification model that leverages the document structure to provide dialogue-contextualized passage encodings and better locate knowledge relevant to the conversation.

- [Iconary: A Pictionary-Based Game for Testing Multimodal Communication with Drawings and Text](https://aclanthology.org/2021.emnlp-main.141)
  - Christopher Clark, Jordi Salvador, Dustin Schwenk, Derrick Bonafilia, Mark Yatskar, Eric Kolve, Alvaro Herrasti, Jonghyun Choi, Sachin Mehta, Sam Skjonsberg, Carissa Schoenick, Aaron Sarnat, Hannaneh Hajishirzi, Aniruddha Kembhavi, Oren Etzioni, Ali Farhadi
  - **TLDR**: We propose a new game of drawing and guessing based on Pictionary that uses visual metaphors and icon compositions to express challenging words.

- [Self-training Improves Pre-training for Few-shot Learning in Task-oriented Dialog Systems](https://aclanthology.org/2021.emnlp-main.142)
  - Fei Mi, Wanhao Zhou, Lingjing Kong, Fengyu Cai, Minlie Huang, Boi Faltings
  - **TLDR**: We propose a self-training approach to utilize the abundant unlabeled dialog data to further improve state-of-the-art pre-trained models in few-shot learning scenarios for task-oriented dialog (ToD) systems.

- [Contextual Rephrase Detection for Reducing Friction in Dialogue Systems](https://aclanthology.org/2021.emnlp-main.143)
  - Zhuoyi Wang, Saurabh Gupta, Jie Hao, Xing Fan, Dingcheng Li, Alexander Hanbo Li, Chenlei Guo
  - **TLDR**: We propose a new model for voice assistants that can identify rephrases from multi-turn dialogues and use the user feedback to improve the accuracy of the rephrase detection.

- [Few-Shot Intent Detection via Contrastive Pre-Training and Fine-Tuning](https://aclanthology.org/2021.emnlp-main.144)
  - Jianguo Zhang, Trung Bui, Seunghyun Yoon, Xiang Chen, Zhiwei Liu, Congying Xia, Quan Hung Tran, Walter Chang, Philip Yu
  - **TLDR**: We present a simple yet effective few-shot intent detection schema via contrastive pre-training and fine-tuning.

- [“It doesn’t look good for a date”: Transforming Critiques into Preferences for Conversational Recommendation Systems](https://aclanthology.org/2021.emnlp-main.145)
  - Victor Bursztyn, Jennifer Healey, Nedim Lipka, Eunyee Koh, Doug Downey, Larry Birnbaum
  - **TLDR**: We present a method for transforming a user critique into a positive preference (e.g., “I prefer more romantic”) in order to retrieve reviews pertaining to potentially better recommendations.

- [AttentionRank: Unsupervised Keyphrase Extraction using Self and Cross Attentions](https://aclanthology.org/2021.emnlp-main.146)
  - Haoran Ding, Xiao Luo
  - **TLDR**: We propose the AttentionRank, a hybrid attention model, to identify keyphrases from a document in an unsupervised manner.

- [Unsupervised Relation Extraction: A Variational Autoencoder Approach](https://aclanthology.org/2021.emnlp-main.147)
  - Chenhan Yuan, Hoda Eldardiry
  - **TLDR**: We propose a VAE-based unsupervised relation extraction technique that overcomes this limitation by using the classifications as an intermediate variable instead of a latent variable.

- [Robust Retrieval Augmented Generation for Zero-shot Slot Filling](https://aclanthology.org/2021.emnlp-main.148)
  - Michael Glass, Gaetano Rossiello, Md Faisal Mahbub Chowdhury, Alfio Gliozzo
  - **TLDR**: We present a novel approach to zero-shot slot filling that extends dense passage retrieval with hard negatives and robust training procedures for retrieval augmented generation models.

- [Everything Is All It Takes: A Multipronged Strategy for Zero-Shot Cross-Lingual Information Extraction](https://aclanthology.org/2021.emnlp-main.149)
  - Mahsa Yarmohammadi, Shijie Wu, Marc Marone, Haoran Xu, Seth Ebner, Guanghui Qin, Yunmo Chen, Jialiang Guo, Craig Harman, Kenton Murray, Aaron Steven White, Mark Dredze, Benjamin Van Durme
  - **TLDR**: We explore techniques including data projection and self-training, and how different pretrained encoders impact them.

- [Harms of Gender Exclusivity and Challenges in Non-Binary Representation in Language Technologies](https://aclanthology.org/2021.emnlp-main.150)
  - Sunipa Dev, Masoud Monajatipoor, Anaelia Ovalle, Arjun Subramonian, Jeff Phillips, Kai-Wei Chang
  - **TLDR**: We explain the complexity of gender and language around it, and survey non-binary persons to understand harms associated with the treatment of gender as binary in English language technologies.

- [Are Gender-Neutral Queries Really Gender-Neutral? Mitigating Gender Bias in Image Search](https://aclanthology.org/2021.emnlp-main.151)
  - Jialu Wang, Yang Liu, Xin Wang
  - **TLDR**: We propose two novel debiasing methods for image search models that reduce gender bias in search images.

- [Style Pooling: Automatic Text Style Obfuscation for Improved Classification Fairness](https://aclanthology.org/2021.emnlp-main.152)
  - Fatemehsadat Mireshghallah, Taylor Berg-Kirkpatrick
  - **TLDR**: We propose a VAE-based framework that obfuscates stylistic features of human-generated text through style transfer, by automatically re-writing the text itself.

- [Modeling Disclosive Transparency in NLP Application Descriptions](https://aclanthology.org/2021.emnlp-main.153)
  - Michael Saxon, Sharon Levy, Xinyi Wang, Alon Albalak, William Yang Wang
  - **TLDR**: We introduce neural language model-based probabilistic metrics to directly model disclosive transparency, and demonstrate that they correlate with user and expert opinions of system transparency, making them a valid objective proxy.

- [Reconstruction Attack on Instance Encoding for Language Understanding](https://aclanthology.org/2021.emnlp-main.154)
  - Shangyu Xie, Yuan Hong
  - **TLDR**: We propose a novel reconstruction attack to break TextHide by recovering the private training data, and thus unveil the privacy risks of instance encoding.

- [Fairness-aware Class Imbalanced Learning](https://aclanthology.org/2021.emnlp-main.155)
  - Shivashankar Subramanian, Afshin Rahimi, Timothy Baldwin, Trevor Cohn, Lea Frermann
  - **TLDR**: We propose novel methods for long-tail learning that mitigate class imbalance and mitigate bias in NLP tasks.

- [CRYPTOGRU: Low Latency Privacy-Preserving Text Analysis With GRU](https://aclanthology.org/2021.emnlp-main.156)
  - Bo Feng, Qian Lou, Lei Jiang, Geoffrey Fox
  - **TLDR**: We present a novel hybrid structure of HE and GC gated recurrent unit (GRU) network,, for low-latency secure inferences.

- [Local Word Discovery for Interactive Transcription](https://aclanthology.org/2021.emnlp-main.157)
  - William Lane, Steven Bird
  - **TLDR**: We propose a new computational task which is tuned to the available knowledge and interests in an Indigenous language, and which supports the construction of high quality texts and lexicons.

- [Segment, Mask, and Predict: Augmenting Chinese Word Segmentation with Self-Supervision](https://aclanthology.org/2021.emnlp-main.158)
  - Mieradilijiang Maimaiti, Yang Liu, Yuanhang Zheng, Gang Chen, Kaiyu Huang, Ji Zhang, Huanbo Luan, Maosong Sun
  - **TLDR**: We propose a self-supervised CWS approach with a straightforward and effective architecture.

- [Minimal Supervision for Morphological Inflection](https://aclanthology.org/2021.emnlp-main.159)
  - Omer Goldman, Reut Tsarfaty
  - **TLDR**: We propose a new method for bootstrapping labeled data from a seed as small as a few hundred amino acids.

- [Fast WordPiece Tokenization](https://aclanthology.org/2021.emnlp-main.160)
  - Xinying Song, Alex Salcianu, Yang Song, Dave Dopson, Denny Zhou
  - **TLDR**: We propose efficient algorithms for the WordPiece tokenization used in BERT, from single-word tokenization to general text (e.g., sentence) tokenization.

- [You should evaluate your language model on marginal likelihood over tokenisations](https://aclanthology.org/2021.emnlp-main.161)
  - Kris Cao, Laura Rimell
  - **TLDR**: We show that the marginal perplexity of language models can be significantly better than the one-best-tokenisation and show that this uncertainty can be correlated with the tokeniser entropy.

- [Broaden the Vision: Geo-Diverse Visual Commonsense Reasoning](https://aclanthology.org/2021.emnlp-main.162)
  - Da Yin, Liunian Harold Li, Ziniu Hu, Nanyun Peng, Kai-Wei Chang
  - **TLDR**: We present a dataset for visual commonsense reasoning and show that the performance of vision-and-language models for non-Western regions is significantly lower than that for Western regions.

- [Reference-Centric Models for Grounded Collaborative Dialogue](https://aclanthology.org/2021.emnlp-main.163)
  - Daniel Fried, Justin Chiu, Dan Klein
  - **TLDR**: We present a grounded neural dialogue model that successfully collaborates with people in a partially-observable reference game.

- [CrossVQA: Scalably Generating Benchmarks for Systematically Testing VQA Generalization](https://aclanthology.org/2021.emnlp-main.164)
  - Arjun Akula, Soravit Changpinyo, Boqing Gong, Piyush Sharma, Song-Chun Zhu, Radu Soricut
  - **TLDR**: We propose a semi-automatic framework for generating disentangled visual question answering models that can be used to evaluate cross-dataset adaptation models.

- [Visual Goal-Step Inference using wikiHow](https://aclanthology.org/2021.emnlp-main.165)
  - Yue Yang, Artemis Panagopoulou, Qing Lyu, Li Zhang, Mark Yatskar, Chris Callison-Burch
  - **TLDR**: Visual goal-step inference for multimodal models.

- [Systematic Generalization on gSCAN: What is Nearly Solved and What is Next?](https://aclanthology.org/2021.emnlp-main.166)
  - Linlu Qiu, Hexiang Hu, Bowen Zhang, Peter Shaw, Fei Sha
  - **TLDR**: We analyze the 

- [Effect of Visual Extensions on Natural Language Understanding in Vision-and-Language Models](https://aclanthology.org/2021.emnlp-main.167)
  - Taichi Iki, Akiko Aizawa
  - **TLDR**: We propose to evaluate V&L models using an NLU benchmark and show that the pre-training causes the performance drop in NLU tasks with few exceptions.

- [Neural Path Hunter: Reducing Hallucination in Dialogue Systems via Path Grounding](https://aclanthology.org/2021.emnlp-main.168)
  - Nouha Dziri, Andrea Madotto, Osmar Zaïane, Avishek Joey Bose
  - **TLDR**: We propose Neural Path Hunter which improves faithfulness and reduces hallucination of neural dialogue systems to known facts supplied by a Knowledge Graph.

- [Thinking Clearly, Talking Fast: Concept-Guided Non-Autoregressive Generation for Open-Domain Dialogue Systems](https://aclanthology.org/2021.emnlp-main.169)
  - Yicheng Zou, Zhihua Liu, Xingwu Hu, Qi Zhang
  - **TLDR**: We propose a concept-guided non-autoregressive dialogue generation model for open-domain dialogue generation that can produce diverse and coherent responses.

- [Perspective-taking and Pragmatics for Generating Empathetic Responses Focused on Emotion Causes](https://aclanthology.org/2021.emnlp-main.170)
  - Hyunwoo Kim, Byeongchang Kim, Gunhee Kim
  - **TLDR**: We propose a novel method for generating empathetic responses in dialogue models by infering emotion cause words from utterances with no word-level label.

- [Generation and Extraction Combined Dialogue State Tracking with Hierarchical Ontology Integration](https://aclanthology.org/2021.emnlp-main.171)
  - Xinmeng Li, Qian Li, Wansen Wu, Quanjun Yin
  - **TLDR**: We propose a new model for dialogue state tracking that is more robust to out-of-vocabulary problem and improves the interrelation between slots with masked hierarchical attention.

- [CoLV: A Collaborative Latent Variable Model for Knowledge-Grounded Dialogue Generation](https://aclanthology.org/2021.emnlp-main.172)
  - Haolan Zhan, Lei Shen, Hongshen Chen, Hainan Zhang
  - **TLDR**: We propose a collaborative latent variable model for knowledge-grounded dialogue generation that captures the inherent correlation between knowledge selection and response generation.

- [A Three-Stage Learning Framework for Low-Resource Knowledge-Grounded Dialogue Generation](https://aclanthology.org/2021.emnlp-main.173)
  - Shilei Liu, Xiaofeng Zhao, Bochao Li, Feiliang Ren, Longhui Zhang, Shujuan Yin
  - **TLDR**: We propose a novel three-stage learning framework based on weakly supervised learning which benefits from large scale ungrounded dialogues and unstructured knowledge base.

- [Intention Reasoning Network for Multi-Domain End-to-end Task-Oriented Dialogue](https://aclanthology.org/2021.emnlp-main.174)
  - Zhiyuan Ma, Jianjun Li, Zezheng Zhang, Guohui Li, Yongjing Cheng
  - **TLDR**: We propose a novel intention mechanism to better model deterministic entity knowledge and generate more accurate responses in task-oriented dialog system.

- [More is Better: Enhancing Open-Domain Dialogue Generation via Multi-Source Heterogeneous Knowledge](https://aclanthology.org/2021.emnlp-main.175)
  - Sixing Wu, Ying Li, Minghui Wang, Dawei Zhang, Yang Zhou, Zhonghai Wu
  - **TLDR**: We propose a novel dialogue generation model, MSKE-Dialog, which uses multi-source heterogeneous knowledge to generate informative dialogues.

- [Domain-Lifelong Learning for Dialogue State Tracking via Knowledge Preservation Networks](https://aclanthology.org/2021.emnlp-main.176)
  - Qingbin Liu, Pengfei Cao, Cao Liu, Jiansong Chen, Xunliang Cai, Fan Yang, Shizhu He, Kang Liu, Jun Zhao
  - **TLDR**: We propose a novel domain-lifelong learning method for dialogue state tracking that alleviates catastrophic forgetting and outperforms previous state-of-the-art lifelong learning methods.

- [CSAGN: Conversational Structure Aware Graph Network for Conversational Semantic Role Labeling](https://aclanthology.org/2021.emnlp-main.177)
  - Han Wu, Kun Xu, Linqi Song
  - **TLDR**: We present a simple and effective architecture for conversational semantic role labeling which encodes the speaker dependent information.

- [Different Strokes for Different Folks: Investigating Appropriate Further Pre-training Approaches for Diverse Dialogue Tasks](https://aclanthology.org/2021.emnlp-main.178)
  - Yao Qiu, Jinchao Zhang, Jie Zhou
  - **TLDR**: We propose a new way to improve multiple task-oriented dialogue downstream tasks by designing appropriate further pre-training tasks that benefit downstream tasks.

- [Knowledge Enhanced Fine-Tuning for Better Handling Unseen Entities in Dialogue Generation](https://aclanthology.org/2021.emnlp-main.179)
  - Leyang Cui, Yu Wu, Shujie Liu, Yue Zhang
  - **TLDR**: We propose a new method for pre-training dialogue generation that learns a better semantic representation by predicting the information in the knowledge base, only based on the input context.

- [An Evaluation Dataset and Strategy for Building Robust Multi-turn Response Selection Model](https://aclanthology.org/2021.emnlp-main.180)
  - Kijong Han, Seojin Lee, Dong-hun Lee
  - **TLDR**: We analyze the weaknesses of the open-domain Korean Multi-turn response selection models and publish an adversarial dataset to evaluate these weaknesses.

- [Unsupervised Conversation Disentanglement through Co-Training](https://aclanthology.org/2021.emnlp-main.181)
  - Hui Liu, Zhan Shi, Xiaodan Zhu
  - **TLDR**: We propose a novel method for deep co-training a conversation disentanglement model without referencing any human annotations.

- [Don’t be Contradicted with Anything! CI-ToD: Towards Benchmarking Consistency for Task-oriented Dialogue System](https://aclanthology.org/2021.emnlp-main.182)
  - Libo Qin, Tianbao Xie, Shijue Huang, Qiguang Chen, Xiao Xu, Wanxiang Che
  - **TLDR**: We propose a task-oriented dialogue direction for open-domain dialogue.

- [Transferable Persona-Grounded Dialogues via Grounded Minimal Edits](https://aclanthology.org/2021.emnlp-main.183)
  - Chen Henry Wu, Yinhe Zheng, Xiaoxi Mao, Minlie Huang
  - **TLDR**: Grounded dialogue models generate responses that are grounded on certain concepts.

- [EARL: Informative Knowledge-Grounded Conversation Generation with Entity-Agnostic Representation Learning](https://aclanthology.org/2021.emnlp-main.184)
  - Hao Zhou, Minlie Huang, Yong Liu, Wei Chen, Xiaoyan Zhu
  - **TLDR**: We propose an Entity-Agnostic Representation Learning (EARL) method to introduce knowledge graphs to informative conversation generation.

- [DialogueCSE: Dialogue-based Contrastive Learning of Sentence Embeddings](https://aclanthology.org/2021.emnlp-main.185)
  - Che Liu, Rui Wang, Jinghua Liu, Jian Sun, Fei Huang, Luo Si
  - **TLDR**: DialogueCSE is a dialogue-based contrastive learning approach for sentence embeddings from dialogues.

- [Improving Graph-based Sentence Ordering with Iteratively Predicted Pairwise Orderings](https://aclanthology.org/2021.emnlp-main.186)
  - Shaopeng Lai, Ante Wang, Fandong Meng, Jie Zhou, Yubin Ge, Jiali Zeng, Junfeng Yao, Degen Huang, Jinsong Su
  - **TLDR**: We propose a novel sentence ordering framework which introduces two classifiers to make better use of pairwise orderings for graph-based sentence ordering.

- [Not Just Classification: Recognizing Implicit Discourse Relation on Joint Modeling of Classification and Generation](https://aclanthology.org/2021.emnlp-main.187)
  - Feng Jiang, Yaxin Fan, Xiaomin Chu, Peifeng Li, Qiaoming Zhu
  - **TLDR**: We propose a method for implicit discourse relation recognition that combines the classification and generation of sentences.

- [A Language Model-based Generative Classifier for Sentence-level Discourse Parsing](https://aclanthology.org/2021.emnlp-main.188)
  - Ying Zhang, Hidetaka Kamigaito, Manabu Okumura
  - **TLDR**: We propose a language model-based generative classifier for using more information from labels by treating the labels as an input while enhancing label representations by embedding descriptions for each label.

- [Multimodal Phased Transformer for Sentiment Analysis](https://aclanthology.org/2021.emnlp-main.189)
  - Junyan Cheng, Iordanis Fostiropoulos, Barry Boehm, Mohammad Soleymani
  - **TLDR**: We propose multimodal Sparse Phased Transformer (SPT) to alleviate the problem of self-attention complexity and memory footprint.

- [Hierarchical Multi-label Text Classification with Horizontal and Vertical Category Correlations](https://aclanthology.org/2021.emnlp-main.190)
  - Linli Xu, Sijie Teng, Ruoyu Zhao, Junliang Guo, Chi Xiao, Deqiang Jiang, Bo Ren
  - **TLDR**: We propose a novel HMTC framework that considers both vertical and horizontal category correlations in hierarchical multi-label text classification.

- [RankNAS: Efficient Neural Architecture Search by Pairwise Ranking](https://aclanthology.org/2021.emnlp-main.191)
  - Chi Hu, Chenglong Wang, Xiangnan Ma, Xia Meng, Yinqiao Li, Tong Xiao, Jingbo Zhu, Changliang Li
  - **TLDR**: We propose a new architecture search algorithm that uses pairwise ranking to find the best architectures.

- [FLiText: A Faster and Lighter Semi-Supervised Text Classification with Convolution Networks](https://aclanthology.org/2021.emnlp-main.192)
  - Chen Liu, Zhang Mengchao, Fu Zhibing, Panpan Hou, Yu Li
  - **TLDR**: We develop a new SOTA framework for lightweight models that improves the accuracy of lightweight models on text classification.

- [Evaluating Debiasing Techniques for Intersectional Biases](https://aclanthology.org/2021.emnlp-main.193)
  - Shivashankar Subramanian, Xudong Han, Timothy Baldwin, Trevor Cohn, Lea Frermann
  - **TLDR**: We propose a new method for evaluating and debiasing NLP models which consider multiple identities, including gender, race, gender-variant, and intersectional groups.

- [Definition Modelling for Appropriate Specificity](https://aclanthology.org/2021.emnlp-main.194)
  - Han Huang, Tomoyuki Kajiwara, Yuki Arase
  - **TLDR**: We propose a method for definition generation with appropriate specificity in definitions.

- [Transductive Learning for Unsupervised Text Style Transfer](https://aclanthology.org/2021.emnlp-main.195)
  - Fei Xiao, Liang Pang, Yanyan Lan, Yan Wang, Huawei Shen, Xueqi Cheng
  - **TLDR**: We propose a novel transductive style transfer model based on a retrieval-based context-aware style representation.

- [Integrating Semantic Scenario and Word Relations for Abstractive Sentence Summarization](https://aclanthology.org/2021.emnlp-main.196)
  - Yong Guan, Shaoru Guo, Ru Li, Xiaoli Li, Hu Zhang
  - **TLDR**: We propose a novel Dual Graph network for Abstractive Sentence Summarization.

- [Coupling Context Modeling with Zero Pronoun Recovering for Document-Level Natural Language Generation](https://aclanthology.org/2021.emnlp-main.197)
  - Xin Tan, Longyin Zhang, Guodong Zhou
  - **TLDR**: We propose a novel adaptive two-stage approach to couple context modeling with ZP recovering to mitigate the ZP problem in NLG tasks.

- [Adaptive Bridge between Training and Inference for Dialogue Generation](https://aclanthology.org/2021.emnlp-main.198)
  - Haoran Xu, Hainan Zhang, Yanyan Zou, Hongshen Chen, Zhuoye Ding, Yanyan Lan
  - **TLDR**: We propose a novel adaptive switching mechanism, which learns to automatically transit between ground-truth learning and generated learning regarding the word-level matching score, such as the cosine similarity.

- [ConRPG: Paraphrase Generation using Contexts as Regularizer](https://aclanthology.org/2021.emnlp-main.199)
  - Yuxian Meng, Xiang Ao, Qing He, Xiaofei Sun, Qinghong Han, Fei Wu, Chun Fan, Jiwei Li
  - **TLDR**: We propose a new unsupervised paradigm for paraphrase generation based on the assumption that the probabilities of generating two sentences with the same meaning given the same context should be the same.

- [Building the Directed Semantic Graph for Coherent Long Text Generation](https://aclanthology.org/2021.emnlp-main.200)
  - Ziao Wang, Xiaofeng Zhang, Hongwei Du
  - **TLDR**: We propose a novel two-stage approach to generate coherent long text conditionally depending on the short input text.

- [Iterative GNN-based Decoder for Question Generation](https://aclanthology.org/2021.emnlp-main.201)
  - Zichu Fei, Qi Zhang, Yaqian Zhou
  - **TLDR**: We propose a novel graph-based natural question generation model that captures structure information in the previous generation and uses it to improve the generation of questions from a passage.

- [Asking Questions Like Educational Experts: Automatically Generating Question-Answer Pairs on Real-World Examination Data](https://aclanthology.org/2021.emnlp-main.202)
  - Fanyi Qu, Xin Jia, Yunfang Wu
  - **TLDR**: We propose a new unified framework for question-answer pair generation on RACE.

- [Syntactically-Informed Unsupervised Paraphrasing with Non-Parallel Data](https://aclanthology.org/2021.emnlp-main.203)
  - Erguang Yang, Mingtong Liu, Deyi Xiong, Yujie Zhang, Yao Meng, Changjian Hu, Jinan Xu, Yufeng Chen
  - **TLDR**: Syntactically controlled paraphrase generation with non-parallel data.

- [Exploring Task Difficulty for Few-Shot Relation Extraction](https://aclanthology.org/2021.emnlp-main.204)
  - Jiale Han, Bo Cheng, Wei Lu
  - **TLDR**: We propose a novel approach based on contrastive learning that learns better representations by exploiting relation label information.

- [MuVER: Improving First-Stage Entity Retrieval with Multi-View Entity Representations](https://aclanthology.org/2021.emnlp-main.205)
  - Xinyin Ma, Yong Jiang, Nguyen Bach, Tao Wang, Zhongqiang Huang, Fei Huang, Weiming Lu
  - **TLDR**: We propose Multi-View Entity Representations (MuVER), a novel approach for entity retrieval that constructs multi-view representations for entity descriptions and approximates the optimal view for mentions via a heuristic searching method.

- [Treasures Outside Contexts: Improving Event Detection via Global Statistics](https://aclanthology.org/2021.emnlp-main.206)
  - Rui Li, Wenlin Zhao, Cheng Yang, Sen Su
  - **TLDR**: We propose a novel event detection model based on statistical features extracted from word-event co-occurrence frequencies in the training set.

- [Uncertain Local-to-Global Networks for Document-Level Event Factuality Identification](https://aclanthology.org/2021.emnlp-main.207)
  - Pengfei Cao, Yubo Chen, Yuqing Yang, Kang Liu, Jun Zhao
  - **TLDR**: We propose a novel method for document-level event factuality identification, which can be utilized to improve performance.

- [A Novel Global Feature-Oriented Relational Triple Extraction Model based on Table Filling](https://aclanthology.org/2021.emnlp-main.208)
  - Feiliang Ren, Longhui Zhang, Shujuan Yin, Xiaofeng Zhao, Shilei Liu, Bochao Li, Yaduo Liu
  - **TLDR**: We propose a global feature-oriented triple extraction model that makes full use of the mentioned two kinds of global associations.

- [Structure-Augmented Keyphrase Generation](https://aclanthology.org/2021.emnlp-main.209)
  - Jihyuk Kim, Myeongho Jeong, Seungtaek Choi, Seung-won Hwang
  - **TLDR**: We propose novel structure-augmented document encoding approaches that augment the text of a short text with missing/incomplete keyphrases and augment the structure of the document.

- [An Empirical Study on Multiple Information Sources for Zero-Shot Fine-Grained Entity Typing](https://aclanthology.org/2021.emnlp-main.210)
  - Yi Chen, Haiyun Jiang, Lemao Liu, Shuming Shi, Chuang Fan, Min Yang, Ruifeng Xu
  - **TLDR**: We empirically study three kinds of auxiliary information: context consistency, type hierarchy and background knowledge (e.g., prototypes and descriptions) of types, and propose a multi-source fusion model (MSF) targeting these sources.

- [DyLex: Incorporating Dynamic Lexicons into BERT for Sequence Labeling](https://aclanthology.org/2021.emnlp-main.211)
  - Baojun Wang, Zhao Zhang, Kun Xu, Guang-Yuan Hao, Yuyang Zhang, Lifeng Shang, Linlin Li, Xiao Chen, Xin Jiang, Qun Liu
  - **TLDR**: We propose DyLex, a plug-in lexicon incorporation approach for BERT based sequence labeling tasks.

- [MapRE: An Effective Semantic Mapping Approach for Low-resource Relation Extraction](https://aclanthology.org/2021.emnlp-main.212)
  - Manqing Dong, Chunguang Pan, Zhipeng Luo
  - **TLDR**: We propose a framework for label-agnostic and label-aware semantic mapping information for low resource relation extraction.

- [Heterogeneous Graph Neural Networks for Keyphrase Generation](https://aclanthology.org/2021.emnlp-main.213)
  - Jiacheng Ye, Ruijian Cai, Tao Gui, Qi Zhang
  - **TLDR**: We propose a novel graph-based method that can capture explicit knowledge from related references for keyphrase generation and prediction.

- [Machine Reading Comprehension as Data Augmentation: A Case Study on Implicit Event Argument Extraction](https://aclanthology.org/2021.emnlp-main.214)
  - Jian Liu, Yufeng Chen, Jinan Xu
  - **TLDR**: We propose a novel approach to address the data sparsity issue faced by implicit EAE by bridging the task with machine reading comprehension.

- [Importance Estimation from Multiple Perspectives for Keyphrase Extraction](https://aclanthology.org/2021.emnlp-main.215)
  - Mingyang Song, Liping Jing, Lin Xiao
  - **TLDR**: We propose a new approach to estimate the importance of keyphrase from multiple perspectives (called as    keyphrase importance estimation) and show that it is biased.

- [Gradient Imitation Reinforcement Learning for Low Resource Relation Extraction](https://aclanthology.org/2021.emnlp-main.216)
  - Xuming Hu, Chenwei Zhang, Yawen Yang, Xiaohe Li, Li Lin, Lijie Wen, Philip S. Yu
  - **TLDR**: We propose a novel meta-learning scheme for low-resource relation extraction which uses pseudo label data to imitate the gradient descent direction on labeled data and bootstrap its optimization capability through trial and error.

- [Low-resource Taxonomy Enrichment with Pretrained Language Models](https://aclanthology.org/2021.emnlp-main.217)
  - Kunihiro Takeoka, Kosuke Akimoto, Masafumi Oyamada
  - **TLDR**: We propose Musubu, an efficient framework for taxonomy enrichment in low-resource settings with pretrained language models (LMs) as knowledge bases to compensate for the shortage of information.

- [Entity Relation Extraction as Dependency Parsing in Visually Rich Documents](https://aclanthology.org/2021.emnlp-main.218)
  - Yue Zhang, Zhang Bo, Rui Wang, Junjie Cao, Chen Li, Zuyi Bao
  - **TLDR**: We present a novel entity relation extraction model for visually rich documents.

- [Synchronous Dual Network with Cross-Type Attention for Joint Entity and Relation Extraction](https://aclanthology.org/2021.emnlp-main.219)
  - Hui Wu, Xiaodong Shi
  - **TLDR**: We propose a novel synchronous dual network with cross-type attention mechanism for jointly training entity and relation extraction.

- [Less is More: Pretrain a Strong Siamese Encoder for Dense Text Retrieval Using a Weak Decoder](https://aclanthology.org/2021.emnlp-main.220)
  - Shuqi Lu, Di He, Chenyan Xiong, Guolin Ke, Waleed Malik, Zhicheng Dou, Paul Bennett, Tie-Yan Liu, Arnold Overwijk
  - **TLDR**: We show that an autoencoder language model with a low reconstruction loss may not provide good sequence representations because the decoder may take shortcuts by exploiting language patterns.

- [TransPrompt: Towards an Automatic Transferable Prompting Framework for Few-shot Text Classification](https://aclanthology.org/2021.emnlp-main.221)
  - Chengyu Wang, Jianing Wang, Minghui Qiu, Jun Huang, Ming Gao
  - **TLDR**: We propose TransPrompt, a transferable prompting framework for few-shot learning across similar tasks.

- [Weakly-supervised Text Classification Based on Keyword Graph](https://aclanthology.org/2021.emnlp-main.222)
  - Lu Zhang, Jiandong Ding, Yi Xu, Yingyao Liu, Shuigeng Zhou
  - **TLDR**: We propose a novel framework for weakly-supervised text classification by GNN that explores keyword-keyword correlation on keyword graph by GANL.

- [Efficient-FedRec: Efficient Federated Learning Framework for Privacy-Preserving News Recommendation](https://aclanthology.org/2021.emnlp-main.223)
  - Jingwei Yi, Fangzhao Wu, Chuhan Wu, Ruixuan Liu, Guangzhong Sun, Xing Xie
  - **TLDR**: We propose a federated learning framework for privacy-preserving news recommendation.

- [RocketQAv2: A Joint Training Method for Dense Passage Retrieval and Passage Re-ranking](https://aclanthology.org/2021.emnlp-main.224)
  - Ruiyang Ren, Yingqi Qu, Jing Liu, Wayne Xin Zhao, QiaoQiao She, Hua Wu, Haifeng Wang, Ji-Rong Wen
  - **TLDR**: We propose a novel joint training approach for dense passage retrieval and passage re-ranking.

- [Dealing with Typos for BERT-based Passage Retrieval and Ranking](https://aclanthology.org/2021.emnlp-main.225)
  - Shengyao Zhuang, Guido Zuccon
  - **TLDR**: We propose a novel method for improving the performance of passage retrieval and ranking methods that can adapt to keyword mismatch caused by typos in queries.

- [From Alignment to Assignment: Frustratingly Simple Unsupervised Entity Alignment](https://aclanthology.org/2021.emnlp-main.226)
  - Xin Mao, Wenting Wang, Yuanbin Wu, Man Lan
  - **TLDR**: We propose a frustratingly simple but effective unsupervised entity alignment method without neural networks.

- [Simple and Effective Unsupervised Redundancy Elimination to Compress Dense Vectors for Passage Retrieval](https://aclanthology.org/2021.emnlp-main.227)
  - Xueguang Ma, Minghan Li, Kai Sun, Ji Xin, Jimmy Lin
  - **TLDR**: We propose a simple unsupervised compression pipeline that consists of principal component analysis (PCA), product quantization, and hybrid search.

- [Relation Extraction with Word Graphs from N-grams](https://aclanthology.org/2021.emnlp-main.228)
  - Han Qin, Yuanhe Tian, Yan Song
  - **TLDR**: We propose attentive graph convolutional networks for relation extraction, which use lexicon-based contextual information to improve neural relation extraction.

- [A Bayesian Framework for Information-Theoretic Probing](https://aclanthology.org/2021.emnlp-main.229)
  - Tiago Pimentel, Ryan Cotterell
  - **TLDR**: We propose a new framework to measure and measure Bayesian mutual information, which analyses information from the perspective of Bayesian agents—allowing for more intuitive findings in scenarios with finite data.

- [Masked Language Modeling and the Distributional Hypothesis: Order Word Matters Pre-training for Little](https://aclanthology.org/2021.emnlp-main.230)
  - Koustuv Sinha, Robin Jia, Dieuwke Hupkes, Joelle Pineau, Adina Williams, Douwe Kiela
  - **TLDR**: We show that purely distributional information largely explains the success of masked language model pre-training, and underscore the importance of curating challenging evaluation datasets that require deeper linguistic knowledge.

- [What’s Hidden in a One-layer Randomly Weighted Transformer?](https://aclanthology.org/2021.emnlp-main.231)
  - Sheng Shen, Zhewei Yao, Douwe Kiela, Kurt Keutzer, Michael Mahoney
  - **TLDR**: We show that, hidden within one-layer randomly weighted neural networks, there exist subnetworks that can achieve impressive performance, without ever modifying the weight initializations, on machine translation tasks.

- [Rethinking Denoised Auto-Encoding in Language Pre-Training](https://aclanthology.org/2021.emnlp-main.232)
  - Fuli Luo, Pengcheng Yang, Shicheng Li, Xuancheng Ren, Xu Sun, Songfang Huang, Fei Huang
  - **TLDR**: We propose a novel method for learning noise invariant sequence representations that are covariant with the noise of pre-trained neural networks.

- [Lifelong Explainer for Lifelong Learners](https://aclanthology.org/2021.emnlp-main.233)
  - Xuelin Situ, Sameen Maruf, Ingrid Zukerman, Cecile Paris, Gholamreza Haffari
  - **TLDR**: We propose a novel Lifelong Explanation (LLEA) approach that continuously trains a student explainer under the supervision of a teacher on different tasks undertaken in the lifetime learning domain.

- [Linguistic Dependencies and Statistical Dependence](https://aclanthology.org/2021.emnlp-main.234)
  - Jacob Louis Hoover, Wenyu Du, Alessandro Sordoni, Timothy J. O’Donnell
  - **TLDR**: We provide an extensive analysis of the relationship between linguistic dependencies and statistical dependence between words.

- [Modeling Human Sentence Processing with Left-Corner Recurrent Neural Network Grammars](https://aclanthology.org/2021.emnlp-main.235)
  - Ryo Yoshida, Hiroshi Noji, Yohei Oseki
  - **TLDR**: We investigated whether hierarchical structures make language models more human-like, and if so, which parsing strategy is most cognitively plausible.

- [A Simple and Effective Positional Encoding for Transformers](https://aclanthology.org/2021.emnlp-main.236)
  - Pu-Chin Chen, Henry Tsai, Srinadh Bhojanapalli, Hyung Won Chung, Yin-Wen Chang, Chun-Sung Ferng
  - **TLDR**: We propose Decoupled Positional Attention for Transformers (DIET), a simple yet effective mechanism to encode position and segment information into the Transformer models.

- [Explore Better Relative Position Embeddings from Encoding Perspective for Transformer Models](https://aclanthology.org/2021.emnlp-main.237)
  - Anlin Qu, Jianwei Niu, Shasha Mo
  - **TLDR**: We propose two novel RPEs for Transformer models that improve the perception ability at medium and long relative positions.

- [Adversarial Mixing Policy for Relaxing Locally Linear Constraints in Mixup](https://aclanthology.org/2021.emnlp-main.238)
  - Guang Liu, Yuzhao Mao, Huang Hailong, Gao Weiguo, Li Xuan
  - **TLDR**: We propose the Adversarial Mixing Policy (AMP), a novel adversarial mixing policy for deep classification models.

- [Is this the end of the gold standard? A straightforward reference-less grammatical error correction metric](https://aclanthology.org/2021.emnlp-main.239)
  - Md Asadul Islam, Enrico Magnani
  - **TLDR**: We propose a reference-less GEC evaluation system that is strongly correlated with human judgement, solves the issues related to the use of a reference, and does not need another annotated dataset for fine-tuning.

- [Augmenting BERT-style Models with Predictive Coding to Improve Discourse-level Representations](https://aclanthology.org/2021.emnlp-main.240)
  - Vladimir Araujo, Andrés Villa, Marcelo Mendoza, Marie-Francine Moens, Alvaro Soto
  - **TLDR**: We propose to use ideas from predictive coding theory to augment BERT-style language models with a mechanism that allows them to learn suitable discourse-level representations.

- [Backdoor Attacks on Pre-trained Models by Layerwise Weight Poisoning](https://aclanthology.org/2021.emnlp-main.241)
  - Linyang Li, Demin Song, Xiaonan Li, Jiehang Zeng, Ruotian Ma, Xipeng Qiu
  - **TLDR**: Weird News Photos:

- [GAML-BERT: Improving BERT Early Exiting by Gradient Aligned Mutual Learning](https://aclanthology.org/2021.emnlp-main.242)
  - Wei Zhu, Xiaoling Wang, Yuan Ni, Guotong Xie
  - **TLDR**: We propose a novel framework for improving the early exiting of BERT.

- [The Power of Scale for Parameter-Efficient Prompt Tuning](https://aclanthology.org/2021.emnlp-main.243)
  - Brian Lester, Rami Al-Rfou, Noah Constant
  - **TLDR**: We propose a simple yet effective mechanism for learning soft prompts to condition frozen language models to perform specific downstream tasks.

- [Scalable Font Reconstruction with Dual Latent Manifolds](https://aclanthology.org/2021.emnlp-main.244)
  - Nikita Srivatsan, Si Wu, Jonathan Barron, Taylor Berg-Kirkpatrick
  - **TLDR**: We propose a deep generative model that performs typography analysis and font reconstruction by learning disentangled manifolds of both font style and character shape.

- [Neuro-Symbolic Approaches for Text-Based Policy Learning](https://aclanthology.org/2021.emnlp-main.245)
  - Subhajit Chaudhury, Prithviraj Sen, Masaki Ono, Daiki Kimura, Michiaki Tatsubori, Asim Munawar
  - **TLDR**: We present SymboLic Action policy for Textual Environments (SLATE), that learns interpretable action policy rules from symbolic abstractions of textual observations for improved generalization.

- [Layer-wise Model Pruning based on Mutual Information](https://aclanthology.org/2021.emnlp-main.246)
  - Chun Fan, Jiwei Li, Tianwei Zhang, Xiang Ao, Fei Wu, Yuxian Meng, Xiaofei Sun
  - **TLDR**: We propose MI-based layer-wise pruning, a method for deep multi-layer neural networks that prunes each layer by propagating the effect of global signals through layers, leading to better performances at the same sparsity level.

- [Hierarchical Heterogeneous Graph Representation Learning for Short Text Classification](https://aclanthology.org/2021.emnlp-main.247)
  - Yaqing Wang, Song Wang, Quanming Yao, Dejing Dou
  - **TLDR**: We propose a new graph neural network based method for short text classification which outperforms existing GNN-based methods.

- [kFolden: k-Fold Ensemble for Out-Of-Distribution Detection](https://aclanthology.org/2021.emnlp-main.248)
  - Xiaoya Li, Jiwei Li, Xiaofei Sun, Chun Fan, Tianwei Zhang, Fei Wu, Yuxian Meng, Jun Zhang
  - **TLDR**: We propose a simple yet effective framework for out-of-distribution detection in NLP.

- [Frustratingly Simple Pretraining Alternatives to Masked Language Modeling](https://aclanthology.org/2021.emnlp-main.249)
  - Atsuki Yamaguchi, George Chrysostomou, Katerina Margatina, Nikolaos Aletras
  - **TLDR**: We propose five simple pretraining objectives based on token-level classification tasks as replacements of MLM.

- [HRKD: Hierarchical Relational Knowledge Distillation for Cross-domain Language Model Compression](https://aclanthology.org/2021.emnlp-main.250)
  - Chenhe Dong, Yaliang Li, Ying Shen, Minghui Qiu
  - **TLDR**: We propose a hierarchical relational knowledge distillation method for pre-trained language models that captures both hierarchical and domain relational information.

- [Searching for an Effective Defender: Benchmarking Defense against Adversarial Word Substitution](https://aclanthology.org/2021.emnlp-main.251)
  - Zongyi Li, Jianhan Xu, Jiehang Zeng, Linyang Li, Xiaoqing Zheng, Qi Zhang, Kai-Wei Chang, Cho-Jui Hsieh
  - **TLDR**: We propose a novel method to defend against adversarial word-substitution attacks for neural NLP models.

- [Re-embedding Difficult Samples via Mutual Information Constrained Semantically Oversampling for Imbalanced Text Classification](https://aclanthology.org/2021.emnlp-main.252)
  - Jiachen Tian, Shizhan Chen, Xiaowang Zhang, Zhiyong Feng, Deyi Xiong, Shaojuan Wu, Chunliu Dou
  - **TLDR**: We propose a Mutual Information constrained Semantically Oversampling framework that can generate anchor instances to help the backbone network determine the re-embedding position of a non-overlapping representation for each difficult sample.

- [Beyond Text: Incorporating Metadata and Label Structure for Multi-Label Document Classification using Heterogeneous Graphs](https://aclanthology.org/2021.emnlp-main.253)
  - Chenchen Ye, Linhai Zhang, Yulan He, Deyu Zhou, Jie Wu
  - **TLDR**: We propose a novel neural network based approach for multi-label document classification, in which two heterogeneous graphs are constructed and learned using heterogeneous graph transformers.

- [Natural Language Processing Meets Quantum Physics: A Survey and Categorization](https://aclanthology.org/2021.emnlp-main.254)
  - Sixuan Wu, Jian Li, Peng Zhang, Yue Zhang
  - **TLDR**: We review the literature on quantum NLP and quantum physics, and provide a detailed analysis of the promising and promising methods.

- [MetaTS: Meta Teacher-Student Network for Multilingual Sequence Labeling with Minimal Supervision](https://aclanthology.org/2021.emnlp-main.255)
  - Zheng Li, Danqing Zhang, Tianyu Cao, Ying Wei, Yiwei Song, Bing Yin
  - **TLDR**: Meta Teacher-Student Network for multilingual sequence labeling with minimal supervision.

- [Neural Machine Translation with Heterogeneous Topic Knowledge Embeddings](https://aclanthology.org/2021.emnlp-main.256)
  - Weixuan Wang, Wei Peng, Meng Zhang, Qun Liu
  - **TLDR**: We propose heterogeneous ways of embedding topic information at the sentence level into an NMT model to improve translation performance.

- [Allocating Large Vocabulary Capacity for Cross-Lingual Language Model Pre-Training](https://aclanthology.org/2021.emnlp-main.257)
  - Bo Zheng, Li Dong, Shaohan Huang, Saksham Singhal, Wanxiang Che, Ting Liu, Xia Song, Furu Wei
  - **TLDR**: We propose a new algorithm VoCap to determine the desired vocabulary capacity of each language and use it to accelerate cross-lingual language model pre-training.

- [Recurrent Attention for Neural Machine Translation](https://aclanthology.org/2021.emnlp-main.258)
  - Jiali Zeng, Shuangzhi Wu, Yongjing Yin, Yufan Jiang, Mu Li
  - **TLDR**: We propose a novel substitute mechanism for self-attention in Transformer models and show that it is competitive and outperforms Transformer counterpart in certain scenarios.

- [Learning from Multiple Noisy Augmented Data Sets for Better Cross-Lingual Spoken Language Understanding](https://aclanthology.org/2021.emnlp-main.259)
  - Yingmei Guo, Linjun Shou, Jian Pei, Ming Gong, Mingxing Xu, Zhiyong Wu, Daxin Jiang
  - **TLDR**: We propose a novel method for denoising training data in low-resource languages by reducing noise in augmented data.

- [Enlivening Redundant Heads in Multi-head Self-attention for Machine Translation](https://aclanthology.org/2021.emnlp-main.260)
  - Tianfu Zhang, Heyan Huang, Chong Feng, Longbing Cao
  - **TLDR**: We propose a redundant head enlivening (RHE) method to precisely identify redundant heads, and then vitalize their potential by learning syntactic relations and prior knowledge in the text without sacrificing the roles of important heads.

- [Unsupervised Neural Machine Translation with Universal Grammar](https://aclanthology.org/2021.emnlp-main.261)
  - Zuchao Li, Masao Utiyama, Eiichiro Sumita, Hai Zhao
  - **TLDR**: We propose a new grammar-based language parallel signal for unsupervised machine translation that can be used to enhance the training of unsupervisional machine translation models.

- [Encouraging Lexical Translation Consistency for Document-Level Neural Machine Translation](https://aclanthology.org/2021.emnlp-main.262)
  - Xinglin Lyu, Junhui Li, Zhengxian Gong, Min Zhang
  - **TLDR**: We propose a novel approach to improve lexical consistency in document-level neural machine translation by encouraging lexical translation consistency.

- [Improving Neural Machine Translation by Bidirectional Training](https://aclanthology.org/2021.emnlp-main.263)
  - Liang Ding, Di Wu, Dacheng Tao
  - **TLDR**: We present a simple and effective pretraining strategy – bidirectional training (BiT) for neural machine translation.

- [Scheduled Sampling Based on Decoding Steps for Neural Machine Translation](https://aclanthology.org/2021.emnlp-main.264)
  - Yijin Liu, Fandong Meng, Yufeng Chen, Jinan Xu, Jie Zhou
  - **TLDR**: We propose a new method for scheduled sampling based on decoding steps, which improves the gap between training and inference.

- [Learning to Rewrite for Non-Autoregressive Neural Machine Translation](https://aclanthology.org/2021.emnlp-main.265)
  - Xinwei Geng, Xiaocheng Feng, Bing Qin
  - **TLDR**: We propose a novel architecture for autoregressive neural machine translation that learns to rewrite the erroneous translation pieces.

- [SHAPE: Shifted Absolute Position Embedding for Transformers](https://aclanthology.org/2021.emnlp-main.266)
  - Shun Kiyono, Sosuke Kobayashi, Jun Suzuki, Kentaro Inui
  - **TLDR**: We propose a new position embedding algorithm that achieves shift invariance and generalization to unseen data.

- [Self-Supervised Quality Estimation for Machine Translation](https://aclanthology.org/2021.emnlp-main.267)
  - Yuanhang Zheng, Zhixing Tan, Meng Zhang, Mieradilijiang Maimaiti, Huanbo Luan, Maosong Sun, Qun Liu, Yang Liu
  - **TLDR**: We propose a self-supervised method for both sentence- and word-level QE, which performs quality estimation by recovering the masked target words.

- [Generalised Unsupervised Domain Adaptation of Neural Machine Translation with Cross-Lingual Data Selection](https://aclanthology.org/2021.emnlp-main.268)
  - Thuy-Trang Vu, Xuanli He, Dinh Phung, Gholamreza Haffari
  - **TLDR**: We propose a cross-lingual data selection method for neural machine translation that enables the transferability of the domain classifier between the languages in a zero-shot manner.

- [STANKER: Stacking Network based on Level-grained Attention-masked BERT for Rumor Detection on Social Media](https://aclanthology.org/2021.emnlp-main.269)
  - Dongning Rao, Xin Miao, Zhihua Jiang, Ran Li
  - **TLDR**: We propose a new ensemble for rumor detection on social media with comments and propose a novel method for masking co-attention between posts and comments on lower-layers.

- [ActiveEA: Active Learning for Neural Entity Alignment](https://aclanthology.org/2021.emnlp-main.270)
  - Bing Liu, Harrisen Scells, Guido Zuccon, Wen Hua, Genghong Zhao
  - **TLDR**: We propose a novel Active Learning framework for neural entity alignment and propose a structure-aware uncertainty sampling strategy for neural EA.

- [Cost-effective End-to-end Information Extraction for Semi-structured Document Images](https://aclanthology.org/2021.emnlp-main.271)
  - Wonseok Hwang, Hyunji Lee, Jinyeong Yim, Geewook Kim, Minjoon Seo
  - **TLDR**: We present a novel sequence generation approach for document information extraction that can be used to improve the performance of existing pipeline-based systems.

- [Improving Math Word Problems with Pre-trained Knowledge and Hierarchical Reasoning](https://aclanthology.org/2021.emnlp-main.272)
  - Weijiang Yu, Yingpeng Wen, Fudan Zheng, Nong Xiao
  - **TLDR**: We propose a new algorithm for word problem solving that uses contextual information to build hierarchical reasoning like the human being for mining the contextual structure between words and sentences.

- [GraphMR: Graph Neural Network for Mathematical Reasoning](https://aclanthology.org/2021.emnlp-main.273)
  - Weijie Feng, Binbin Liu, Dongpeng Xu, Qilong Zheng, Yun Xu
  - **TLDR**: We propose a graph-to-sequence neural network GraphMR, which can effectively learn the hierarchical information of graphs inputs to solve mathematics and speculate answers.

- [What Changes Can Large-scale Language Models Bring? Intensive Study on HyperCLOVA: Billions-scale Korean Generative Pretrained Transformers](https://aclanthology.org/2021.emnlp-main.274)
  - Boseop Kim, HyoungSeok Kim, Sang-Woo Lee, Gichang Lee, Donghyun Kwak, Jeon Dong Hyeon, Sunghyun Park, Sungju Kim, Seonhoon Kim, Dongpil Seo, Heungsub Lee, Minyoung Jeong, Sungjae Lee, Minsub Kim, Suk Hyun Ko, Seokhun Kim, Taeyong Park, Jinuk Kim, Soyoung Kang, Na-Hyeon Ryu, Kang Min Yoo, Minsuk Chang, Soobin Suh, Sookyo In, Jinseong Park, Kyungduk Kim, Hiun Kim, Jisu Jeong, Yong Goo Yeo, Donghoon Ham, Dongju Park, Min Young Lee, Jaewook Kang, Inho Kang, Jung-Woo Ha, Woomyoung Park, Nako Sung
  - **TLDR**: We present a Korean variant of 82B GPT-3 trained on a Korean-centric corpus of 560B tokens and show state-of-the-art in-context zero-shot and few-shot learning performances on various downstream tasks in Korean.

- [APIRecX: Cross-Library API Recommendation via Pre-Trained Language Model](https://aclanthology.org/2021.emnlp-main.275)
  - Yuning Kang, Zan Wang, Hongyu Zhang, Junjie Chen, Hanmo You
  - **TLDR**: We propose APIRecX, the first cross-library API recommendation approach, which uses BPE to split each API call in each API sequence and pre-trains a GPT based language model.

- [GMH: A General Multi-hop Reasoning Model for KG Completion](https://aclanthology.org/2021.emnlp-main.276)
  - Yao Zhang, Hongru Liang, Adam Jatowt, Wenqiang Lei, Xin Wei, Ning Jiang, Zhenglu Yang
  - **TLDR**: We propose a general multi-hop reasoning model which solves the issues of where to go, and when to stop.

- [BPM_MT: Enhanced Backchannel Prediction Model using Multi-Task Learning](https://aclanthology.org/2021.emnlp-main.277)
  - Jin Yea Jang, San Kim, Minyoung Jung, Saim Shin, Gahgene Gweon
  - **TLDR**: We present a BC prediction model with multitask learning and show significant performance improvement in four BC categories.

- [Graphine: A Dataset for Graph-aware Terminology Definition Generation](https://aclanthology.org/2021.emnlp-main.278)
  - Zequn Liu, Shukai Wang, Yiyang Gu, Ruiyi Zhang, Ming Zhang, Sheng Wang
  - **TLDR**: Graph-aware graph-aware definition generation for biomedical terminology definition.

- [Leveraging Order-Free Tag Relations for Context-Aware Recommendation](https://aclanthology.org/2021.emnlp-main.279)
  - Junmo Kang, Jeonghwan Kim, Suwon Shin, Sung-Hyon Myaeng
  - **TLDR**: We propose a sequence-oblivious generation method for tag recommendation, in which the next tag to be generated is independent of the order of the generated tags and the order in training data.

- [End-to-End Conversational Search for Online Shopping with Utterance Transfer](https://aclanthology.org/2021.emnlp-main.280)
  - Liqiang Xiao, Jun Ma, Xin Luna Dong, Pascual Martínez-Gómez, Nasser Zalmout, Wei Chen, Tong Zhao, Hao He, Yaohui Jin
  - **TLDR**: We propose a new conversational search system that combines the dialog system with search to retrieve online shopping products.

- [Self-Supervised Curriculum Learning for Spelling Error Correction](https://aclanthology.org/2021.emnlp-main.281)
  - Zifa Gan, Hongfei Xu, Hongying Zan
  - **TLDR**: We propose a new method for improving the performance of the state-of-the-art SEC method with Curriculum Learning, and show that it improves the model training and improves the CL measurement.

- [Fix-Filter-Fix: Intuitively Connect Any Models for Effective Bug Fixing](https://aclanthology.org/2021.emnlp-main.282)
  - Haiwen Hong, Jingfeng Zhang, Yin Zhang, Yao Wan, Yulei Sui
  - **TLDR**: We propose a general framework for automatically bug fixing in neural machine translation based on the theory of Fˆ3 and a general filter mechanism for bug fixing.

- [Neuro-Symbolic Reinforcement Learning with First-Order Logic](https://aclanthology.org/2021.emnlp-main.283)
  - Daiki Kimura, Masaki Ono, Subhajit Chaudhury, Ryosuke Kohita, Akifumi Wachi, Don Joven Agravante, Michiaki Tatsubori, Asim Munawar, Alexander Gray
  - **TLDR**: We propose a novel RL method for text-based games with a recent neuro-symbolic framework called Logical Neural Network, which can learn symbolic and interpretable rules in their differentiable network.

- [Biomedical Concept Normalization by Leveraging Hypernyms](https://aclanthology.org/2021.emnlp-main.284)
  - Cheng Yan, Yuanzhe Zhang, Kang Liu, Jun Zhao, Yafei Shi, Shengping Liu
  - **TLDR**: We propose a novel framework for biomedical concept normalization that employs biomedical concept hypernyms to facilitate BCN.

- [Leveraging Capsule Routing to Associate Knowledge with Medical Literature Hierarchically](https://aclanthology.org/2021.emnlp-main.285)
  - Xin Liu, Qingcai Chen, Junying Chen, Wenxiu Zhou, Tingyu Liu, Xinlan Yang, Weihua Peng
  - **TLDR**: We propose a novel method to associate knowledge with medical literature hierarchically using capsule routing and dynamic routing.

- [Label-Enhanced Hierarchical Contextualized Representation for Sequential Metaphor Identification](https://aclanthology.org/2021.emnlp-main.286)
  - Shuqun Li, Liang Yang, Weidong He, Shiqi Zhang, Jingjie Zeng, Hongfei Lin
  - **TLDR**: We propose a model augmented with hierarchical contextualized representation to extract more information from both sentence-level and discourse-level.

- [SpellBERT: A Lightweight Pretrained Model for Chinese Spelling Check](https://aclanthology.org/2021.emnlp-main.287)
  - Tuo Ji, Hang Yan, Xipeng Qiu
  - **TLDR**: We propose a graph neural network for Chinese spelling check that captures both radical and pinyin information as visual and phonetic features.

- [Automated Generation of Accurate & Fluent Medical X-ray Reports](https://aclanthology.org/2021.emnlp-main.288)
  - Hoang Nguyen, Dong Nie, Taivanbat Badamdorj, Yujie Liu, Yingying Zhu, Jason Truong, Li Cheng
  - **TLDR**: We present a novel and efficient method for generating medical reports from chest X-ray image inputs that are fluent and clinically accurate.

- [Enhancing Document Ranking with Task-adaptive Training and Segmented Token Recovery Mechanism](https://aclanthology.org/2021.emnlp-main.289)
  - Xingwu Sun, Yanling Cui, Hongyin Tang, Fuzheng Zhang, Beihong Jin, Shi Wang
  - **TLDR**: We propose a new ranking model DR-BERT, which improves the Document Retrieval (DR) task by a task-adaptive training process and a Segmented Token Recovery Mechanism (STRM).

- [Abstract, Rationale, Stance: A Joint Model for Scientific Claim Verification](https://aclanthology.org/2021.emnlp-main.290)
  - Zhiwei Zhang, Jiyi Li, Fumiyo Fukumoto, Yanming Ye
  - **TLDR**: We propose a new pipeline model for scientific claim verification that combines sentence attention scores of abstract retrieval, rationale selection and rational selection with claim information.

- [A Fine-Grained Domain Adaption Model for Joint Word Segmentation and POS Tagging](https://aclanthology.org/2021.emnlp-main.291)
  - Peijie Jiang, Dingkun Long, Yueheng Sun, Meishan Zhang, Guangwei Xu, Pengjun Xie
  - **TLDR**: We present a novel domain-mixed representation learning model for domain adaption and propose a novel method to construct a pseudo target domain corpus based on fine-grained subdomains incrementally.

- [Answering Open-Domain Questions of Varying Reasoning Steps from Text](https://aclanthology.org/2021.emnlp-main.292)
  - Peng Qi, Haejun Lee, Tg Sido, Christopher Manning
  - **TLDR**: We develop a unified system to answer directly from text open-domain questions that may require a varying number of retrieval steps.

- [Adaptive Information Seeking for Open-Domain Question Answering](https://aclanthology.org/2021.emnlp-main.293)
  - Yunchang Zhu, Liang Pang, Yanyan Lan, Huawei Shen, Xueqi Cheng
  - **TLDR**: A novel adaptive information-seeking strategy for open-domain question answering.

- [Mapping probability word problems to executable representations](https://aclanthology.org/2021.emnlp-main.294)
  - Simon Suster, Pieter Fivez, Pietro Totis, Angelika Kimmig, Jesse Davis, Luc de Raedt, Walter Daelemans
  - **TLDR**: We present a two-step approach to solving probability word problems using sequence-to-sequence models and transfer learning.

- [Enhancing Multiple-choice Machine Reading Comprehension by Punishing Illogical Interpretations](https://aclanthology.org/2021.emnlp-main.295)
  - Yiming Ju, Yuanzhe Zhang, Zhixing Tian, Kang Liu, Xiaohuan Cao, Wenting Zhao, Jinlong Li, Jun Zhao
  - **TLDR**: We propose a new method for improving machine reading comprehension by punishing the illogical attributions of paragraphs in multiple-choice MRC.

- [Large-Scale Relation Learning for Question Answering over Knowledge Bases with Pre-trained Language Models](https://aclanthology.org/2021.emnlp-main.296)
  - Yuanmeng Yan, Rumei Li, Sirui Wang, Hongzhi Zhang, Zan Daoguang, Fuzheng Zhang, Wei Wu, Weiran Xu
  - **TLDR**: We propose relation-augmented training for BERT-based KBQA, a method for question answering over knowledge bases that learns to align natural language expressions to the relations in the knowledge base and reason over the missing connections in the KB.

- [Phrase Retrieval Learns Passage Retrieval, Too](https://aclanthology.org/2021.emnlp-main.297)
  - Jinhyuk Lee, Alexander Wettig, Danqi Chen
  - **TLDR**: We show that phrase retrieval can be used as a coarse-level retrieval unit for coarse-scale document retrieval and provide a theoretical and practical analysis of its use in multi-granularity retrieval.

- [Neural Natural Logic Inference for Interpretable Question Answering](https://aclanthology.org/2021.emnlp-main.298)
  - Jihao Shi, Xiao Ding, Li Du, Ting Liu, Bing Qin
  - **TLDR**: We propose a neural-symbolic QA approach that integrates natural logic reasoning within deep learning architectures, towards developing effective and yet explainable question answering models.

- [Smoothing Dialogue States for Open Conversational Machine Reading](https://aclanthology.org/2021.emnlp-main.299)
  - Zhuosheng Zhang, Siru Ouyang, Hai Zhao, Masao Utiyama, Eiichiro Sumita
  - **TLDR**: We propose a novel gating strategy for conversational machine reading by smoothing the two dialogue states in only one decoder and bridge decision making and question generation to provide a richer dialogue state reference.

- [FinQA: A Dataset of Numerical Reasoning over Financial Data](https://aclanthology.org/2021.emnlp-main.300)
  - Zhiyu Chen, Wenhu Chen, Charese Smiley, Sameena Shah, Iana Borova, Dylan Langdon, Reema Moussa, Matt Beane, Ting-Hao Huang, Bryan Routledge, William Yang Wang
  - **TLDR**: We propose a large-scale dataset for financial data analysis and answer deep questions over financial data.

- [FiD-Ex: Improving Sequence-to-Sequence Models for Extractive Rationale Generation](https://aclanthology.org/2021.emnlp-main.301)
  - Kushal Lakhotia, Bhargavi Paranjape, Asish Ghoshal, Scott Yih, Yashar Mehdad, Srini Iyer
  - **TLDR**: We present FiD-Ex, a novel sequence to sequence model for natural language explanations of model predictions.

- [RockNER: A Simple Method to Create Adversarial Examples for Evaluating the Robustness of Named Entity Recognition Models](https://aclanthology.org/2021.emnlp-main.302)
  - Bill Yuchen Lin, Wenyang Gao, Jun Yan, Ryan Moreno, Xiang Ren
  - **TLDR**: We propose RockNER, a simple yet effective method to audit the robustness of named entity recognition (NER) models.

- [Diagnosing the First-Order Logical Reasoning Ability Through LogicNLI](https://aclanthology.org/2021.emnlp-main.303)
  - Jidong Tian, Yitian Li, Wenqing Chen, Liqiang Xiao, Hao He, Yaohui Jin
  - **TLDR**: We propose a diagnostic method for first-order logic (FOL) reasoning with a new proposed benchmark, LogicNLI, which can be used to diagnose LMs from four perspectives: accuracy, robustness, generalization, and interpretability.

- [Constructing a Psychometric Testbed for Fair Natural Language Processing](https://aclanthology.org/2021.emnlp-main.304)
  - Ahmed Abbasi, David Dobolyi, John P. Lalor, Richard G. Netemeyer, Kendall Smith, Yi Yang
  - **TLDR**: We present a corpus of user-generated text for psychometric natural language processing and provide a testbed for measuring bias and fairness of text classification methods.

- [COUGH: A Challenge Dataset and Models for COVID-19 FAQ Retrieval](https://aclanthology.org/2021.emnlp-main.305)
  - Xinliang Frederick Zhang, Heming Sun, Xiang Yue, Simon Lin, Huan Sun
  - **TLDR**: We present a large, challenging dataset, COUGH, for COVID-19 FAQ retrieval.

- [Chinese WPLC: A Chinese Dataset for Evaluating Pretrained Language Models on Word Prediction Given Long-Range Context](https://aclanthology.org/2021.emnlp-main.306)
  - Huibin Ge, Chenxi Sun, Deyi Xiong, Qun Liu
  - **TLDR**: We present a Chinese dataset for evaluating pretrained language models on Word Prediction given Long-term Context.

- [WinoLogic: A Zero-Shot Logic-based Diagnostic Dataset for Winograd Schema Challenge](https://aclanthology.org/2021.emnlp-main.307)
  - Weinan He, Canming Huang, Yongmei Liu, Xiaodan Zhu
  - **TLDR**: We propose a new dataset for evaluating neural language models on commonsense knowledge.

- [Pseudo Zero Pronoun Resolution Improves Zero Anaphora Resolution](https://aclanthology.org/2021.emnlp-main.308)
  - Ryuto Konno, Shun Kiyono, Yuichiroh Matsubayashi, Hiroki Ouchi, Kentaro Inui
  - **TLDR**: We propose two new pretraining tasks for masked language models and a new finetuning method for zero anaphora resolution.

- [Aligning Cross-lingual Sentence Representations with Dual Momentum Contrast](https://aclanthology.org/2021.emnlp-main.309)
  - Liang Wang, Wei Zhao, Jingming Liu
  - **TLDR**: We propose to align sentence representations from different languages into a unified embedding space, where semantic similarities (both cross-lingual and monolingual) can be computed with a simple dot product.

- [Total Recall: a Customized Continual Learning Method for Neural Semantic Parsers](https://aclanthology.org/2021.emnlp-main.310)
  - Zhuang Li, Lizhen Qu, Gholamreza Haffari
  - **TLDR**: We propose TotalRecall, a continual learning method for neural semantic parsers that improves generalization capability and improves performance over SOTA continual learning algorithms.

- [Exophoric Pronoun Resolution in Dialogues with Topic Regularization](https://aclanthology.org/2021.emnlp-main.311)
  - Xintong Yu, Hongming Zhang, Yangqiu Song, Changshui Zhang, Kun Xu, Dong Yu
  - **TLDR**: We propose to solve the out-of-text PCR problem of exophoric pronouns by using the local context and global topics of dialogues to solve it.

- [Context-Aware Interaction Network for Question Matching](https://aclanthology.org/2021.emnlp-main.312)
  - Zhe Hu, Zuohui Fu, Yu Yin, Gerard de Melo
  - **TLDR**: We propose a context-aware interaction network (COIN) to properly align two sequences and infer their semantic relationship.

- [TEMP: Taxonomy Expansion with Dynamic Margin Loss through Taxonomy-Paths](https://aclanthology.org/2021.emnlp-main.313)
  - Zichen Liu, Hongyuan Xu, Yanlong Wen, Ning Jiang, HaiYing Wu, Xiaojie Yuan
  - **TLDR**: We propose TEMP, a self-supervised taxonomy expansion method, which predicts the position of new concepts by ranking the generated taxonomy-paths.

- [A Graph-Based Neural Model for End-to-End Frame Semantic Parsing](https://aclanthology.org/2021.emnlp-main.314)
  - ZhiChao Lin, Yueheng Sun, Meishan Zhang
  - **TLDR**: We propose an end-to-end neural model for frame semantic parsing which is highly competitive with pipeline models.

- [Virtual Data Augmentation: A Robust and General Framework for Fine-tuning Pre-trained Models](https://aclanthology.org/2021.emnlp-main.315)
  - Kun Zhou, Wayne Xin Zhao, Sirui Wang, Fuzheng Zhang, Wei Wu, Ji-Rong Wen
  - **TLDR**: We present a general framework for robustly fine-tuning pre-trained language models and show that it improves the robustness of PLMs and alleviates the performance degradation under adversarial attacks.

- [CATE: A Contrastive Pre-trained Model for Metaphor Detection with Semi-supervised Learning](https://aclanthology.org/2021.emnlp-main.316)
  - Zhenxi Lin, Qianli Ma, Jiangyue Yan, Jieyu Chen
  - **TLDR**: We propose a new method for metaphor detection with semi-supervised learning based on linguistic theories.

- [To be Closer: Learning to Link up Aspects with Opinions](https://aclanthology.org/2021.emnlp-main.317)
  - Yuxiang Zhou, Lejian Liao, Yang Gao, Zhanming Jie, Wei Lu
  - **TLDR**: We propose a new aspect-centric tree structure for aspect-based sentiment analysis, which is expected to be closer to the standard dependency parse tree than the standard one.

- [Seeking Common but Distinguishing Difference, A Joint Aspect-based Sentiment Analysis Model](https://aclanthology.org/2021.emnlp-main.318)
  - Hongjiang Jing, Zuchao Li, Hai Zhao, Shu Jiang
  - **TLDR**: We propose a new joint ABSA model which not only enjoys the benefits of encoder sharing but also focuses on the difference to improve the effectiveness of the model.

- [Argument Pair Extraction with Mutual Guidance and Inter-sentence Relation Graph](https://aclanthology.org/2021.emnlp-main.319)
  - Jianzhu Bao, Bin Liang, Jingyi Sun, Yice Zhang, Min Yang, Ruifeng Xu
  - **TLDR**: We propose a mutual guidance framework for argument pair extraction that can help to identify interactive argument pairs from two passages of a discussion.

- [Emotion Inference in Multi-Turn Conversations with Addressee-Aware Module and Ensemble Strategy](https://aclanthology.org/2021.emnlp-main.320)
  - Dayu Li, Xiaodan Zhu, Yang Li, Suge Wang, Deyu Li, Jian Liao, Jianxing Zheng
  - **TLDR**: We propose a novel module for emotion inference in multi-turn conversations by modeling the propagation of emotional states among participants in the conversation history, and propose an addressee-aware module to automatically learn whether the participant keeps the historical emotional state or is affected by others in the next upcoming turn.

- [Improving Federated Learning for Aspect-based Sentiment Analysis via Topic Memories](https://aclanthology.org/2021.emnlp-main.321)
  - Han Qin, Guimin Chen, Yuanhe Tian, Yan Song
  - **TLDR**: We propose a novel approach to address the data inaccessibility problem in sentiment analysis by incorporating topic memory for localized prediction.

- [Comparative Opinion Quintuple Extraction from Product Reviews](https://aclanthology.org/2021.emnlp-main.322)
  - Ziheng Liu, Rui Xia, Jianfei Yu
  - **TLDR**: We propose a new comparative opinion mining task for which we extract all comparative opinion quintuples from product reviews and extract the corresponding comparative opinion tuples.

- [CTAL: Pre-training Cross-modal Transformer for Audio-and-Language Representations](https://aclanthology.org/2021.emnlp-main.323)
  - Hang Li, Wenbiao Ding, Yu Kang, Tianqiao Liu, Zhongqin Wu, Zitao Liu
  - **TLDR**: We present a novel cross-modal fusion mechanism for audio-and-language task-specific predictive models.

- [Relation-aware Video Reading Comprehension for Temporal Language Grounding](https://aclanthology.org/2021.emnlp-main.324)
  - Jialin Gao, Xin Sun, Mengmeng Xu, Xi Zhou, Bernard Ghanem
  - **TLDR**: We propose a Relation-aware Network for temporal language grounding in videos.

- [Mutual-Learning Improves End-to-End Speech Translation](https://aclanthology.org/2021.emnlp-main.325)
  - Jiawei Zhao, Wei Luo, Boxing Chen, Andrew Gilman
  - **TLDR**: We propose a trainable mutual-learning scenario for end-to-end speech translation, where the MT and the ST models are considered as peers, rather than teacher/student.

- [Vision Guided Generative Pre-trained Language Models for Multimodal Abstractive Summarization](https://aclanthology.org/2021.emnlp-main.326)
  - Tiezheng Yu, Wenliang Dai, Zihan Liu, Pascale Fung
  - **TLDR**: We present a simple yet effective method to construct vision guided (VG) GPLMs for the MAS task using attention-based add-on layers to incorporate visual information while maintaining their original text generation ability.

- [Natural Language Video Localization with Learnable Moment Proposals](https://aclanthology.org/2021.emnlp-main.327)
  - Shaoning Xiao, Long Chen, Jian Shao, Yueting Zhuang, Jun Xiao
  - **TLDR**: Propose-and-rank methods for natural language video localization are under-estimated due to the predefined manners.

- [Language-Aligned Waypoint (LAW) Supervision for Vision-and-Language Navigation in Continuous Environments](https://aclanthology.org/2021.emnlp-main.328)
  - Sonia Raychaudhuri, Saim Wani, Shivansh Patel, Unnat Jain, Angel Chang
  - **TLDR**: We propose a simple and effective language-aligned supervision scheme for the vision-and-language navigation task, and a new metric that measures the number of sub-instructions the agent has completed during navigation.

- [How to leverage the multimodal EHR data for better medical prediction?](https://aclanthology.org/2021.emnlp-main.329)
  - Bo Yang, Lijun Wu
  - **TLDR**: We propose a method to extract the accompanying clinical notes from EHR and propose a way to integrate these data, we also comprehensively study the different models and the data leverage methods for better medical task prediction performance.

- [Considering Nested Tree Structure in Sentence Extractive Summarization with Pre-trained Transformer](https://aclanthology.org/2021.emnlp-main.330)
  - Jingun Kwon, Naoki Kobayashi, Hidetaka Kamigaito, Manabu Okumura
  - **TLDR**: We propose a nested tree-based extractive summarization model on RoBERTa (NeRoBERTa), where nested tree structures consist of syntactic and discourse trees in a given document.

- [Frame Semantic-Enhanced Sentence Modeling for Sentence-level Extractive Text Summarization](https://aclanthology.org/2021.emnlp-main.331)
  - Yong Guan, Shaoru Guo, Ru Li, Xiaoli Li, Hongye Tan
  - **TLDR**: We propose a novel Frame Semantic-Enhanced Sentence Modeling for Extractive Summarization, which leverages Frame semantics to model sentences from both intra-sentence level and inter-sentences level, facilitating the text summarization task.

- [CAST: Enhancing Code Summarization with Hierarchical Splitting and Reconstruction of Abstract Syntax Trees](https://aclanthology.org/2021.emnlp-main.332)
  - Ensheng Shi, Yanlin Wang, Lun Du, Hongyu Zhang, Shi Han, Dongmei Zhang, Hongbin Sun
  - **TLDR**: We propose a novel model CAST that hierarchically splits and reconstructs ASTs for code summarization.

- [SgSum:Transforming Multi-document Summarization into Sub-graph Selection](https://aclanthology.org/2021.emnlp-main.333)
  - Moye Chen, Wei Li, Jiachen Liu, Xinyan Xiao, Hua Wu, Haifeng Wang
  - **TLDR**: We propose a novel MDS framework that uses a sub-graph selection problem to formulate the MDS task as a subgraph selection task and produce a more coherent and informative summary.

- [Event Graph based Sentence Fusion](https://aclanthology.org/2021.emnlp-main.334)
  - Ruifeng Yuan, Zili Wang, Wenjie Li
  - **TLDR**: We propose to use graph structure to guide sentence fusion in text summarization.

- [Transformer-based Lexically Constrained Headline Generation](https://aclanthology.org/2021.emnlp-main.335)
  - Kosuke Yamada, Yuta Hitomi, Hideaki Tamori, Ryohei Sasano, Naoaki Okazaki, Kentaro Inui, Koichi Takeda
  - **TLDR**: We propose a new Transformer-based method for automatic headline generation that guarantees to include the given phrase in the generated headline.

- [Learn to Copy from the Copying History: Correlational Copy Network for Abstractive Summarization](https://aclanthology.org/2021.emnlp-main.336)
  - Haoran Li, Song Xu, Peng Yuan, Yujia Wang, Youzheng Wu, Xiaodong He, Bowen Zhou
  - **TLDR**: We propose a novel way to improve the standard copying mechanism by keeping track of the copying history.

- [Gradient-Based Adversarial Factual Consistency Evaluation for Abstractive Summarization](https://aclanthology.org/2021.emnlp-main.337)
  - Zhiyuan Zeng, Jiaze Chen, Weiran Xu, Lei Li
  - **TLDR**: We propose a robust and efficient adversarial data augmentation approach to generate highly abstract yet factually correct summaries.

- [Word Reordering for Zero-shot Cross-lingual Structured Prediction](https://aclanthology.org/2021.emnlp-main.338)
  - Tao Ji, Yong Jiang, Tao Wang, Zhongqiang Huang, Fei Huang, Yuanbin Wu, Xiaoling Wang
  - **TLDR**: We propose a new reordering module to organize words following the source language order, which learns task-specific reordering strategies from a general-purpose order predictor model.

- [A Unified Encoding of Structures in Transition Systems](https://aclanthology.org/2021.emnlp-main.339)
  - Tao Ji, Yong Jiang, Tao Wang, Zhongqiang Huang, Fei Huang, Yuanbin Wu, Xiaoling Wang
  - **TLDR**: We propose a novel attention-based encoder unifying representation of all structures in a transition system.

- [Improving Unsupervised Question Answering via Summarization-Informed Question Generation](https://aclanthology.org/2021.emnlp-main.340)
  - Chenyang Lyu, Lifeng Shang, Yvette Graham, Jennifer Foster, Xin Jiang, Qun Liu
  - **TLDR**: We propose a distantly-supervised QG method which uses questions generated heuristically from summaries as a source of training data for a QG system.

- [TransferNet: An Effective and Transparent Framework for Multi-hop Question Answering over Relation Graph](https://aclanthology.org/2021.emnlp-main.341)
  - Jiaxin Shi, Shulin Cao, Lei Hou, Juanzi Li, Hanwang Zhang
  - **TLDR**: We propose TransferNet, an effective and transparent model for multi-hop question answering, which achieves 100% accuracy in 2-hop and 3-hop questions.

- [Topic Transferable Table Question Answering](https://aclanthology.org/2021.emnlp-main.342)
  - Saneem Chemmengath, Vishwajeet Kumar, Samarth Bharadwaj, Jaydeep Sen, Mustafa Canim, Soumen Chakrabarti, Alfio Gliozzo, Karthik Sankaranarayanan
  - **TLDR**: We propose a pragmatic adaptation framework for weakly-supervised table question-answering that can be used to simulate the practical topic shift scenario.

- [WebSRC: A Dataset for Web-Based Structural Reading Comprehension](https://aclanthology.org/2021.emnlp-main.343)
  - Xingyu Chen, Zihan Zhao, Lu Chen, JiaBao Ji, Danyang Zhang, Ao Luo, Yuxuan Xiong, Kai Yu
  - **TLDR**: We introduce Web-based Structural Reading Comprehension, a novel task for web search and show the difficulty of the task.

- [Cryptonite: A Cryptic Crossword Benchmark for Extreme Ambiguity in Language](https://aclanthology.org/2021.emnlp-main.344)
  - Avia Efrat, Uri Shaham, Dan Kilman, Omer Levy
  - **TLDR**: We present Cryptonite, a large-scale dataset based on cryptic crosswords, which is both linguistically complex and naturally sourced.

- [End-to-End Entity Resolution and Question Answering Using Differentiable Knowledge Graphs](https://aclanthology.org/2021.emnlp-main.345)
  - Amir Saffari, Armin Oliya, Priyanka Sen, Tom Ayoola
  - **TLDR**: We extend the boundaries of end-to-end end-end (E2E) trained models for question answering over knowledge graphs (KGQA) to include the training of an ER component.

- [Improving Query Graph Generation for Complex Question Answering over Knowledge Base](https://aclanthology.org/2021.emnlp-main.346)
  - Kechen Qin, Cheng Li, Virgil Pavlu, Javed Aslam
  - **TLDR**: We propose a new query graph generation method that uses the knowledge base to generate query graphs.

- [DiscoDVT: Generating Long Text with Discourse-Aware Discrete Variational Transformer](https://aclanthology.org/2021.emnlp-main.347)
  - Haozhe Ji, Minlie Huang
  - **TLDR**: We propose DiscoDVTVVT, a discourse-aware discrete variational Transformer for generating long text with long-range coherence.

- [Mathematical Word Problem Generation from Commonsense Knowledge Graph and Equations](https://aclanthology.org/2021.emnlp-main.348)
  - Tianqiao Liu, Qiang Fang, Wenbiao Ding, Hang Li, Zhongqin Wu, Zitao Liu
  - **TLDR**: We develop an end-to-end neural model to generate diverse MWPs in real-world scenarios from commonsense knowledge graph and equations.

- [Generic resources are what you need: Style transfer tasks without task-specific parallel training data](https://aclanthology.org/2021.emnlp-main.349)
  - Huiyuan Lai, Antonio Toral, Malvina Nissim
  - **TLDR**: We propose a novel approach to style transfer that leverages generic resources, and without using any task-specific parallel (source–target) data outperforms existing unsupervised approaches on the two most popular style transfer tasks: formality transfer and polarity swap.

- [Revisiting Pivot-Based Paraphrase Generation: Language Is Not the Only Optional Pivot](https://aclanthology.org/2021.emnlp-main.350)
  - Yitao Cai, Yue Cao, Xiaojun Wan
  - **TLDR**: We explore the feasibility of using semantic and syntactic representations as the pivot for paraphrase generation.

- [Structural Adapters in Pretrained Language Models for AMR-to-Text Generation](https://aclanthology.org/2021.emnlp-main.351)
  - Leonardo F. R. Ribeiro, Yue Zhang, Iryna Gurevych
  - **TLDR**: We propose StructAdapt, an adapter method to encode graph structure into PLMs.

- [Data-to-text Generation by Splicing Together Nearest Neighbors](https://aclanthology.org/2021.emnlp-main.352)
  - Sam Wiseman, Arturs Backurs, Karl Stratos
  - **TLDR**: We propose to tackle data-to-text generation tasks by directly splicing together retrieved segments of text from “neighbor” source-target pairs.

- [Contextualize Knowledge Bases with Transformer for End-to-end Task-Oriented Dialogue Systems](https://aclanthology.org/2021.emnlp-main.353)
  - Yanjie Gou, Yinjie Lei, Lingqiao Liu, Yong Dai, Chunxu Shen
  - **TLDR**: We propose a novel Memory Enhanced Transformer framework for knowledge bases, which can improve the performance of end-to-end task-oriented dialogue systems.

- [Efficient Dialogue Complementary Policy Learning via Deep Q-network Policy and Episodic Memory Policy](https://aclanthology.org/2021.emnlp-main.354)
  - Yangyang Zhao, Zhenyu Wang, Changxi Zhu, Shihan Wang
  - **TLDR**: We propose a novel complementary policy learning framework for dialogue policy learning, which exploits the complementary advantages of episodic memory and deep Q-network.

- [CRFR: Improving Conversational Recommender Systems via Flexible Fragments Reasoning on Knowledge Graphs](https://aclanthology.org/2021.emnlp-main.355)
  - Jinfeng Zhou, Bo Wang, Ruifang He, Yuexian Hou
  - **TLDR**: We propose CRFR, which effectively does explicit multi-hop reasoning on KGs with a conversational context-based reinforcement learning model.

- [DuRecDial 2.0: A Bilingual Parallel Corpus for Conversational Recommendation](https://aclanthology.org/2021.emnlp-main.356)
  - Zeming Liu, Haifeng Wang, Zheng-Yu Niu, Hua Wu, Wanxiang Che
  - **TLDR**: We provide a bilingual parallel human-to-human recommendation dialog dataset (DuRecDial 2.0) to enable researchers to explore a challenging task of multilingual and cross-lingual conversational recommendation.

- [End-to-End Learning of Flowchart Grounded Task-Oriented Dialogs](https://aclanthology.org/2021.emnlp-main.357)
  - Dinesh Raghu, Shantanu Agarwal, Sachindra Joshi, None Mausam
  - **TLDR**: We propose a novel problem within end-to-end learning of task oriented dialogs (TOD), in which the dialog system mimics a troubleshooting agent who helps a user by diagnosing their problem (e.g., car not starting).

- [Dimensional Emotion Detection from Categorical Emotion](https://aclanthology.org/2021.emnlp-main.358)
  - Sungjoon Park, Jiseon Kim, Seonghyeon Ye, Jaeyeol Jeon, Hee Young Park, Alice Oh
  - **TLDR**: We present a model to predict fine-grained emotions along the continuous dimensions of valence, arousal, and dominance (VAD) with a corpus with categorical emotion annotations.

- [Not All Negatives are Equal: Label-Aware Contrastive Loss for Fine-grained Text Classification](https://aclanthology.org/2021.emnlp-main.359)
  - Varsha Suresh, Desmond Ong
  - **TLDR**: We propose Label-aware Contrastive Loss, a contrastive objective function for language models that helps to improve performance on fine-grained text classification tasks.

- [Joint Multi-modal Aspect-Sentiment Analysis with Auxiliary Cross-modal Relation Detection](https://aclanthology.org/2021.emnlp-main.360)
  - Xincheng Ju, Dong Zhang, Rong Xiao, Junhui Li, Shoushan Li, Min Zhang, Guodong Zhou
  - **TLDR**: We propose a multi-modal joint learning approach with auxiliary cross-modality relation detection for multi-media aspect-level sentiment analysis.

- [Solving Aspect Category Sentiment Analysis as a Text Generation Task](https://aclanthology.org/2021.emnlp-main.361)
  - Jian Liu, Zhiyang Teng, Leyang Cui, Hanmeng Liu, Yue Zhang
  - **TLDR**: We propose a new method for using pre-trained language models in aspect category sentiment analysis, which uses natural language sentences to represent the output.

- [Semantics-Preserved Data Augmentation for Aspect-Based Sentiment Analysis](https://aclanthology.org/2021.emnlp-main.362)
  - Ting-Wei Hsu, Chung-Chi Chen, Hen-Hsen Huang, Hsin-Hsi Chen
  - **TLDR**: We propose a semantics-preservation data augmentation approach by considering the importance of each word in a textual sequence according to the related aspects and sentiments.

- [The Effect of Round-Trip Translation on Fairness in Sentiment Analysis](https://aclanthology.org/2021.emnlp-main.363)
  - Jonathan Gabel Christiansen, Mathias Gammelgaard, Anders Søgaard
  - **TLDR**: We show that round-trip translation improves classification fairness and propose a method for retraining sentiment classifiers on round-trip-translated data.

- [CHoRaL: Collecting Humor Reaction Labels from Millions of Social Media Users](https://aclanthology.org/2021.emnlp-main.364)
  - Zixiaofan Yang, Shayan Hooshmand, Julia Hirschberg
  - **TLDR**: We present a novel framework for generating perceived humor labels on Facebook posts related to COVID-19 and analyze the expression of COVID related humor in social media.

- [CSDS: A Fine-Grained Chinese Dataset for Customer Service Dialogue Summarization](https://aclanthology.org/2021.emnlp-main.365)
  - Haitao Lin, Liqun Ma, Junnan Zhu, Lu Xiang, Yu Zhou, Jiajun Zhang, Chengqing Zong
  - **TLDR**: We introduce a novel Chinese dataset for Customer Service Dialogue Summarization (CSDS) and show that existing methods are prone to generate redundant and incoherent summaries.

- [CodRED: A Cross-Document Relation Extraction Dataset for Acquiring Knowledge in the Wild](https://aclanthology.org/2021.emnlp-main.366)
  - Yuan Yao, Jiaju Du, Yankai Lin, Peng Li, Zhiyuan Liu, Jie Zhou, Maosong Sun
  - **TLDR**: We present the first human-annotated cross-document relation extraction dataset for knowledge acquisition in the wild.

- [Building and Evaluating Open-Domain Dialogue Corpora with Clarifying Questions](https://aclanthology.org/2021.emnlp-main.367)
  - Mohammad Aliannejadi, Julia Kiseleva, Aleksandr Chuklin, Jeff Dalton, Mikhail Burtsev
  - **TLDR**: We present a dataset and a pipeline for evaluating the quality of clarifying questions in open-domain dialogues.

- [We Need to Talk About train-dev-test Splits](https://aclanthology.org/2021.emnlp-main.368)
  - Rob van der Goot
  - **TLDR**: We propose to use a tune-set when developing neural network methods, which can be used for model picking so that comparing the different versions of a new model can safely be done on the development data.

- [PhoMT: A High-Quality and Large-Scale Benchmark Dataset for Vietnamese-English Machine Translation](https://aclanthology.org/2021.emnlp-main.369)
  - Long Doan, Linh The Nguyen, Nguyen Luong Tran, Thai Hoang, Dat Quoc Nguyen
  - **TLDR**: We present a large-scale Vietnamese-English machine translation parallel dataset and study.

- [Lying Through One’s Teeth: A Study on Verbal Leakage Cues](https://aclanthology.org/2021.emnlp-main.370)
  - Min-Hsuan Yeh, Lun-Wei Ku
  - **TLDR**: We study verbal leakage cues in lie detection datasets and evaluate their significance and validity.

- [Multi-granularity Textual Adversarial Attack with Behavior Cloning](https://aclanthology.org/2021.emnlp-main.371)
  - Yangyi Chen, Jin Su, Wei Wei
  - **TLDR**: We propose a novel adversarial attack model that generates high-quality adversarial samples with fewer queries to victim models.

- [All Bark and No Bite: Rogue Dimensions in Transformer Language Models Obscure Representational Quality](https://aclanthology.org/2021.emnlp-main.372)
  - William Timkey, Marten van Schijndel
  - **TLDR**: We show that a small number of rogue dimensions dominate the measure of similarity in contextualized language models and show that these dimensions are not important to the behavior of the model.

- [Incorporating Residual and Normalization Layers into Analysis of Masked Language Models](https://aclanthology.org/2021.emnlp-main.373)
  - Goro Kobayashi, Tatsuki Kuribayashi, Sho Yokoi, Kentaro Inui
  - **TLDR**: We extend the scope of the analysis of Transformers from solely the attention patterns to the whole attention block, i.e., multi-head attention, residual connection, and layer normalization.

- [Mind the Style of Text! Adversarial and Backdoor Attacks Based on Text Style Transfer](https://aclanthology.org/2021.emnlp-main.374)
  - Fanchao Qi, Yangyi Chen, Xurui Zhang, Mukai Li, Zhiyuan Liu, Maosong Sun
  - **TLDR**: We present a new adversarial and backdoor attack method based on text style transfer, which is aimed at altering the style of a sentence while preserving its meaning.

- [Sociolectal Analysis of Pretrained Language Models](https://aclanthology.org/2021.emnlp-main.375)
  - Sheng Zhang, Xin Zhang, Weiming Zhang, Anders Søgaard
  - **TLDR**: Pretrained language models systematically disfavor young non-white male speakers and learn sociolectal biases.

- [Examining Cross-lingual Contextual Embeddings with Orthogonal Structural Probes](https://aclanthology.org/2021.emnlp-main.376)
  - Tomasz Limisiewicz, David Mareček
  - **TLDR**: We propose a novel orthogonal structural probe for cross-lingual embeddings and show that for some languages, no transformation is needed.

- [Are Transformers a Modern Version of ELIZA? Observations on French Object Verb Agreement](https://aclanthology.org/2021.emnlp-main.377)
  - Bingzhi Li, Guillaume Wisniewski, Benoit Crabbé
  - **TLDR**: We show that neural networks are able to capture a non-trivial amount of grammatical structure.

- [Fine-grained Entity Typing via Label Reasoning](https://aclanthology.org/2021.emnlp-main.378)
  - Qing Liu, Hongyu Lin, Xinyan Xiao, Xianpei Han, Le Sun, Hua Wu
  - **TLDR**: We propose Label Reasoning Network(LRN), which sequentially reasons fine-grained entity labels by discovering and exploiting label dependencies knowledge entailed in the data.

- [Enhanced Language Representation with Label Knowledge for Span Extraction](https://aclanthology.org/2021.emnlp-main.379)
  - Pan Yang, Xin Cong, Zhenyu Sun, Xingwu Liu
  - **TLDR**: We propose a novel model to integrate label knowledge into text representation and show that it achieves state-of-the-art performance on span extraction tasks.

- [PRIDE: Predicting Relationships in Conversations](https://aclanthology.org/2021.emnlp-main.380)
  - Anna Tigunova, Paramita Mirza, Andrew Yates, Gerhard Weikum
  - **TLDR**: We propose a novel multi-label classifier for extracting interpersonal relationships from dialogues.

- [Extracting Fine-Grained Knowledge Graphs of Scientific Claims: Dataset and Transformer-Based Results](https://aclanthology.org/2021.emnlp-main.381)
  - Ian Magnusson, Scott Friedman
  - **TLDR**: We present a graph annotation schema for scientific claims that captures causal, comparative, predictive, predictive and proportional associations over experimental variables along with their qualifications, subtypes, and evidence.

- [Sequential Cross-Document Coreference Resolution](https://aclanthology.org/2021.emnlp-main.382)
  - Emily Allaway, Shuai Wang, Miguel Ballesteros
  - **TLDR**: We propose a new model for cross-document coreference resolution that improves the efficiency of both entity and event coreference while providing strong evidence of the efficacy of both sequential models and higher-order inference in cross-word analysis.

- [Mixture-of-Partitions: Infusing Large Biomedical Knowledge Graphs into BERT](https://aclanthology.org/2021.emnlp-main.383)
  - Zaiqiao Meng, Fangyu Liu, Thomas Clark, Ehsan Shareghi, Nigel Collier
  - **TLDR**: We propose a novel infusion approach for biomedical BERTs that can handle a very large knowledge graph (KG) by partitioning it into smaller sub-graphs and infusing their specific knowledge into various BERT models using lightweight adapters.

- [Filling the Gaps in Ancient Akkadian Texts: A Masked Language Modelling Approach](https://aclanthology.org/2021.emnlp-main.384)
  - Koren Lazar, Benny Saret, Asaf Yehudai, Wayne Horowitz, Nathan Wasserman, Gabriel Stanovsky
  - **TLDR**: We present models which complete missing text given transliterations of ancient Mesopotamian documents, originally written on cuneiform clay tablets (2500 BCE - 100 CE).

- [AVocaDo: Strategy for Adapting Vocabulary to Downstream Domain](https://aclanthology.org/2021.emnlp-main.385)
  - Jimin Hong, TaeHee Kim, Hyesu Lim, Jaegul Choo
  - **TLDR**: We propose to consider the vocabulary as an optimizable parameter, allowing us to update the vocabulary by expanding it with domain specific vocabulary based on a tokenization statistic.

- [Can We Improve Model Robustness through Secondary Attribute Counterfactuals?](https://aclanthology.org/2021.emnlp-main.386)
  - Ananth Balashankar, Xuezhi Wang, Ben Packer, Nithum Thain, Ed Chi, Alex Beutel
  - **TLDR**: We propose RDI, a context-aware methodology which takes into account the impact of secondary attributes on the model’s predictions and increases sensitivity for secondary attributes over reweighted counterfactually augmented data.

- [Long-Range Modeling of Source Code Files with eWASH: Extended Window Access by Syntax Hierarchy](https://aclanthology.org/2021.emnlp-main.387)
  - Colin Clement, Shuai Lu, Xiaoyu Liu, Michele Tufano, Dawn Drain, Nan Duan, Neel Sundaresan, Alexey Svyatkovskiy
  - **TLDR**: We propose a new architecture-independent approach for leveraging the syntactic hierarchies of source code for incorporating entire file-level context into a fixed-length window.

- [Can Language Models be Biomedical Knowledge Bases?](https://aclanthology.org/2021.emnlp-main.388)
  - Mujeen Sung, Jinhyuk Lee, Sean Yi, Minji Jeon, Sungdong Kim, Jaewoo Kang
  - **TLDR**: We present a biomedical factual knowledge benchmark for biomedical LMs and show that biomedical LM can be used as domain-specific KBs.

- [LayoutReader: Pre-training of Text and Layout for Reading Order Detection](https://aclanthology.org/2021.emnlp-main.389)
  - Zilong Wang, Yiheng Xu, Lei Cui, Jingbo Shang, Furu Wei
  - **TLDR**: We present a large-scale dataset for reading order detection and a novel method for reading text and layout information for document images.

- [Region under Discussion for visual dialog](https://aclanthology.org/2021.emnlp-main.390)
  - Mauricio Mazuecos, Franco M. Luque, Jorge Sánchez, Hernán Maina, Thomas Vadora, Luciana Benotti
  - **TLDR**: We propose a novel interpretable representation that visually grounds dialog history: the Region under Discussion.

- [Learning grounded word meaning representations on similarity graphs](https://aclanthology.org/2021.emnlp-main.391)
  - Mariella Dimiccoli, Herwig Wendt, Pau Batlle Franch
  - **TLDR**: We propose a novel approach to learn visually grounded meaning representations of words as low-dimensional node embeddings on an underlying graph hierarchy.

- [WhyAct: Identifying Action Reasons in Lifestyle Vlogs](https://aclanthology.org/2021.emnlp-main.392)
  - Oana Ignat, Santiago Castro, Hanwen Miao, Weiji Li, Rada Mihalcea
  - **TLDR**: We aim to automatically identify human action reasons in online videos.

- [Genre as Weak Supervision for Cross-lingual Dependency Parsing](https://aclanthology.org/2021.emnlp-main.393)
  - Max Müller-Eberstein, Rob van der Goot, Barbara Plank
  - **TLDR**: We propose a novel method for using genre metadata to amplify information implicitly stored in unsupervised contextualized representations for domain-targeted data selection in cross-lingual, zero-shot dependency parsing.

- [On the Relation between Syntactic Divergence and Zero-Shot Performance](https://aclanthology.org/2021.emnlp-main.394)
  - Ofir Arviv, Dmitry Nikolaev, Taelin Karidi, Omri Abend
  - **TLDR**: We explore the link between the extent to which syntactic relations are preserved in translation and the ease of correctly constructing a parse tree in a zero-shot setting.

- [Improved Latent Tree Induction with Distant Supervision via Span Constraints](https://aclanthology.org/2021.emnlp-main.395)
  - Zhiyang Xu, Andrew Drozdov, Jay Yoon Lee, Tim O’Gorman, Subendhu Rongali, Dylan Finkbeiner, Shilpa Suresh, Mohit Iyyer, Andrew McCallum
  - **TLDR**: We present a technique that uses distant supervision in the form of span constraints (i.e. phrase bracketing) to improve performance in unsupervised constituency parsing.

- [Aligning Multidimensional Worldviews and Discovering Ideological Differences](https://aclanthology.org/2021.emnlp-main.396)
  - Jeremiah Milbauer, Adarsh Mathew, James Evans
  - **TLDR**: We propose a novel method for discovering the multifaceted ideological and worldview characteristics of communities on Reddit.

- [Just Say No: Analyzing the Stance of Neural Dialogue Generation in Offensive Contexts](https://aclanthology.org/2021.emnlp-main.397)
  - Ashutosh Baheti, Maarten Sap, Alan Ritter, Mark Riedl
  - **TLDR**: We investigate the role of dialogue models in generating toxic responses in offensive Reddit conversations and show that they are two times more likely to agree with offensive comments.

- [Multi-Modal Open-Domain Dialogue](https://aclanthology.org/2021.emnlp-main.398)
  - Kurt Shuster, Eric Michael Smith, Da Ju, Jason Weston
  - **TLDR**: We propose a novel approach to multi-modal dialogue that outperforms strong existing models in both pre-training and fine-tuning, and show that such efforts do not diminish model performance with respect to human preference.

- [A Label-Aware BERT Attention Network for Zero-Shot Multi-Intent Detection in Spoken Language Understanding](https://aclanthology.org/2021.emnlp-main.399)
  - Ting-Wei Wu, Ruolin Su, Biing Juang
  - **TLDR**: We propose a Label-Aware BERT Attention Network for zero-shot multi-intent detection and show that it can detect unseen intent labels in few/zero-shot setting.

- [Zero-Shot Dialogue Disentanglement by Self-Supervised Entangled Response Selection](https://aclanthology.org/2021.emnlp-main.400)
  - Ta-Chung Chi, Alexander Rudnicky
  - **TLDR**: Dialogue disentanglement aims to group utterances in a long and multi-participant dialogue into threads.

- [SIMMC 2.0: A Task-oriented Dialog Dataset for Immersive Multimodal Conversations](https://aclanthology.org/2021.emnlp-main.401)
  - Satwik Kottur, Seungwhan Moon, Alborz Geramifard, Babak Damavandi
  - **TLDR**: We present a new dataset for Situated and Interactive Multimodal Conversations, SIMMC 2.0, which includes 11K task-oriented user<->assistant dialogs (117K utterances) in the shopping domain, grounded in immersive and photo-realistic scenes.

- [RAST: Domain-Robust Dialogue Rewriting as Sequence Tagging](https://aclanthology.org/2021.emnlp-main.402)
  - Jie Hao, Linfeng Song, Liwei Wang, Kun Xu, Zhaopeng Tu, Dong Yu
  - **TLDR**: We propose a novel sequence-tagging-based model for dialogue rewriting that is robust to changes in the input data and improves on the current state-of-the-art systems.

- [MRF-Chat: Improving Dialogue with Markov Random Fields](https://aclanthology.org/2021.emnlp-main.403)
  - Ishaan Grover, Matthew Huggins, Cynthia Breazeal, Hae Won Park
  - **TLDR**: We propose a novel probabilistic approach using Markov Random Fields (MRF) to augment existing deep-learning methods for improved next utterance prediction.

- [Dialogue State Tracking with a Language Model using Schema-Driven Prompting](https://aclanthology.org/2021.emnlp-main.404)
  - Chia-Hsuan Lee, Hao Cheng, Mari Ostendorf
  - **TLDR**: We propose a new approach to task-aware history encoding that uses schema-driven prompting to provide task-specific history encoding for both categorical and non-categorical slots.

- [Signed Coreference Resolution](https://aclanthology.org/2021.emnlp-main.405)
  - Kayo Yin, Kenneth DeHaan, Malihe Alikhani
  - **TLDR**: We propose a new challenge for Sign Language Processing and Sign Language Modeling, which aims to solve the problem of coreference resolution in signed languages.

- [Consistent Accelerated Inference via Confident Adaptive Transformers](https://aclanthology.org/2021.emnlp-main.406)
  - Tal Schuster, Adam Fisch, Tommi Jaakkola, Regina Barzilay
  - **TLDR**: We develop a novel approach for confidently accelerating inference in the large and expensive multilayer Transformers that are now ubiquitous in natural language processing (NLP).

- [Improving and Simplifying Pattern Exploiting Training](https://aclanthology.org/2021.emnlp-main.407)
  - Derek Tam, Rakesh R. Menon, Mohit Bansal, Shashank Srivastava, Colin Raffel
  - **TLDR**: We present a new few-shot learning algorithm that uses patterns for few-shots learning without any task-specific unlabeled data.

- [Unsupervised Data Augmentation with Naive Augmentation and without Unlabeled Data](https://aclanthology.org/2021.emnlp-main.408)
  - David Lowell, Brian Howard, Zachary C. Lipton, Byron Wallace
  - **TLDR**: We show that applying a consistency loss to data augmentation can be used to enforce consistency between observed and noise-detected predictions in sequence labeling tasks.

- [Pre-train or Annotate? Domain Adaptation with a Constrained Budget](https://aclanthology.org/2021.emnlp-main.409)
  - Fan Bai, Alan Ritter, Wei Xu
  - **TLDR**: We study domain adaptation under budget constraints and show that data annotation and pre-training can be used to improve performance.

- [Lawyers are Dishonest? Quantifying Representational Harms in Commonsense Knowledge Resources](https://aclanthology.org/2021.emnlp-main.410)
  - Ninareh Mehrabi, Pei Zhou, Fred Morstatter, Jay Pujara, Xiang Ren, Aram Galstyan
  - **TLDR**: We show that both ConceptNet and GenericsKB are biased and propose a filtering-based approach to mitigate such biases.

- [OSCaR: Orthogonal Subspace Correction and Rectification of Biases in Word Embeddings](https://aclanthology.org/2021.emnlp-main.411)
  - Sunipa Dev, Tao Li, Jeff M Phillips, Vivek Srikumar
  - **TLDR**: We propose a new method for mitigating gender biases in language representations that ensures that semantic information is retained in the embeddings and bias is also effectively mitigated.

- [Sentence-Permuted Paragraph Generation](https://aclanthology.org/2021.emnlp-main.412)
  - Wenhao Yu, Chenguang Zhu, Tong Zhao, Zhichun Guo, Meng Jiang
  - **TLDR**: We propose a novel framework for sentence-permuted paragraph generation that maximizes the expected log-likelihood of output paragraph distributions with respect to all possible sentence orders.

- [Extract, Denoise and Enforce: Evaluating and Improving Concept Preservation for Text-to-Text Generation](https://aclanthology.org/2021.emnlp-main.413)
  - Yuning Mao, Wenchang Ma, Deren Lei, Jiawei Han, Xiang Ren
  - **TLDR**: We present a systematic analysis of text-to-text generation using seq2seq learning and propose a novel method to extract, denoise, and enforce important input concepts as lexical constraints.

- [Paraphrase Generation: A Survey of the State of the Art](https://aclanthology.org/2021.emnlp-main.414)
  - Jianing Zhou, Suma Bhat
  - **TLDR**: We present various approaches to paraphrase generation using neural methods.

- [Exposure Bias versus Self-Recovery: Are Distortions Really Incremental for Autoregressive Text Generation?](https://aclanthology.org/2021.emnlp-main.415)
  - Tianxing He, Jingzhao Zhang, Zhiming Zhou, James Glass
  - **TLDR**: We propose metrics to quantify the impact of exposure bias in language generation and show that the distortion induced by the prefix discrepancy is limited, and does not seem to be incremental during the generation.

- [Generating Self-Contained and Summary-Centric Question Answer Pairs via Differentiable Reward Imitation Learning](https://aclanthology.org/2021.emnlp-main.416)
  - Li Zhou, Kevin Small, Yong Zhang, Sandeep Atluri
  - **TLDR**: We propose a model for generating question-answer pairs (QA pairs) with self-contained, summary-centric questions and length-constrained, article-summarizing answers.

- [Unsupervised Paraphrasing with Pretrained Language Models](https://aclanthology.org/2021.emnlp-main.417)
  - Tong Niu, Semih Yavuz, Yingbo Zhou, Nitish Shirish Keskar, Huan Wang, Caiming Xiong
  - **TLDR**: We propose a transfer learning approach to paraphrase generation that achieves state-of-the-art performance on both the Quora Question Pair and ParaNMT datasets.

- [Profanity-Avoiding Training Framework for Seq2seq Models with Certified Robustness](https://aclanthology.org/2021.emnlp-main.418)
  - Hengtong Zhang, Tianhang Zheng, Yaliang Li, Jing Gao, Lu Su, Bo Li
  - **TLDR**: We propose a training framework for seq2seq models that can prevent the models from generating profanity.

- [Journalistic Guidelines Aware News Image Captioning](https://aclanthology.org/2021.emnlp-main.419)
  - Xuewen Yang, Svebor Karaman, Joel Tetreault, Alejandro Jaimes
  - **TLDR**: We propose a new approach to the caption generation task of news article image captioning that leverages the structure of captions to improve the generation quality and guide our representation design.

- [AESOP: Paraphrase Generation with Adaptive Syntactic Control](https://aclanthology.org/2021.emnlp-main.420)
  - Jiao Sun, Xuezhe Ma, Nanyun Peng
  - **TLDR**: We propose to control paraphrase generation through carefully chosen target syntactic structures to generate more proper and higher quality paraphrases.

- [Refocusing on Relevance: Personalization in NLG](https://aclanthology.org/2021.emnlp-main.421)
  - Shiran Dudy, Steven Bedrick, Bonnie Webber
  - **TLDR**: We argue that NLG systems in general should place a much higher level of emphasis on making use of additional context, and suggest that relevance (as used in Information Retrieval) be thought of as a crucial tool for designing user-oriented text-generating tasks.

- [The Future is not One-dimensional: Complex Event Schema Induction by Graph Modeling for Event Prediction](https://aclanthology.org/2021.emnlp-main.422)
  - Manling Li, Sha Li, Zhenhailong Wang, Lifu Huang, Kyunghyun Cho, Heng Ji, Jiawei Han, Clare Voss
  - **TLDR**: We propose a graph-based schema representation for event schemas that encompasses events, arguments, temporal connections and argument relations.

- [Learning Constraints and Descriptive Segmentation for Subevent Detection](https://aclanthology.org/2021.emnlp-main.423)
  - Haoyu Wang, Hongming Zhang, Muhao Chen, Dan Roth
  - **TLDR**: We propose a novel approach to learn and enforce constraints for subevent detection and prediction in text.

- [ChemNER: Fine-Grained Chemistry Named Entity Recognition with Ontology-Guided Distant Supervision](https://aclanthology.org/2021.emnlp-main.424)
  - Xuan Wang, Vivian Hu, Xiangchen Song, Shweta Garg, Jinfeng Xiao, Jiawei Han
  - **TLDR**: We propose ChemNER, an ontology-guided, distantly-supervised method for fine-grained chemistry NER.

- [Moving on from OntoNotes: Coreference Resolution Model Transfer](https://aclanthology.org/2021.emnlp-main.425)
  - Patrick Xia, Benjamin Van Durme
  - **TLDR**: We quantify transferability of coref models based on the number of annotated documents available in the target dataset.

- [Document-level Entity-based Extraction as Template Generation](https://aclanthology.org/2021.emnlp-main.426)
  - Kung-Hsiang Huang, Sam Tang, Nanyun Peng
  - **TLDR**: We propose a generative framework for document-level entity-based entity-centric entity-level extraction, which can capture cross-entity dependencies, exploit label semantics, and avoid the exponential computation complexity of N-ary relations.

- [Learning Prototype Representations Across Few-Shot Tasks for Event Detection](https://aclanthology.org/2021.emnlp-main.427)
  - Viet Lai, Franck Dernoncourt, Thien Huu Nguyen
  - **TLDR**: We address the sampling bias and outlier issues in few-shot learning for event detection, a subtask of information extraction.

- [Lifelong Event Detection with Knowledge Transfer](https://aclanthology.org/2021.emnlp-main.428)
  - Pengfei Yu, Heng Ji, Prem Natarajan
  - **TLDR**: We propose a new lifelong learning framework for supervised information extraction that improves performance on lifelong event detection and improves novel knowledge acquisition.

- [Modular Self-Supervision for Document-Level Relation Extraction](https://aclanthology.org/2021.emnlp-main.429)
  - Sheng Zhang, Cliff Wong, Naoto Usuyama, Sarthak Jain, Tristan Naumann, Hoifung Poon
  - **TLDR**: We propose a novel approach to document-level relation extraction based on modular self-supervision and a novel method for multi-scale learning.

- [Unsupervised Paraphrasing Consistency Training for Low Resource Named Entity Recognition](https://aclanthology.org/2021.emnlp-main.430)
  - Rui Wang, Ricardo Henao
  - **TLDR**: We propose a principled data augmentation scheme for NER unsupervised consistency training that encourages consistency in model predictions between the original and augmented data.

- [Fine-grained Entity Typing without Knowledge Base](https://aclanthology.org/2021.emnlp-main.431)
  - Jing Qian, Yibin Liu, Lemao Liu, Yangming Li, Haiyun Jiang, Haisong Zhang, Shuming Shi
  - **TLDR**: We propose a novel setting for training FET models: FET without accessing any knowledge base.

- [Adversarial Attack against Cross-lingual Knowledge Graph Alignment](https://aclanthology.org/2021.emnlp-main.432)
  - Zeru Zhang, Zijie Zhang, Yang Zhou, Lingfei Wu, Sixing Wu, Xiaoying Han, Dejing Dou, Tianshi Che, Da Yan
  - **TLDR**: A novel adversarial attack model for knowledge graph learning models that can degrade the quality of deep cross-lingual entity alignment.

- [Towards Realistic Few-Shot Relation Extraction](https://aclanthology.org/2021.emnlp-main.433)
  - Sam Brody, Sichao Wu, Adrian Benton
  - **TLDR**: We show that few-shot relation classification models are not as good as we thought, and propose modifications to train them to better discriminate between relations involving similar entity types.

- [Data Augmentation for Cross-Domain Named Entity Recognition](https://aclanthology.org/2021.emnlp-main.434)
  - Shuguang Chen, Gustavo Aguilar, Leonardo Neves, Thamar Solorio
  - **TLDR**: We propose a novel neural architecture to transform the data representation from a high-resource to a low-resource domain by learning the patterns (e.g. style, noise, abbreviations, etc.) in the text that differentiate them and a shared feature space where both domains are aligned.

- [Incorporating medical knowledge in BERT for clinical relation extraction](https://aclanthology.org/2021.emnlp-main.435)
  - Arpita Roy, Shimei Pan
  - **TLDR**: We present a comprehensive examination of different techniques to add medical knowledge into a pre-trained BERT model for clinical relation extraction.

- [ECONET: Effective Continual Pretraining of Language Models for Event Temporal Reasoning](https://aclanthology.org/2021.emnlp-main.436)
  - Rujun Han, Xiang Ren, Nanyun Peng
  - **TLDR**: We present a continual pre-training approach that equips PTLMs with targeted knowledge about event temporal relations and improves their performance on event-centric tasks.

- [Learning from Noisy Labels for Entity-Centric Information Extraction](https://aclanthology.org/2021.emnlp-main.437)
  - Wenxuan Zhou, Muhao Chen
  - **TLDR**: We propose a simple co-regularization framework for entity-centric information extraction, which prevents overfitting on noisy labels.

- [Extracting Material Property Measurement Data from Scientific Articles](https://aclanthology.org/2021.emnlp-main.438)
  - Gihan Panapitiya, Fred Parks, Jonathan Sepulveda, Emily Saldanha
  - **TLDR**: We propose a method for automatically extracting solubility-related entities from large datasets and compare five entity recognition models.

- [Modeling Document-Level Context for Event Detection via Important Context Selection](https://aclanthology.org/2021.emnlp-main.439)
  - Amir Pouran Ben Veyseh, Minh Van Nguyen, Nghia Ngo Trung, Bonan Min, Thien Huu Nguyen
  - **TLDR**: We propose a novel method to model document-level context for event detection in information extraction using transformer-based language models.

- [Crosslingual Transfer Learning for Relation and Event Extraction via Word Category and Class Alignments](https://aclanthology.org/2021.emnlp-main.440)
  - Minh Van Nguyen, Tuan Ngo Nguyen, Bonan Min, Thien Huu Nguyen
  - **TLDR**: We propose a novel crosslingual alignment method that leverages class information of REE tasks for representation learning.

- [Corpus-based Open-Domain Event Type Induction](https://aclanthology.org/2021.emnlp-main.441)
  - Jiaming Shen, Yunyi Zhang, Heng Ji, Jiawei Han
  - **TLDR**: We propose a corpus-based open-domain event type induction method that automatically discovers salient and high-quality event types from a given corpus.

- [PDALN: Progressive Domain Adaptation over a Pre-trained Model for Low-Resource Cross-Domain Named Entity Recognition](https://aclanthology.org/2021.emnlp-main.442)
  - Tao Zhang, Congying Xia, Philip S. Yu, Zhiwei Liu, Shu Zhao
  - **TLDR**: We propose a progressive domain adaptation Knowledge Distillation approach for cross-domain named entity recognition.

- [Multi-Vector Attention Models for Deep Re-ranking](https://aclanthology.org/2021.emnlp-main.443)
  - Giulio Zhou, Jacob Devlin
  - **TLDR**: We present a lightweight architecture that explores the joint cost vs. accuracy trade-off based on multi-vector attention and show how to efficiently trade off retrieval accuracy with joint computation and offline document storage cost.

- [Toward Deconfounding the Effect of Entity Demographics for Question Answering Accuracy](https://aclanthology.org/2021.emnlp-main.444)
  - Maharshi Gor, Kellie Webster, Jordan Boyd-Graber
  - **TLDR**: We show that question answering is not biased by gender, profession, and nationality, but by question ambiguity.

- [Exploring Strategies for Generalizable Commonsense Reasoning with Pre-trained Models](https://aclanthology.org/2021.emnlp-main.445)
  - Kaixin Ma, Filip Ilievski, Jonathan Francis, Satoru Ozaki, Eric Nyberg, Alessandro Oltramari
  - **TLDR**: We investigate what models learn from commonsense reasoning datasets and show that fine-tuning is not the best way to learn.

- [Transformer Feed-Forward Layers Are Key-Value Memories](https://aclanthology.org/2021.emnlp-main.446)
  - Mor Geva, Roei Schuster, Jonathan Berant, Omer Levy
  - **TLDR**: We show that feed-forward layers in transformer-based language models operate as key-value memories, where each key correlates with textual patterns in the training examples, and each value induces a distribution over the output vocabulary.

- [Connecting Attributions and QA Model Behavior on Realistic Counterfactuals](https://aclanthology.org/2021.emnlp-main.447)
  - Xi Ye, Rohan Nair, Greg Durrett
  - **TLDR**: We investigate how well different attribution methods and even different formats are for understanding counterfactuals in reading comprehension.

- [How Do Neural Sequence Models Generalize? Local and Global Cues for Out-of-Distribution Prediction](https://aclanthology.org/2021.emnlp-main.448)
  - D. Anthony Bau, Jacob Andreas
  - **TLDR**: We show that neural sequence models exhibit structured, consistent generalization in out-of-distribution contexts.

- [Comparing Text Representations: A Theory-Driven Approach](https://aclanthology.org/2021.emnlp-main.449)
  - Gregory Yauney, David Mimno
  - **TLDR**: We present a method to measure the difficulty of a classification-based NLP task and show that bag-of-words representations do poorly on hard natural language inference tasks, while pre-trained MLM representations do better.

- [Human Rationales as Attribution Priors for Explainable Stance Detection](https://aclanthology.org/2021.emnlp-main.450)
  - Sahil Jayaram, Emily Allaway
  - **TLDR**: We present a method for imparting human-like rationalization to a stance detection model using crowdsourced annotations on a small fraction of the training data.

- [The Stem Cell Hypothesis: Dilemma behind Multi-Task Learning with Transformer Encoders](https://aclanthology.org/2021.emnlp-main.451)
  - Han He, Jinho D. Choi
  - **TLDR**: We propose the Stem Cell Hypothesis to reveal the existence of attention heads naturally talented for many tasks that cannot be jointly trained to create adequate embeddings for all of those tasks.

- [Text Counterfactuals via Latent Optimization and Shapley-Guided Search](https://aclanthology.org/2021.emnlp-main.452)
  - Xiaoli Fern, Quintin Pope
  - **TLDR**: We use a language model to generate counterfactuals for a classifier and use the data to improve the quality of the generated counterfactuallys.

- [“Average” Approximates “First Principal Component”? An Empirical Analysis on Representations from Neural Language Models](https://aclanthology.org/2021.emnlp-main.453)
  - Zihan Wang, Chengyu Dong, Jingbo Shang
  - **TLDR**: We show that the average of neural language representations approximates the first principal component of the matrix whose columns are these representations.

- [Controlled Evaluation of Grammatical Knowledge in Mandarin Chinese Language Models](https://aclanthology.org/2021.emnlp-main.454)
  - Yiwen Wang, Jennifer Hu, Roger Levy, Peng Qian
  - **TLDR**: We train language models in Mandarin Chinese to learn syntactic dependencies and show that the benefits of hierarchical inductive biases in acquiring dependency relationships may extend beyond English.

- [GradTS: A Gradient-Based Automatic Auxiliary Task Selection Method Based on Transformer Networks](https://aclanthology.org/2021.emnlp-main.455)
  - Weicheng Ma, Renze Lou, Kai Zhang, Lili Wang, Soroush Vosoughi
  - **TLDR**: Gradient-based auxiliary task selection method for Transformer-based models.

- [NegatER: Unsupervised Discovery of Negatives in Commonsense Knowledge Bases](https://aclanthology.org/2021.emnlp-main.456)
  - Tara Safavi, Jing Zhu, Danai Koutra
  - **TLDR**: We propose NegatER, a framework that ranks potential negatives in commonsense KBs using a contextual language model (LM) and show that the positive knowledge in LMs can be used to generate negative knowledge.

- [Instance-adaptive training with noise-robust losses against noisy labels](https://aclanthology.org/2021.emnlp-main.457)
  - Lifeng Jin, Linfeng Song, Kun Xu, Dong Yu
  - **TLDR**: We propose novel instance-adaptive training frameworks to improve the noise-robustness of neural network training with noisy data.

- [Distributionally Robust Multilingual Machine Translation](https://aclanthology.org/2021.emnlp-main.458)
  - Chunting Zhou, Daniel Levy, Xian Li, Marjan Ghazvininejad, Graham Neubig
  - **TLDR**: We propose a new learning objective for multilingual neural machine translation based on distributionally robust optimization, which minimizes the worst-case expected loss over the set of language pairs.

- [Model Selection for Cross-lingual Transfer](https://aclanthology.org/2021.emnlp-main.459)
  - Yang Chen, Alan Ritter
  - **TLDR**: We show that it is possible to select consistently better models when small amounts of annotated data are available in auxiliary pivot languages.

- [Continual Few-Shot Learning for Text Classification](https://aclanthology.org/2021.emnlp-main.460)
  - Ramakanth Pasunuru, Veselin Stoyanov, Mohit Bansal
  - **TLDR**: We propose a continual few-shot learning task for neural networks that can learn to correct mistakes with only a few training examples.

- [Efficient Nearest Neighbor Language Models](https://aclanthology.org/2021.emnlp-main.461)
  - Junxian He, Graham Neubig, Taylor Berg-Kirkpatrick
  - **TLDR**: We present methods to improve the efficiency of non-parametric neural language models by up to 6x and up to a 6x, respectively.

- [STraTA: Self-Training with Task Augmentation for Better Few-shot Learning](https://aclanthology.org/2021.emnlp-main.462)
  - Tu Vu, Minh-Thang Luong, Quoc Le, Grady Simon, Mohit Iyyer
  - **TLDR**: We propose STraTA, which stands for Self-Training with Task Augmentation, an approach that builds on two key ideas for effective leverage of unlabeled data.

- [TADPOLE: Task ADapted Pre-Training via AnOmaLy DEtection](https://aclanthology.org/2021.emnlp-main.463)
  - Vivek Madan, Ashish Khetan, Zohar Karnin
  - **TLDR**: We propose TADPOLE, a task adapted pre-training framework based on data selection techniques adapted from data selection and finetuning.

- [Gradient-based Adversarial Attacks against Text Transformers](https://aclanthology.org/2021.emnlp-main.464)
  - Chuan Guo, Alexandre Sablayrolles, Hervé Jégou, Douwe Kiela
  - **TLDR**: We propose the first general-purpose gradient-based adversarial attack against transformer models.

- [Do Transformer Modifications Transfer Across Implementations and Applications?](https://aclanthology.org/2021.emnlp-main.465)
  - Sharan Narang, Hyung Won Chung, Yi Tay, Liam Fedus, Thibault Fevry, Michael Matena, Karishma Malkan, Noah Fiedel, Noam Shazeer, Zhenzhong Lan, Yanqi Zhou, Wei Li, Nan Ding, Jake Marcus, Adam Roberts, Colin Raffel
  - **TLDR**: We comprehensively evaluate many of the modifications to the Transformer architecture and find that most of them do not meaningfully improve performance.

- [Paired Examples as Indirect Supervision in Latent Decision Models](https://aclanthology.org/2021.emnlp-main.466)
  - Nitish Gupta, Sameer Singh, Matt Gardner, Dan Roth
  - **TLDR**: We propose a new way to leverage paired examples to improve compositional question answering in DROP by providing additional training objective for compositional, structured models.

- [Pairwise Supervised Contrastive Learning of Sentence Representations](https://aclanthology.org/2021.emnlp-main.467)
  - Dejiao Zhang, Shang-Wen Li, Wei Xiao, Henghui Zhu, Ramesh Nallapati, Andrew O. Arnold, Bing Xiang
  - **TLDR**: We propose PairSupCon, a novel instance discrimination based approach aiming to bridge semantic entailment and contradiction understanding with high-level categorical concept encoding.

- [Muppet: Massive Multi-task Representations with Pre-Finetuning](https://aclanthology.org/2021.emnlp-main.468)
  - Armen Aghajanyan, Anchit Gupta, Akshat Shrivastava, Xilun Chen, Luke Zettlemoyer, Sonal Gupta
  - **TLDR**: We propose pre-finetuning, an additional large-scale learning stage between language model pre-training and fine-tuning, which improves performance on a wide range of tasks.

- [Diverse Distributions of Self-Supervised Tasks for Meta-Learning in NLP](https://aclanthology.org/2021.emnlp-main.469)
  - Trapit Bansal, Karthick Prasad Gunasekaran, Tong Wang, Tsendsuren Munkhdalai, Andrew McCallum
  - **TLDR**: We propose a new meta-learning method that uses self-supervised tasks to improve few-shot learning in NLP.

- [A Simple and Effective Method To Eliminate the Self Language Bias in Multilingual Representations](https://aclanthology.org/2021.emnlp-main.470)
  - Ziyi Yang, Yinfei Yang, Daniel Cer, Eric Darve
  - **TLDR**: Language information removal for weak-alignment multilingual representations.

- [A Massively Multilingual Analysis of Cross-linguality in Shared Embedding Space](https://aclanthology.org/2021.emnlp-main.471)
  - Alexander Jones, William Yang Wang, Kyle Mahowald
  - **TLDR**: We investigate the role of sentence-level alignment metrics in cross-lingual language models and show that word order agreement and agreement in morphological complexity are two of the strongest linguistic predictors of cross-language alignment.

- [Frustratingly Simple but Surprisingly Strong: Using Language-Independent Features for Zero-shot Cross-lingual Semantic Parsing](https://aclanthology.org/2021.emnlp-main.472)
  - Jingfeng Yang, Federico Fancellu, Bonnie Webber, Diyi Yang
  - **TLDR**: We present a new approach to training semantic parsers in English for cross-lingual cross-language cross-translation.

- [Improving Simultaneous Translation by Incorporating Pseudo-References with Fewer Reorderings](https://aclanthology.org/2021.emnlp-main.473)
  - Junkun Chen, Renjie Zheng, Atsuhito Kita, Mingbo Ma, Liang Huang
  - **TLDR**: We propose a novel method that rewrites the target side of existing full-sentence corpora into simultaneous-style translation.

- [Classification-based Quality Estimation: Small and Efficient Models for Real-world Applications](https://aclanthology.org/2021.emnlp-main.474)
  - Shuo Sun, Ahmed El-Kishky, Vishrav Chaudhary, James Cross, Lucia Specia, Francisco Guzmán
  - **TLDR**: We show that the current model compression techniques for sentence-level quality estimation are not efficient for real-world translation and propose a new classification metric for sentence quality estimation.

- [A Large-Scale Study of Machine Translation in Turkic Languages](https://aclanthology.org/2021.emnlp-main.475)
  - Jamshidbek Mirzakhalov, Anoop Babu, Duygu Ataman, Sherzod Kariev, Francis Tyers, Otabek Abduraufov, Mammad Hajili, Sardana Ivanova, Abror Khaytbaev, Antonio Laverghetta Jr., Bekhzodbek Moydinboyev, Esra Onal, Shaxnoza Pulatova, Ahsan Wahab, Orhan Firat, Sriram Chellappan
  - **TLDR**: We provide the first large-scale case study of the practical application of neural machine translation in the Turkic language family in order to realize the gains of NMT for Turkic languages under high-resource to extremely low-resource scenarios.

- [Analyzing the Surprising Variability in Word Embedding Stability Across Languages](https://aclanthology.org/2021.emnlp-main.476)
  - Laura Burdick, Jonathan K. Kummerfeld, Rada Mihalcea
  - **TLDR**: We explore the stability of word embeddings in diverse languages and show that it correlates with affixing, language gender systems, and other features.

- [Rule-based Morphological Inflection Improves Neural Terminology Translation](https://aclanthology.org/2021.emnlp-main.477)
  - Weijia Xu, Marine Carpuat
  - **TLDR**: We present a modular framework for incorporating lemma constraints in neural machine translation that incorporates linguistic knowledge and diverse types of NMT models can be flexibly applied.

- [Data and Parameter Scaling Laws for Neural Machine Translation](https://aclanthology.org/2021.emnlp-main.478)
  - Mitchell A Gordon, Kevin Duh, Jared Kaplan
  - **TLDR**: We show that cross-entropy loss of translation models scales like a power law with the amount of training data and the number of non-embedding parameters in the model.

- [Good-Enough Example Extrapolation](https://aclanthology.org/2021.emnlp-main.479)
  - Jason Wei
  - **TLDR**: We propose a simple data augmentation protocol that improves performance on three text classification datasets for various data imbalance scenarios.

- [Learning to Selectively Learn for Weakly-supervised Paraphrase Generation](https://aclanthology.org/2021.emnlp-main.480)
  - Kaize Ding, Dingcheng Li, Alexander Hanbo Li, Xing Fan, Chenlei Guo, Yang Liu, Huan Liu
  - **TLDR**: We propose a novel approach to generate high-quality paraphrases with data of weak supervision.

- [Effective Convolutional Attention Network for Multi-label Clinical Document Classification](https://aclanthology.org/2021.emnlp-main.481)
  - Yang Liu, Hua Cheng, Russell Klopfer, Matthew R. Gormley, Thomas Schaaf
  - **TLDR**: We present a novel convolutional attention network for medical coding and show state-of-the-art results on medical coding.

- [Contrastive Code Representation Learning](https://aclanthology.org/2021.emnlp-main.482)
  - Paras Jain, Ajay Jain, Tianjun Zhang, Pieter Abbeel, Joseph Gonzalez, Ion Stoica
  - **TLDR**: We propose ContraCode: a contrastive pre-training task that learns code functionality, not form.

- [IGA: An Intent-Guided Authoring Assistant](https://aclanthology.org/2021.emnlp-main.483)
  - Simeng Sun, Wenlong Zhao, Varun Manjunatha, Rajiv Jain, Vlad Morariu, Franck Dernoncourt, Balaji Vasan Srinivasan, Mohit Iyyer
  - **TLDR**: We present a novel interactive writing assistant that generates and rephrases text according to author specifications.

- [Math Word Problem Generation with Mathematical Consistency and Problem Context Constraints](https://aclanthology.org/2021.emnlp-main.484)
  - Zichao Wang, Andrew Lan, Richard Baraniuk
  - **TLDR**: We develop a novel language model and context keyword selection model for arithmetic math word problems that improve the language quality of generated MWPs and an equation consistency constraint for math equations to improve the mathematical validity of the generated MWP.

- [Navigating the Kaleidoscope of COVID-19 Misinformation Using Deep Learning](https://aclanthology.org/2021.emnlp-main.485)
  - Yuanzhi Chen, Mohammad Hasan
  - **TLDR**: We show that the deep Transformer-based pre-trained models, utilized via the mixed-domain transfer learning, are only good at capturing the local context, thus exhibits poor generalization, and a combination of shallow network-based domain-specific models and convolutional neural networks can efficiently extract local as well as global context directly from the target data in a hierarchical fashion, enabling it to offer a generalizable solution.

- [Detecting Health Advice in Medical Research Literature](https://aclanthology.org/2021.emnlp-main.486)
  - Yingya Li, Jun Wang, Bei Yu
  - **TLDR**: We develop and validate an NLP-based prediction model for identifying health advice in research publications and use it to retrieve specific health advice on COVID-19 treatments.

- [A Semantic Feature-Wise Transformation Relation Network for Automatic Short Answer Grading](https://aclanthology.org/2021.emnlp-main.487)
  - Zhaohui Li, Yajur Tomar, Rebecca J. Passonneau
  - **TLDR**: We propose a new model for automatic short answer grading that exploits the multiple components of ASAG datasets more effectively.

- [Evaluating Scholarly Impact: Towards Content-Aware Bibliometrics](https://aclanthology.org/2021.emnlp-main.488)
  - Saurav Manchanda, George Karypis
  - **TLDR**: We present approaches to estimate content-aware bibliometrics to quantitatively measure the scholarly impact of a publication.

- [A Scalable Framework for Learning From Implicit User Feedback to Improve Natural Language Understanding in Large-Scale Conversational AI Systems](https://aclanthology.org/2021.emnlp-main.489)
  - Sunghyun Park, Han Li, Ameen Patel, Sidharth Mudgal, Sungjin Lee, Young-Bum Kim, Spyros Matsoukas, Ruhi Sarikaya
  - **TLDR**: We propose a scalable and automatic approach for improving NLU in a large-scale conversational AI system by leveraging implicit user feedback, with an insight that user interaction data and dialog context have rich information embedded from which user satisfaction and intention can be inferred.

- [Summarize-then-Answer: Generating Concise Explanations for Multi-hop Reading Comprehension](https://aclanthology.org/2021.emnlp-main.490)
  - Naoya Inoue, Harsh Trivedi, Steven Sinha, Niranjan Balasubramanian, Kentaro Inui
  - **TLDR**: We propose a new approach to generate concise, abstractive explanations for multi-hop reading comprehension by training a question-focused, abstractively summarized extractive explainer.

- [FewshotQA: A simple framework for few-shot learning of question answering tasks using pre-trained text-to-text models](https://aclanthology.org/2021.emnlp-main.491)
  - Rakesh Chada, Pradeep Natarajan
  - **TLDR**: We propose a simple fine-tuning framework that leverages pre-trained text-to-text models and is directly aligned with their pre-training objective.

- [Multi-stage Training with Improved Negative Contrast for Neural Passage Retrieval](https://aclanthology.org/2021.emnlp-main.492)
  - Jing Lu, Gustavo Hernandez Abrego, Ji Ma, Jianmo Ni, Yinfei Yang
  - **TLDR**: We propose a multi-stage framework for neural passage retrieval that combines synthetic data generation, negative sampling, and fusion.

- [Perhaps PTLMs Should Go to School – A Task to Assess Open Book and Closed Book QA](https://aclanthology.org/2021.emnlp-main.493)
  - Manuel Ciosici, Joe Cecil, Dong-Ho Lee, Alex Hedges, Marjorie Freedman, Ralph Weischedel
  - **TLDR**: We present a new task and leaderboard to stimulate research on question answering and pre-trained language models (PTLMs) to understand a significant instructional document, e.g., an introductory college textbook or a manual.

- [ReasonBERT: Pre-trained to Reason with Distant Supervision](https://aclanthology.org/2021.emnlp-main.494)
  - Xiang Deng, Yu Su, Alyssa Lees, You Wu, Cong Yu, Huan Sun
  - **TLDR**: We present ReasonBert, a pre-training method that augments language models with the ability to reason over long-range relations and multiple, possibly hybrid contexts.

- [Single-dataset Experts for Multi-dataset Question Answering](https://aclanthology.org/2021.emnlp-main.495)
  - Dan Friedman, Ben Dodge, Danqi Chen
  - **TLDR**: We train a collection of lightweight, dataset-specific adapter modules that outperform all our baselines in terms of in-distribution accuracy and transfer performance, and simple methods based on parameter-averaging lead to better zero-shot generalization and few-shot transfer performance.

- [Simple Entity-Centric Questions Challenge Dense Retrievers](https://aclanthology.org/2021.emnlp-main.496)
  - Christopher Sciavolino, Zexuan Zhong, Jinhyuk Lee, Danqi Chen
  - **TLDR**: We show that dense retrievers can only generalize to common entities unless the question pattern is explicitly observed during training.

- [Mitigating False-Negative Contexts in Multi-document Question Answering with Retrieval Marginalization](https://aclanthology.org/2021.emnlp-main.497)
  - Ansong Ni, Matt Gardner, Pradeep Dasigi
  - **TLDR**: We show that marginalizing over the set of supporting evidence in question answering tasks improves the performance of multi-document query answering models.

- [MultiDoc2Dial: Modeling Dialogues Grounded in Multiple Documents](https://aclanthology.org/2021.emnlp-main.498)
  - Song Feng, Siva Sankalp Patel, Hui Wan, Sachindra Joshi
  - **TLDR**: We propose MultiDoc2Dial, a new task and dataset on modeling goal-oriented dialogues grounded in multiple documents.

- [GupShup: Summarizing Open-Domain Code-Switched Conversations](https://aclanthology.org/2021.emnlp-main.499)
  - Laiba Mehnaz, Debanjan Mahata, Rakesh Gosangi, Uma Sushmitha Gunturi, Riya Jain, Gauri Gupta, Amardeep Kumar, Isabelle G. Lee, Anish Acharya, Rajiv Ratn Shah
  - **TLDR**: We introduce the task of abstractive summarization of Hindi-English (Hi-En) code-switched conversations.

- [BiSECT: Learning to Split and Rephrase Sentences with Bitexts](https://aclanthology.org/2021.emnlp-main.500)
  - Joongwon Kim, Mounica Maddela, Reno Kriz, Wei Xu, Chris Callison-Burch
  - **TLDR**: We present a novel dataset and a new model for sentence splitting and rephrase tasks.

- [Data Collection vs. Knowledge Graph Completion: What is Needed to Improve Coverage?](https://aclanthology.org/2021.emnlp-main.501)
  - Kenneth Church, Yuchen Bian
  - **TLDR**: We estimate the correlation between corpus statistics and pyscholinguistic norms and show that 1M words is not enough for good estimates of word associations and embeddings.

- [Universal Sentence Representation Learning with Conditional Masked Language Model](https://aclanthology.org/2021.emnlp-main.502)
  - Ziyi Yang, Yinfei Yang, Daniel Cer, Jax Law, Eric Darve
  - **TLDR**: We present a novel sentence representation learning method for unsupervised sentence representation training on unlabeled corpora.

- [On the Benefit of Syntactic Supervision for Cross-lingual Transfer in Semantic Role Labeling](https://aclanthology.org/2021.emnlp-main.503)
  - Zhisong Zhang, Emma Strubell, Eduard Hovy
  - **TLDR**: Syntactic supervision for cross-lingual semantic role labeling in low-resource languages.

- [Implicit Premise Generation with Discourse-aware Commonsense Knowledge Models](https://aclanthology.org/2021.emnlp-main.504)
  - Tuhin Chakrabarty, Aadit Trivedi, Smaranda Muresan
  - **TLDR**: Enthymemes are defined as arguments where a premise or conclusion is left implicit.

- [Inducing Transformer’s Compositional Generalization Ability via Auxiliary Sequence Prediction Tasks](https://aclanthology.org/2021.emnlp-main.505)
  - Yichen Jiang, Mohit Bansal
  - **TLDR**: We propose a new method for learning compositional symbolic structures of Transformer models by combining auxiliary sequence prediction tasks with auxiliary sequence parsing tasks.

- [Flexible Generation of Natural Language Deductions](https://aclanthology.org/2021.emnlp-main.506)
  - Kaj Bostrom, Xinyu Zhao, Swarat Chaudhuri, Greg Durrett
  - **TLDR**: We present a method for building deductive inference models from natural language inputs without any in-domain training data.

- [Structure-aware Fine-tuning of Sequence-to-sequence Transformers for Transition-based AMR Parsing](https://aclanthology.org/2021.emnlp-main.507)
  - Jiawei Zhou, Tahira Naseem, Ramón Fernandez Astudillo, Young-Suk Lee, Radu Florian, Salim Roukos
  - **TLDR**: We propose a structure-aware transition-based parser for linearized abstract meaning representation parsers and show that it is simpler and more efficient than previous transition-aware parsers.

- [Think about it! Improving defeasible reasoning by first modeling the question scenario.](https://aclanthology.org/2021.emnlp-main.508)
  - Aman Madaan, Niket Tandon, Dheeraj Rajagopal, Peter Clark, Yiming Yang, Eduard Hovy
  - **TLDR**: We show that neural models can be improved by guiding a system to “think about” a question and explicitly model the scenario, rather than answering reflexively.

- [Open Aspect Target Sentiment Classification with Natural Language Prompts](https://aclanthology.org/2021.emnlp-main.509)
  - Ronald Seoh, Ian Birle, Mrinal Tak, Haw-Shiuan Chang, Brian Pinette, Alfred Hough
  - **TLDR**: We propose simple approaches that better solve ATSC with natural language prompts, enabling the task under zero-shot cases and enhancing supervised settings, especially for few-shot.

- [Does BERT Learn as Humans Perceive? Understanding Linguistic Styles through Lexica](https://aclanthology.org/2021.emnlp-main.510)
  - Shirley Anugrah Hayati, Dongyeop Kang, Lyle Ungar
  - **TLDR**: We investigate lexicon usages across styles and show that human perception and machine word importance differ in the strength of the stylistic cues that they provide.

- [Improving Stance Detection with Multi-Dataset Learning and Knowledge Distillation](https://aclanthology.org/2021.emnlp-main.511)
  - Yingjie Li, Chenye Zhao, Cornelia Caragea
  - **TLDR**: We propose a multi-target and a multi–dataset training setting for stance detection and propose a novel knowledge distillation method for the task.

- [Discovering the Unknown Knowns: Turning Implicit Knowledge in the Dataset into Explicit Training Examples for Visual Question Answering](https://aclanthology.org/2021.emnlp-main.512)
  - Jihyung Kil, Cheng Zhang, Dong Xuan, Wei-Lun Chao
  - **TLDR**: We present a simple data augmentation pipeline for visual question answering that can significantly improve the performance of VQA models.

- [Improving Pre-trained Vision-and-Language Embeddings for Phrase Grounding](https://aclanthology.org/2021.emnlp-main.513)
  - Zi-Yi Dou, Nanyun Peng
  - **TLDR**: We propose a method to extract matched phrase-region pairs from pre-trained vision-and-language embeddings and propose four fine-tuning objectives to improve the model phrase grounding ability using image-caption data without any supervised grounding signals.

- [Sequential Randomized Smoothing for Adversarially Robust Speech Recognition](https://aclanthology.org/2021.emnlp-main.514)
  - Raphael Olivier, Bhiksha Raj
  - **TLDR**: We present a robust speech recognition model that can be attacked with adaptive adversarial attacks and show that it can only be broken with very high distortion.

- [Hitting your MARQ: Multimodal ARgument Quality Assessment in Long Debate Video](https://aclanthology.org/2021.emnlp-main.515)
  - Md Kamrul Hasan, James Spann, Masum Hasan, Md Saiful Islam, Kurtis Haut, Rada Mihalcea, Ehsan Hoque
  - **TLDR**: We propose a multimodal argument quality assessor that captures multimodality and uses it to improve argument quality prediction and prediction.

- [Mind the Context: The Impact of Contextualization in Neural Module Networks for Grounding Visual Referring Expressions](https://aclanthology.org/2021.emnlp-main.516)
  - Arjun Akula, Spandana Gella, Keze Wang, Song-Chun Zhu, Siva Reddy
  - **TLDR**: We propose a method to contextualize the module arguments in neural module networks to enhance the module's capacity in exploiting the visiolinguistic associations.

- [Weakly-Supervised Visual-Retriever-Reader for Knowledge-based Question Answering](https://aclanthology.org/2021.emnlp-main.517)
  - Man Luo, Yankai Zeng, Pratyay Banerjee, Chitta Baral
  - **TLDR**: We present a novel knowledge-based visual question answering pipeline that uses visual retriever-reader pipeline to approach knowledge-by-visual question answering.

- [NDH-Full: Learning and Evaluating Navigational Agents on Full-Length Dialogue](https://aclanthology.org/2021.emnlp-main.518)
  - Hyounghun Kim, Jialu Li, Mohit Bansal
  - **TLDR**: We propose a new task setup called NDH-Full which takes the full dialogue and the whole navigation path as one instance.

- [Timeline Summarization based on Event Graph Compression via Time-Aware Optimal Transport](https://aclanthology.org/2021.emnlp-main.519)
  - Manling Li, Tengfei Ma, Mo Yu, Lingfei Wu, Tian Gao, Heng Ji, Kathleen McKeown
  - **TLDR**: We propose to represent the news articles as an event-graph and compress the graph to its salient sub-graph.

- [StreamHover: Livestream Transcript Summarization and Annotation](https://aclanthology.org/2021.emnlp-main.520)
  - Sangwoo Cho, Franck Dernoncourt, Tim Ganter, Trung Bui, Nedim Lipka, Walter Chang, Hailin Jin, Jonathan Brandt, Hassan Foroosh, Fei Liu
  - **TLDR**: We present StreamHover, a framework for annotating and summarizing livestream transcripts.

- [Cross-Register Projection for Headline Part of Speech Tagging](https://aclanthology.org/2021.emnlp-main.521)
  - Adrian Benton, Hanyang Li, Igor Malioutov
  - **TLDR**: We train a multi-domain POS tagger on both long-form and headline text and show that joint training on both registers improves over training on just one or naïvely concatenating training sets.

- [Editing Factual Knowledge in Language Models](https://aclanthology.org/2021.emnlp-main.522)
  - Nicola De Cao, Wilker Aziz, Ivan Titov
  - **TLDR**: We present KnowledgeEditor, a method which can be used to edit factual knowledge and, thus, fix ‘bugs’ or unexpected predictions without the need for expensive re-training or fine-tuning.

- [Sparse Attention with Linear Units](https://aclanthology.org/2021.emnlp-main.523)
  - Biao Zhang, Ivan Titov, Rico Sennrich
  - **TLDR**: We propose a novel method for achieving sparsity in attention that is efficient and sparsity-efficient, and show that sparsity naturally emerges from such a formulation.

- [Knowledge Base Completion Meets Transfer Learning](https://aclanthology.org/2021.emnlp-main.524)
  - Vid Kocijan, Thomas Lukasiewicz
  - **TLDR**: We present a novel knowledge base completion method that can transfer unseen facts from existing facts in knowledge bases without the need for entity or relation matching.

- [SPECTRA: Sparse Structured Text Rationalization](https://aclanthology.org/2021.emnlp-main.525)
  - Nuno M. Guerreiro, André F. T. Martins
  - **TLDR**: We present a unified framework for deterministic extraction of structured explanations via constrained inference on a factor graph, forming a differentiable layer.

- [Towards Zero-Shot Knowledge Distillation for Natural Language Processing](https://aclanthology.org/2021.emnlp-main.526)
  - Ahmad Rashid, Vasileios Lioutas, Abbas Ghaddar, Mehdi Rezagholizadeh
  - **TLDR**: We present Zero-shot Knowledge Distillation for NLP, a knowledge transfer algorithm for deep learning based natural language processing.

- [Adversarial Regularization as Stackelberg Game: An Unrolled Optimization Approach](https://aclanthology.org/2021.emnlp-main.527)
  - Simiao Zuo, Chen Liang, Haoming Jiang, Xiaodong Liu, Pengcheng He, Jianfeng Gao, Weizhu Chen, Tuo Zhao
  - **TLDR**: We propose Stackelberg Adversarial Regularization, a novel adversarial regularization algorithm that is based on adversarial competition between adversarial and defending players.

- [Aspect-Controllable Opinion Summarization](https://aclanthology.org/2021.emnlp-main.528)
  - Reinald Kim Amplayo, Stefanos Angelidis, Mirella Lapata
  - **TLDR**: We propose a novel approach for generating personalized summaries based on aspect queries and a novel multi-instance learning model for prediction of aspects of a document.

- [QuestEval: Summarization Asks for Fact-based Evaluation](https://aclanthology.org/2021.emnlp-main.529)
  - Thomas Scialom, Paul-Alexis Dray, Sylvain Lamprier, Benjamin Piwowarski, Jacopo Staiano, Alex Wang, Patrick Gallinari
  - **TLDR**: We propose a unified framework for summarization evaluation that improves the correlation with human judgments over four evaluation dimensions.

- [Simple Conversational Data Augmentation for Semi-supervised Abstractive Dialogue Summarization](https://aclanthology.org/2021.emnlp-main.530)
  - Jiaao Chen, Diyi Yang
  - **TLDR**: We present a simple yet effective set of Conversational Data Augmentation methods for semi-supervised abstractive conversation summarization, such as random swapping/deletion to perturb the discourse relations inside conversations, dialogue-acts-guided insertion to interrupt the development of conversations, and conditional generation-based substitution to substitute utterances with their paraphrases generated based on the conversation context.

- [Finding a Balanced Degree of Automation for Summary Evaluation](https://aclanthology.org/2021.emnlp-main.531)
  - Shiyue Zhang, Mohit Bansal
  - **TLDR**: We propose flexible semiautomatic to automatic summary evaluation metrics, following the Pyramid human evaluation method.

- [CLIFF: Contrastive Learning for Improving Faithfulness and Factuality in Abstractive Summarization](https://aclanthology.org/2021.emnlp-main.532)
  - Shuyang Cao, Lu Wang
  - **TLDR**: We present a novel contrastive learning formulation for generating abstractive summaries that are faithful and factually consistent with the given articles.

- [Multilingual Unsupervised Neural Machine Translation with Denoising Adapters](https://aclanthology.org/2021.emnlp-main.533)
  - Ahmet Üstün, Alexandre Berard, Laurent Besacier, Matthias Gallé
  - **TLDR**: We propose a new approach to multilingual unsupervised machine translation by using auxiliary parallel language pairs.

- [BERT, mBERT, or BiBERT? A Study on Contextualized Embeddings for Neural Machine Translation](https://aclanthology.org/2021.emnlp-main.534)
  - Haoran Xu, Benjamin Van Durme, Kenton Murray
  - **TLDR**: We show that using the output of a tailored and suitable bilingual pre-trained language model as the input of the NMT encoder achieves state-of-the-art translation performance.

- [Controlling Machine Translation for Multiple Attributes with Additive Interventions](https://aclanthology.org/2021.emnlp-main.535)
  - Andrea Schioppa, David Vilar, Artem Sokolov, Katja Filippova
  - **TLDR**: We propose vector-valued interventions for control of machine translation outputs along multiple attributes simultaneously via a weighted linear combination of the corresponding vectors.

- [A Generative Framework for Simultaneous Machine Translation](https://aclanthology.org/2021.emnlp-main.536)
  - Yishu Miao, Phil Blunsom, Lucia Specia
  - **TLDR**: We propose a generative framework for simultaneous machine translation.

- [It Is Not As Good As You Think! Evaluating Simultaneous Machine Translation on Interpretation Data](https://aclanthology.org/2021.emnlp-main.537)
  - Jinming Zhao, Philip Arthur, Gholamreza Haffari, Trevor Cohn, Ehsan Shareghi
  - **TLDR**: We propose a new method for evaluation and evaluation of simultaneous machine translation systems trained on offline translations and show that it improves the performance of existing systems.

- [Boosting Cross-Lingual Transfer via Self-Learning with Uncertainty Estimation](https://aclanthology.org/2021.emnlp-main.538)
  - Liyan Xu, Xuchao Zhang, Xujiang Zhao, Haifeng Chen, Feng Chen, Jinho D. Choi
  - **TLDR**: We propose a self-learning framework for multilingual pre-trained language models that uses unlabeled data of target languages, combined with uncertainty estimation in the process to select high-quality silver labels.

- [Levenshtein Training for Word-level Quality Estimation](https://aclanthology.org/2021.emnlp-main.539)
  - Shuoyang Ding, Marcin Junczys-Dowmunt, Matt Post, Philipp Koehn
  - **TLDR**: We propose a novel scheme to use the Levenshtein Transformer to perform the task of word-level quality estimation.

- [Interactive Machine Comprehension with Dynamic Knowledge Graphs](https://aclanthology.org/2021.emnlp-main.540)
  - Xingdi Yuan
  - **TLDR**: Graph representations can serve as inductive biases in interactive machine reading comprehension tasks.

- [Residual Adapters for Parameter-Efficient ASR Adaptation to Atypical and Accented Speech](https://aclanthology.org/2021.emnlp-main.541)
  - Katrin Tomanek, Vicky Zayats, Dirk Padfield, Kara Vaillancourt, Fadi Biadsy
  - **TLDR**: We show that by adding a relatively small number of extra parameters to the encoder layers via so-called residual adapter, we can achieve similar adaptation gains compared to model fine-tuning, while only updating a tiny fraction (less than 0.5%) of the model parameters.

- [Visual News: Benchmark and Challenges in News Image Captioning](https://aclanthology.org/2021.emnlp-main.542)
  - Fuxiao Liu, Yinghan Wang, Tianlu Wang, Vicente Ordonez
  - **TLDR**: We propose Visual News Captioner, an entity-aware model for the task of news image captioning.

- [Integrating Visuospatial, Linguistic, and Commonsense Structure into Story Visualization](https://aclanthology.org/2021.emnlp-main.543)
  - Adyasha Maharana, Mohit Bansal
  - **TLDR**: We propose a novel approach to generate visual story using constituency parse trees and dense captioning.

- [VideoCLIP: Contrastive Pre-training for Zero-shot Video-Text Understanding](https://aclanthology.org/2021.emnlp-main.544)
  - Hu Xu, Gargi Ghosh, Po-Yao Huang, Dmytro Okhonko, Armen Aghajanyan, Florian Metze, Luke Zettlemoyer, Christoph Feichtenhofer
  - **TLDR**: We present VideoCLIP, a contrastive approach to pre-train a unified model for zero-shot video and text understanding, without using any labels on downstream tasks.

- [NewsCLIPpings: Automatic Generation of Out-of-Context Multimodal Media](https://aclanthology.org/2021.emnlp-main.545)
  - Grace Luo, Trevor Darrell, Anna Rohrbach
  - **TLDR**: We present a dataset for detecting and detecting image-text inconsistency in news that can mislead humans.

- [Powering Comparative Classification with Sentiment Analysis via Domain Adaptive Knowledge Transfer](https://aclanthology.org/2021.emnlp-main.546)
  - Zeyu Li, Yilong Qin, Zihan Liu, Wei Wang
  - **TLDR**: We study Comparative Preference Classification (CPC) which aims at predicting whether a preference comparison exists between two entities in a given sentence and, if so, which entity is preferred over the other.

- [Tribrid: Stance Classification with Neural Inconsistency Detection](https://aclanthology.org/2021.emnlp-main.547)
  - Song Yang, Jacopo Urbani
  - **TLDR**: We present a new neural architecture where the input also includes automatically generated negated perspectives over a given claim.

- [SYSML: StYlometry with Structure and Multitask Learning: Implications for Darknet Forum Migrant Analysis](https://aclanthology.org/2021.emnlp-main.548)
  - Pranav Maneriker, Yuntian He, Srinivasan Parthasarathy
  - **TLDR**: We develop a novel stylometry-based multitask learning approach for natural language and model interactions using graph embeddings to construct low-dimensional representations of short episodes of user activity for authorship attribution.

- [Few-Shot Emotion Recognition in Conversation with Sequential Prototypical Networks](https://aclanthology.org/2021.emnlp-main.549)
  - Gaël Guibon, Matthieu Labeau, Hélène Flamein, Luce Lefeuvre, Chloé Clavel
  - **TLDR**: We propose a novel method for sequence labeling in conversation that can serve conversational emotion classification for different languages and sparse labels.

- [CLASSIC: Continual and Contrastive Learning of Aspect Sentiment Classification Tasks](https://aclanthology.org/2021.emnlp-main.550)
  - Zixuan Ke, Bing Liu, Hu Xu, Lei Shu
  - **TLDR**: We propose a novel continual learning method for aspect sentiment classification tasks in a domain incremental learning setting.

- [Implicit Sentiment Analysis with Event-centered Text Representation](https://aclanthology.org/2021.emnlp-main.551)
  - Deyu Zhou, Jianan Wang, Linhai Zhang, Yulan He
  - **TLDR**: We propose a novel model for event-centric implicit sentiment analysis that utilizes the sentiment-aware event contained in a sentence to infer its sentiment polarity.

- [SimCSE: Simple Contrastive Learning of Sentence Embeddings](https://aclanthology.org/2021.emnlp-main.552)
  - Tianyu Gao, Xingcheng Yao, Danqi Chen
  - **TLDR**: We propose a simple contrastive learning objective for sentence embeddings that improves the state-of-the-art sentence embedding.

- [When is Wall a Pared and when a Muro?: Extracting Rules Governing Lexical Selection](https://aclanthology.org/2021.emnlp-main.553)
  - Aditi Chaudhary, Kayo Yin, Antonios Anastasopoulos, Graham Neubig
  - **TLDR**: We present a method for automatically identifying fine-grained lexical distinctions between vocabulary items and extracting rules explaining these distinctions in a human- and machine-readable format.

- [Aligning Actions Across Recipe Graphs](https://aclanthology.org/2021.emnlp-main.554)
  - Lucia Donatelli, Theresa Schmidt, Debanjali Biswas, Arne Köhn, Fangzhou Zhai, Alexander Koller
  - **TLDR**: We present a novel and fully-parsed English recipe corpus, ARA (Aligned Recipe Actions), which annotates correspondences between individual actions across similar recipes with the goal of capturing information implicit for accurate recipe understanding.

- [Generating Datasets with Pretrained Language Models](https://aclanthology.org/2021.emnlp-main.555)
  - Timo Schick, Hinrich Schütze
  - **TLDR**: We show how to obtain high-quality sentence embeddings from pretrained language models without the need for labeled data, finetuning or modifications to the pretraining objective.

- [Continuous Entailment Patterns for Lexical Inference in Context](https://aclanthology.org/2021.emnlp-main.556)
  - Martin Schmitt, Hinrich Schütze
  - **TLDR**: We present a novel method for combining a pretrained language model with textual patterns that improves performance on predicate entailment and lexical inference in context.

- [Numeracy enhances the Literacy of Language Models](https://aclanthology.org/2021.emnlp-main.557)
  - Avijit Thawani, Jay Pujara, Filip Ilievski
  - **TLDR**: We use number encoders as a proxy for evaluating literacy in NLP, and show that they improve the accuracy of masked word prediction tasks.

- [Students Who Study Together Learn Better: On the Importance of Collective Knowledge Distillation for Domain Transfer in Fact Verification](https://aclanthology.org/2021.emnlp-main.558)
  - Mitch Paul Mithun, Sandeep Suntwal, Mihai Surdeanu
  - **TLDR**: We propose Group Learning, a knowledge and model distillation approach for fact verification in which multiple student models have access to different delexicalized views of the data, but are encouraged to learn from each other through pair-wise consistency losses.

- [MultiEURLEX - A multi-lingual and multi-label legal document classification dataset for zero-shot cross-lingual transfer](https://aclanthology.org/2021.emnlp-main.559)
  - Ilias Chalkidis, Manos Fergadiotis, Ion Androutsopoulos
  - **TLDR**: We present a new multilingual dataset for topic classification of legal documents and show that fine-tuning a multilingually pretrained model in a single source language leads to catastrophic forgetting of multilingual knowledge and, consequently, poor zero-shot transfer to other languages.

- [Joint Passage Ranking for Diverse Multi-Answer Retrieval](https://aclanthology.org/2021.emnlp-main.560)
  - Sewon Min, Kenton Lee, Ming-Wei Chang, Kristina Toutanova, Hannaneh Hajishirzi
  - **TLDR**: We present a novel multi-answer retrieval model that uses autoregressive rerankers to model the joint probability of retrieved passages.

- [Generative Context Pair Selection for Multi-hop Question Answering](https://aclanthology.org/2021.emnlp-main.561)
  - Dheeru Dua, Cicero Nogueira dos Santos, Patrick Ng, Ben Athiwaratkun, Bing Xiang, Matt Gardner, Sameer Singh
  - **TLDR**: We propose a generative context selection model for multi-hop question answering that reasons about how the given question could have been generated given a context pair and not just independent contexts.

- [Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering](https://aclanthology.org/2021.emnlp-main.562)
  - Arij Riabi, Thomas Scialom, Rachel Keraron, Benoît Sagot, Djamé Seddah, Jacopo Staiano
  - **TLDR**: We propose a method to improve the Cross-lingual Question Answering performance without requiring additional annotated data, leveraging Question Generation models to produce synthetic samples in a cross-lingually cross-language fashion.

- [Have You Seen That Number? Investigating Extrapolation in Question Answering Models](https://aclanthology.org/2021.emnlp-main.563)
  - Jeonghwan Kim, Giwon Hong, Kyung-min Kim, Junmo Kang, Sung-Hyon Myaeng
  - **TLDR**: We rigorously test state-of-the-art numerical MRC models on DROP, a numerical MEC dataset, to see if they can handle passages that contain out-of_range numbers.

- [Surface Form Competition: Why the Highest Probability Answer Isn’t Always Right](https://aclanthology.org/2021.emnlp-main.564)
  - Ari Holtzman, Peter West, Vered Shwartz, Yejin Choi, Luke Zettlemoyer
  - **TLDR**: We propose a new scoring function that compensates for surface form competition in language models by reweighing each option according to its a priori likelihood within the context of a specific task.

- [Entity-Based Knowledge Conflicts in Question Answering](https://aclanthology.org/2021.emnlp-main.565)
  - Shayne Longpre, Kartik Perisetla, Anthony Chen, Nikhil Ramesh, Chris DuBois, Sameer Singh
  - **TLDR**: We propose a novel framework for generating knowledge conflicts, which minimizes hallucination, and a simple method to mitigate over-reliance on parametric knowledge.

- [Back-Training excels Self-Training at Unsupervised Domain Adaptation of Question Generation and Passage Retrieval](https://aclanthology.org/2021.emnlp-main.566)
  - Devang Kulshreshtha, Robert Belfer, Iulian Vlad Serban, Siva Reddy
  - **TLDR**: We introduce back-training, an alternative to self-training for unsupervised domain adaptation (UDA).

- [DWUG: A large Resource of Diachronic Word Usage Graphs in Four Languages](https://aclanthology.org/2021.emnlp-main.567)
  - Dominik Schlechtweg, Nina Tahmasebi, Simon Hengchen, Haim Dubossarsky, Barbara McGillivray
  - **TLDR**: We present the largest resource of graded contextualized, diachronic word meaning annotation in four different languages, based on 100,000 human semantic proximity judgments.

- [I Wish I Would Have Loved This One, But I Didn’t – A Multilingual Dataset for Counterfactual Detection in Product Review](https://aclanthology.org/2021.emnlp-main.568)
  - James O’Neill, Polina Rozenshtein, Ryuichi Kiryo, Motoko Kubota, Danushka Bollegala
  - **TLDR**: We present a multilingual dataset of Amazon product reviews covering counterfactual statements written in multiple languages and train a robust counterfactually detection model.

- [Does It Capture STEL? A Modular, Similarity-based Linguistic Style Evaluation Framework](https://aclanthology.org/2021.emnlp-main.569)
  - Anna Wegmann, Dong Nguyen
  - **TLDR**: We propose a modular, fine-grained and content-controlled similarity-based style measure that can compare two sentences on style.

- [Evaluating the Morphosyntactic Well-formedness of Generated Texts](https://aclanthology.org/2021.emnlp-main.570)
  - Adithya Pratapa, Antonios Anastasopoulos, Shruti Rijhwani, Aditi Chaudhary, David R. Mortensen, Graham Neubig, Yulia Tsvetkov
  - **TLDR**: We propose L’AMBRE, a metric to evaluate the morphosyntactic well-formedness of text using its dependency parse and morphosyllabic rules of the language.

- [AM2iCo: Evaluating Word Meaning in Context across Low-Resource Languages with Adversarial Examples](https://aclanthology.org/2021.emnlp-main.571)
  - Qianchu Liu, Edoardo Maria Ponti, Diana McCarthy, Ivan Vulić, Anna Korhonen
  - **TLDR**: We present a new multilingual evaluation dataset that captures word meaning in cross-lingual contexts and shows that current SotA pretrained encoders substantially lag behind human performance.

- [CrossFit: A Few-shot Learning Challenge for Cross-task Generalization in NLP](https://aclanthology.org/2021.emnlp-main.572)
  - Qinyuan Ye, Bill Yuchen Lin, Xiang Ren
  - **TLDR**: We present a new problem setup for studying few-shot learning and propose a new few-task generalization algorithm for NLP tasks.

- [On the Influence of Masking Policies in Intermediate Pre-training](https://aclanthology.org/2021.emnlp-main.573)
  - Qinyuan Ye, Belinda Z. Li, Sinong Wang, Benjamin Bolte, Hao Ma, Wen-tau Yih, Xiang Ren, Madian Khabsa
  - **TLDR**: We present a large-scale empirical study on the effect of various masking policies in intermediate pre-training and propose methods to automate the discovery of optimal masking policy.

- [ValNorm Quantifies Semantics to Reveal Consistent Valence Biases Across Languages and Over Centuries](https://aclanthology.org/2021.emnlp-main.574)
  - Autumn Toney, Aylin Caliskan
  - **TLDR**: We propose ValNorm, a novel intrinsic evaluation task and method to quantify the valence dimension of affect in human-rated word embeddings from social psychology.

- [Perturbation CheckLists for Evaluating NLG Evaluation Metrics](https://aclanthology.org/2021.emnlp-main.575)
  - Ananya B. Sai, Tanay Dixit, Dev Yashpal Sheth, Sreyas Mohan, Mitesh M. Khapra
  - **TLDR**: We propose CheckLists for better design and evaluation of automatic evaluation metrics for natural language generation.

- [Robust Open-Vocabulary Translation from Visual Text Representations](https://aclanthology.org/2021.emnlp-main.576)
  - Elizabeth Salesky, David Etter, Matt Post
  - **TLDR**: We propose a novel approach to visual text representations for machine translation models that match or match performance of traditional text models on small and larger datasets.

- [Don’t Go Far Off: An Empirical Study on Neural Poetry Translation](https://aclanthology.org/2021.emnlp-main.577)
  - Tuhin Chakrabarty, Arkadiy Saakyan, Smaranda Muresan
  - **TLDR**: We present an empirical investigation of the performance of poetry translation by multilingual fine-tuning on poetic and non-poetic data.

- [Improving Multilingual Translation by Representation and Gradient Regularization](https://aclanthology.org/2021.emnlp-main.578)
  - Yilin Yang, Akiko Eriguchi, Alexandre Muzio, Prasad Tadepalli, Stefan Lee, Hany Hassan
  - **TLDR**: We propose a joint approach to regularize NMT models at both representation-level and gradient-level to reduce off-shot translation and improve zero-shot translations.

- [Learning Kernel-Smoothed Machine Translation with Retrieved Examples](https://aclanthology.org/2021.emnlp-main.579)
  - Qingnan Jiang, Mingxuan Wang, Jun Cao, Shanbo Cheng, Shujian Huang, Lei Li
  - **TLDR**: We propose Kernel-Smoothed Translation with Example Retrieval, an effective approach to adapt neural machine translation models online.

- [Uncertainty-Aware Balancing for Multilingual and Multi-Domain Neural Machine Translation Training](https://aclanthology.org/2021.emnlp-main.580)
  - Minghao Wu, Yitong Li, Meng Zhang, Liangyou Li, Gholamreza Haffari, Qun Liu
  - **TLDR**: We propose a dynamic multi-corpus machine translation model that dynamically adjusts the training data usage based on the model's uncertainty on a small set of trusted clean data for multi-domain machine translation.

- [Universal Simultaneous Machine Translation with Mixture-of-Experts Wait-k Policy](https://aclanthology.org/2021.emnlp-main.581)
  - Shaolei Zhang, Yang Feng
  - **TLDR**: We propose a universal SiMT model with Mixture-of-Experts Wait-k Policy to achieve the best translation quality under arbitrary latency with only one trained model.

- [How much coffee was consumed during EMNLP 2019? Fermi Problems: A New Reasoning Challenge for AI](https://aclanthology.org/2021.emnlp-main.582)
  - Ashwin Kalyan, Abhinav Kumar, Arjun Chandrasekaran, Ashish Sabharwal, Peter Clark
  - **TLDR**: We present a new reasoning challenge that can be used to help improve AI systems that can reason.

- [Will this Question be Answered? Question Filtering via Answer Model Distillation for Efficient Question Answering](https://aclanthology.org/2021.emnlp-main.583)
  - Siddhant Garg, Alessandro Moschitti
  - **TLDR**: We propose a novel approach towards improving the efficiency of Question Answering (QA) systems by filtering out questions that will not be answered by them.

- [Learning with Instance Bundles for Reading Comprehension](https://aclanthology.org/2021.emnlp-main.584)
  - Dheeru Dua, Pradeep Dasigi, Sameer Singh, Matt Gardner
  - **TLDR**: We propose a new method for training reading comprehension models that compares question-answer scores across multiple related instances and use cross entropy loss to provide a strong supervision signal.

- [Explaining Answers with Entailment Trees](https://aclanthology.org/2021.emnlp-main.585)
  - Bhavana Dalvi, Peter Jansen, Oyvind Tafjord, Zhengnan Xie, Hannah Smith, Leighanna Pipatanangkura, Peter Clark
  - **TLDR**: We present a new dataset for textual question-answering that contains multistep entailment trees and show that a language model can partially solve these tasks.

- [SituatedQA: Incorporating Extra-Linguistic Contexts into QA](https://aclanthology.org/2021.emnlp-main.586)
  - Michael Zhang, Eunsol Choi
  - **TLDR**: We introduce SituatedQA, an open-retrieval QA dataset where systems must produce the correct answer to a question given the temporal or geographical context.

- [ConvAbuse: Data, Analysis, and Benchmarks for Nuanced Abuse Detection in Conversational AI](https://aclanthology.org/2021.emnlp-main.587)
  - Amanda Cercas Curry, Gavin Abercrombie, Verena Rieser
  - **TLDR**: We present the first English corpus study on abusive language towards three conversational AI systems gathered ‘in the wild’: an open-domain social bot, a rule-based chatbot, and a task-based system.

- [Conversational Multi-Hop Reasoning with Neural Commonsense Knowledge and Symbolic Logic Rules](https://aclanthology.org/2021.emnlp-main.588)
  - Forough Arabshahi, Jennifer Lee, Antoine Bosselut, Yejin Choi, Tom Mitchell
  - **TLDR**: We propose a novel and iterative knowledge query mechanism to extract multi-hop reasoning chains from the neural KB which uses symbolic logic rules to significantly reduce the search space.

- [Towards Automatic Evaluation of Dialog Systems: A Model-Free Off-Policy Evaluation Approach](https://aclanthology.org/2021.emnlp-main.589)
  - Haoming Jiang, Bo Dai, Mengjiao Yang, Tuo Zhao, Wei Wei
  - **TLDR**: We propose a new framework for estimating human evaluation scores based on recent advances of off-policy evaluation in reinforcement learning.

- [Continual Learning in Task-Oriented Dialogue Systems](https://aclanthology.org/2021.emnlp-main.590)
  - Andrea Madotto, Zhaojiang Lin, Zhenpeng Zhou, Seungwhan Moon, Paul Crook, Bing Liu, Zhou Yu, Eunjoon Cho, Pascale Fung, Zhiguang Wang
  - **TLDR**: We propose a first-ever continual learning benchmark for task-oriented dialogue systems with 37 domains to be learned continuously in both modularized and end-to-end learning settings.

- [Multilingual and Cross-Lingual Intent Detection from Spoken Data](https://aclanthology.org/2021.emnlp-main.591)
  - Daniela Gerz, Pei-Hao Su, Razvan Kusztos, Avishek Mondal, Michał Lis, Eshan Singhal, Nikola Mrkšić, Tsung-Hsien Wen, Ivan Vulić
  - **TLDR**: We present a systematic study on multilingual and cross-lingual intent detection (ID) from spoken data.

- [Investigating Robustness of Dialog Models to Popular Figurative Language Constructs](https://aclanthology.org/2021.emnlp-main.592)
  - Harsh Jhamtani, Varun Gangal, Eduard Hovy, Taylor Berg-Kirkpatrick
  - **TLDR**: We analyze the performance of existing dialog models in situations where the input dialog context exhibits use of figurative language.

- [Effective Sequence-to-Sequence Dialogue State Tracking](https://aclanthology.org/2021.emnlp-main.593)
  - Jeffrey Zhao, Mahdis Mahdieh, Ye Zhang, Yuan Cao, Yonghui Wu
  - **TLDR**: We show that pre-training for dialogue state tracking with span prediction and recurrent context representation improves the quality of the model.

- [MSˆ2: Multi-Document Summarization of Medical Studies](https://aclanthology.org/2021.emnlp-main.594)
  - Jay DeYoung, Iz Beltagy, Madeleine van Zuylen, Bailey Kuehl, Lucy Wang
  - **TLDR**: We present a large-scale multi-document summarization dataset for biomedical studies and propose a new metric to assess the quality of the summaries generated.

- [CLIPScore: A Reference-free Evaluation Metric for Image Captioning](https://aclanthology.org/2021.emnlp-main.595)
  - Jack Hessel, Ari Holtzman, Maxwell Forbes, Ronan Le Bras, Yejin Choi
  - **TLDR**: We present a new metric for captioning that achieves the highest correlation with human judgements, outperforming existing reference-based metrics like CIDEr and SPICE.

- [On the Challenges of Evaluating Compositional Explanations in Multi-Hop Inference: Relevance, Completeness, and Expert Ratings](https://aclanthology.org/2021.emnlp-main.596)
  - Peter Jansen, Kelly J. Smith, Dan Moreno, Huitzilin Ortiz
  - **TLDR**: We show that expert-augmented explanations for compositional reasoning models are not as good as gold explanations, and show that the current evaluation method is not as accurate as the original method.

- [ESTER: A Machine Reading Comprehension Dataset for Reasoning about Event Semantic Relations](https://aclanthology.org/2021.emnlp-main.597)
  - Rujun Han, I-Hung Hsu, Jiao Sun, Julia Baylon, Qiang Ning, Dan Roth, Nanyun Peng
  - **TLDR**: We present a comprehensive machine reading comprehension dataset for event semantic relations.

- [RICA: Evaluating Robust Inference Capabilities Based on Commonsense Axioms](https://aclanthology.org/2021.emnlp-main.598)
  - Pei Zhou, Rahul Khanna, Seyeon Lee, Bill Yuchen Lin, Daniel Ho, Jay Pujara, Xiang Ren
  - **TLDR**: We propose a new large-scale benchmark for robust inference of pre-trained language models that evaluates robust commonsense inference despite textual perturbations.

- [Compression, Transduction, and Creation: A Unified Framework for Evaluating Natural Language Generation](https://aclanthology.org/2021.emnlp-main.599)
  - Mingkai Deng, Bowen Tan, Zhengzhong Liu, Eric Xing, Zhiting Hu
  - **TLDR**: We propose a unifying perspective based on the nature of information change in natural language generation tasks, including compression, transduction, style transfer, and dialog generation.

- [MATE: Multi-view Attention for Table Transformer Efficiency](https://aclanthology.org/2021.emnlp-main.600)
  - Julian Eisenschlos, Maharshi Gor, Thomas Müller, William Cohen
  - **TLDR**: We propose a novel sparse-attention Transformer architecture for large tables that can handle large documents containing large tables.

- [Learning with Different Amounts of Annotation: From Zero to Many Labels](https://aclanthology.org/2021.emnlp-main.601)
  - Shujian Zhang, Chengyue Gong, Eunsol Choi
  - **TLDR**: We propose a new algorithm that learns from training data with different amount of annotation (with zero, one, or multiple labels) and show that it can improve NLP inference and entity typing tasks.

- [When Attention Meets Fast Recurrence: Training Language Models with Reduced Compute](https://aclanthology.org/2021.emnlp-main.602)
  - Tao Lei
  - **TLDR**: We present SRU++, a highly-efficient architecture that combines fast recurrence and attention for sequence modeling.

- [Universal-KD: Attention-based Output-Grounded Intermediate Layer Knowledge Distillation](https://aclanthology.org/2021.emnlp-main.603)
  - Yimeng Wu, Mehdi Rezagholizadeh, Abbas Ghaddar, Md Akmal Haidar, Ali Ghodsi
  - **TLDR**: We propose Universal-KD to match intermediate layers of the teacher and the student in the output space (by adding pseudo classifiers on intermediate layers) via the attention-based layer projection.

- [Highly Parallel Autoregressive Entity Linking with Discriminative Correction](https://aclanthology.org/2021.emnlp-main.604)
  - Nicola De Cao, Wilker Aziz, Ivan Titov
  - **TLDR**: We propose a new generative model for Entity Linking that is efficient and accurate.

- [Word-Level Coreference Resolution](https://aclanthology.org/2021.emnlp-main.605)
  - Vladimir Dobrovolskii
  - **TLDR**: Span representations are used to find coreference links between word spans.

- [A Secure and Efficient Federated Learning Framework for NLP](https://aclanthology.org/2021.emnlp-main.606)
  - Chenghong Wang, Jieren Deng, Xianrui Meng, Yijue Wang, Ji Li, Sheng Lin, Shuo Han, Fei Miao, Sanguthevar Rajasekaran, Caiwen Ding
  - **TLDR**: We propose a secure and efficient federated learning framework for NLP that is resilient to client dropouts and achieves similar and even better model accuracy compared with existing FL designs.

- [Controllable Semantic Parsing via Retrieval Augmentation](https://aclanthology.org/2021.emnlp-main.607)
  - Panupong Pasupat, Yuan Zhang, Kelvin Guu
  - **TLDR**: We propose a novel method for manipulating the behavior of the parser via exemplar retrieval and augmentation, and show that it can adapt to new semantic schemas without having to re-training the model.

- [Constrained Language Models Yield Few-Shot Semantic Parsers](https://aclanthology.org/2021.emnlp-main.608)
  - Richard Shin, Christopher Lin, Sam Thomson, Charles Chen, Subhro Roy, Emmanouil Antonios Platanios, Adam Pauls, Dan Klein, Jason Eisner, Benjamin Van Durme
  - **TLDR**: We explore the use of large pretrained language models as few-shot semantic parsers.

- [ExplaGraphs: An Explanation Graph Generation Task for Structured Commonsense Reasoning](https://aclanthology.org/2021.emnlp-main.609)
  - Swarnadeep Saha, Prateek Yadav, Lisa Bauer, Mohit Bansal
  - **TLDR**: ExplaGraphs is a new generative and structured commonsense-reasoning task (and an associated dataset) of explanation graph generation for stance prediction and also generate a commonsense graph that serves as non-trivial, complete, and unambiguous explanation for the predicted stance.

- [Connect-the-Dots: Bridging Semantics between Words and Definitions via Aligning Word Sense Inventories](https://aclanthology.org/2021.emnlp-main.610)
  - Wenlin Yao, Xiaoman Pan, Lifeng Jin, Jianshu Chen, Dian Yu, Dong Yu
  - **TLDR**: We propose a gloss alignment algorithm that can align definition sentences (glosses) with the same meaning from different sense inventories to collect rich lexical knowledge.

- [LM-Critic: Language Models for Unsupervised Grammatical Error Correction](https://aclanthology.org/2021.emnlp-main.611)
  - Michihiro Yasunaga, Jure Leskovec, Percy Liang
  - **TLDR**: We propose a novel method for grammatical error correction without any labeled examples.

- [Language-agnostic Representation from Multilingual Sentence Encoders for Cross-lingual Similarity Estimation](https://aclanthology.org/2021.emnlp-main.612)
  - Nattapong Tiyajamorn, Tomoyuki Kajiwara, Yuki Arase, Makoto Onizuka
  - **TLDR**: We propose a method to distill a language-agnostic meaning embedding from a multilingual sentence encoder.

- [Classifying Dyads for Militarized Conflict Analysis](https://aclanthology.org/2021.emnlp-main.613)
  - Niklas Stoehr, Lucas Torroba Hennigen, Samin Ahbab, Robert West, Ryan Cotterell
  - **TLDR**: We propose and evaluate classifiers to determine if a particular pair of entities are allies or enemies.

- [Point-of-Interest Type Prediction using Text and Images](https://aclanthology.org/2021.emnlp-main.614)
  - Danae Sánchez Villegas, Nikolaos Aletras
  - **TLDR**: We propose a multimodal approach to POI type prediction using multimodality from text and images available at posting time.

- [Come hither or go away? Recognising pre-electoral coalition signals in the news](https://aclanthology.org/2021.emnlp-main.615)
  - Ines Rehbein, Simone Paolo Ponzetto, Anna Adendorf, Oke Bahnsen, Lukas Stoetzer, Heiner Stuckenschmidt
  - **TLDR**: We present a multi-task learning approach for political coalition signal prediction from text.

- [#HowYouTagTweets: Learning User Hashtagging Preferences via Personalized Topic Attention](https://aclanthology.org/2021.emnlp-main.616)
  - Yuji Zhang, Yubo Zhang, Chunpu Xu, Jing Li, Ziyan Jiang, Baolin Peng
  - **TLDR**: We propose a novel personalized topic attention to capture salient contents to personalize hashtag contexts.

- [Learning Neural Templates for Recommender Dialogue System](https://aclanthology.org/2021.emnlp-main.617)
  - Zujie Liang, Huang Hu, Can Xu, Jian Miao, Yingying He, Yining Chen, Xiubo Geng, Fan Liang, Daxin Jiang
  - **TLDR**: We present a novel framework for recommender dialogue system that can decouple the dialogue generation from the item recommendation.

- [Proxy Indicators for the Quality of Open-domain Dialogues](https://aclanthology.org/2021.emnlp-main.618)
  - Rostislav Nedelchev, Jens Lehmann, Ricardo Usbeck
  - **TLDR**: We propose a method to evaluate open-domain dialogues using the GLUE benchmark and its various metrics.

- [Q^{2}: Evaluating Factual Consistency in Knowledge-Grounded Dialogues via Question Generation and Question Answering](https://aclanthology.org/2021.emnlp-main.619)
  - Or Honovich, Leshem Choshen, Roee Aharoni, Ella Neeman, Idan Szpektor, Omri Abend
  - **TLDR**: We propose an automatic evaluation metric for factual consistency in knowledge-grounded dialogue using automatic question generation and question answering.

- [Knowledge-Aware Graph-Enhanced GPT-2 for Dialogue State Tracking](https://aclanthology.org/2021.emnlp-main.620)
  - Weizhe Lin, Bo-Hsiang Tseng, Bill Byrne
  - **TLDR**: We propose a novel hybrid architecture for dialogue state tracking that augments GPT-2 with representations derived from Graph Attention Networks in such a way to allow causal, sequential prediction of slot values.

- [A Collaborative Multi-agent Reinforcement Learning Framework for Dialog Action Decomposition](https://aclanthology.org/2021.emnlp-main.621)
  - Huimin Wang, Kam-Fai Wong
  - **TLDR**: We propose a novel multi-agent framework for dialog policy learning that reduces the size of the action space for each agent and improves the efficiency of reinforcement learning.

- [Zero-Shot Dialogue State Tracking via Cross-Task Transfer](https://aclanthology.org/2021.emnlp-main.622)
  - Zhaojiang Lin, Bing Liu, Andrea Madotto, Seungwhan Moon, Zhenpeng Zhou, Paul Crook, Zhiguang Wang, Zhou Yu, Eunjoon Cho, Rajen Subba, Pascale Fung
  - **TLDR**: We propose a transferable generative QA model for dialogue state tracking that can handle both categorical and non-categorical slots in zero-shot DST.

- [Uncertainty Measures in Neural Belief Tracking and the Effects on Dialogue Policy Performance](https://aclanthology.org/2021.emnlp-main.623)
  - Carel van Niekerk, Andrey Malinin, Christian Geishauser, Michael Heck, Hsien-chin Lin, Nurul Lubis, Shutong Feng, Milica Gasic
  - **TLDR**: We propose a new uncertainty measure for neural dialogue belief tracking that improves the robustness of the downstream dialogue policy.

- [Dynamic Forecasting of Conversation Derailment](https://aclanthology.org/2021.emnlp-main.624)
  - Yova Kementchedjhieva, Anders Søgaard
  - **TLDR**: We propose a new algorithm for forecasting derailment in online conversations, which outperforms earlier approaches.

- [A Semantic Filter Based on Relations for Knowledge Graph Completion](https://aclanthology.org/2021.emnlp-main.625)
  - Zongwei Liang, Junan Yang, Hui Liu, Keju Huang
  - **TLDR**: We propose a new approach to measure the rationality of knowledge graph embedding models by extracting the required attributes of the entities and relations.

- [AdapterDrop: On the Efficiency of Adapters in Transformers](https://aclanthology.org/2021.emnlp-main.626)
  - Andreas Rücklé, Gregor Geigle, Max Glockner, Tilman Beck, Jonas Pfeiffer, Nils Reimers, Iryna Gurevych
  - **TLDR**: We propose AdapterDrop, a new approach to reduce the computational overhead of transformer models by removing adapters from lower transformer layers during training and inference.

- [Understanding and Overcoming the Challenges of Efficient Transformer Quantization](https://aclanthology.org/2021.emnlp-main.627)
  - Yelysei Bondarenko, Markus Nagel, Tijmen Blankevoort
  - **TLDR**: We present three new quantization schemes for transformers, each with a different set of compromises for accuracy, model size, and ease of use.

- [CAPE: Context-Aware Private Embeddings for Private Language Learning](https://aclanthology.org/2021.emnlp-main.628)
  - Richard Plant, Dimitra Gkatzia, Valerio Giuffrida
  - **TLDR**: We propose Context-Aware Private Embeddings, a novel approach which combines differential privacy and adversarial learning to preserve privacy during training of embeddings.

- [Text Detoxification using Large Pre-trained Neural Models](https://aclanthology.org/2021.emnlp-main.629)
  - David Dale, Anton Voronov, Daryna Dementieva, Varvara Logacheva, Olga Kozlova, Nikita Semenov, Alexander Panchenko
  - **TLDR**: We present two novel unsupervised methods for eliminating toxicity in text.

- [Document-Level Text Simplification: Dataset, Criteria and Baseline](https://aclanthology.org/2021.emnlp-main.630)
  - Renliang Sun, Hanqi Jin, Xiaojun Wan
  - **TLDR**: We propose a new task of document-level text simplification, which aims to simplify a document consisting of multiple sentences.

- [A Bag of Tricks for Dialogue Summarization](https://aclanthology.org/2021.emnlp-main.631)
  - Muhammad Khalifa, Miguel Ballesteros, Kathleen McKeown
  - **TLDR**: We propose a sequence-to-sequence language model for dialogue summarization and a sequence of pretrained sequence-based methods for summarization.

- [Paraphrasing Compound Nominalizations](https://aclanthology.org/2021.emnlp-main.632)
  - John Lee, Ho Hung Lim, Carol Webster
  - **TLDR**: We propose a method for generating clausal paraphrases for compound nominalizations by generating clausal paraphrased sentences.

- [Data-QuestEval: A Referenceless Metric for Data-to-Text Semantic Evaluation](https://aclanthology.org/2021.emnlp-main.633)
  - Clement Rebuffel, Thomas Scialom, Laure Soulier, Benjamin Piwowarski, Sylvain Lamprier, Jacopo Staiano, Geoffrey Scoutheeten, Patrick Gallinari
  - **TLDR**: We propose a method to build synthetic multimodal corpora enabling to train multimodality for a data-QuestEval metric.

- [Low-Rank Subspaces for Unsupervised Entity Linking](https://aclanthology.org/2021.emnlp-main.634)
  - Akhil Arora, Alberto Garcia-Duran, Robert West
  - **TLDR**: We propose a light-weight and scalable entity linking method, Eigenthemes, that relies solely on the availability of entity names and a referent knowledge base.

- [TDEER: An Efficient Translating Decoding Schema for Joint Extraction of Entities and Relations](https://aclanthology.org/2021.emnlp-main.635)
  - Xianming Li, Xiaotian Luo, Chenghao Dong, Daichuan Yang, Beidi Luan, Zhen He
  - **TLDR**: We propose a novel efficient entities and relations extraction model for the overlapping triple problem.

- [Extracting Event Temporal Relations via Hyperbolic Geometry](https://aclanthology.org/2021.emnlp-main.636)
  - Xingwei Tan, Gabriele Pergola, Yulan He
  - **TLDR**: We propose to encode events and their temporal relations in hyperbolic spaces and propose an end-to-end architecture for temporal relation extraction.

- [Honey or Poison? Solving the Trigger Curse in Few-shot Event Detection via Causal Intervention](https://aclanthology.org/2021.emnlp-main.637)
  - Jiawei Chen, Hongyu Lin, Xianpei Han, Le Sun
  - **TLDR**: We solve the trigger curse problem in few-shot event detection from a causal view.

- [Back to the Basics: A Quantitative Analysis of Statistical and Graph-Based Term Weighting Schemes for Keyword Extraction](https://aclanthology.org/2021.emnlp-main.638)
  - Asahi Ushio, Federico Liberatore, Jose Camacho-Collados
  - **TLDR**: We perform an exhaustive and large-scale empirical comparison of both statistical and graph-based term weighting methods in the context of keyword extraction.

- [Time-dependent Entity Embedding is not All You Need: A Re-evaluation of Temporal Knowledge Graph Completion Models under a Unified Framework](https://aclanthology.org/2021.emnlp-main.639)
  - Zhen Han, Gengyuan Zhang, Yunpu Ma, Volker Tresp
  - **TLDR**: We systematically study six temporal embedding techniques and empirically quantify their performance across a wide range of configurations with about 3000 experiments and 13159 GPU hours.

- [Matching-oriented Embedding Quantization For Ad-hoc Retrieval](https://aclanthology.org/2021.emnlp-main.640)
  - Shitao Xiao, Zheng Liu, Yingxia Shao, Defu Lian, Xing Xie
  - **TLDR**: We propose a novel objective Multinoulli Contrastive Loss for product quantization, which is able to maximize the matching probability of query and ground-truth key, which contributes to the optimal retrieval accuracy.

- [Efficient Mind-Map Generation via Sequence-to-Graph and Reinforced Graph Refinement](https://aclanthology.org/2021.emnlp-main.641)
  - Mengting Hu, Honglei Guo, Shiwan Zhao, Hang Gao, Zhong Su
  - **TLDR**: We propose an efficient and efficient mind-map generation network that converts a document into a graph via sequence-to-graph.

- [Deep Attention Diffusion Graph Neural Networks for Text Classification](https://aclanthology.org/2021.emnlp-main.642)
  - Yonghao Liu, Renchu Guan, Fausto Giunchiglia, Yanchun Liang, Xiaoyue Feng
  - **TLDR**: A novel graph neural network for text classification based on attention-diffusion graph neural networks.

- [Balancing Methods for Multi-label Text Classification with Long-Tailed Class Distribution](https://aclanthology.org/2021.emnlp-main.643)
  - Yi Huang, Buse Giledereli, Abdullatif Köksal, Arzucan Özgür, Elif Ozkirimli
  - **TLDR**: We introduce a new distribution-balanced loss function for multi-label text classification and show its effectiveness in natural language processing.

- [Bayesian Topic Regression for Causal Inference](https://aclanthology.org/2021.emnlp-main.644)
  - Maximilian Ahrens, Julian Ashwin, Jan-Peter Calliess, Vu Nguyen
  - **TLDR**: We propose a novel Bayesian topic model that uses both text and numerical information to model an outcome variable.

- [Enjoy the Salience: Towards Better Transformer-based Faithful Explanations with Word Salience](https://aclanthology.org/2021.emnlp-main.645)
  - George Chrysostomou, Nikolaos Aletras
  - **TLDR**: We propose SaLoss; an auxiliary loss function for guiding the multi-head attention mechanism during training to be close to salient information extracted a priori using TextRank.

- [What’s in Your Head? Emergent Behaviour in Multi-Task Transformer Models](https://aclanthology.org/2021.emnlp-main.646)
  - Mor Geva, Uri Katz, Aviv Ben-Arie, Jonathan Berant
  - **TLDR**: We show that multi-task training leads to emergent behaviour of non-target heads, which may either explain the target task, or generalize beyond their original task.

- [Don’t Search for a Search Method — Simple Heuristics Suffice for Adversarial Text Attacks](https://aclanthology.org/2021.emnlp-main.647)
  - Nathaniel Berger, Stefan Riezler, Sebastian Ebert, Artem Sokolov
  - **TLDR**: We show that adversarial text attacks on neural networks are not as effective as expected, and that constraints on adversarial attacks are too strict.

- [Adversarial Attacks on Knowledge Graph Embeddings via Instance Attribution Methods](https://aclanthology.org/2021.emnlp-main.648)
  - Peru Bhardwaj, John Kelleher, Luca Costabello, Declan O’Sullivan
  - **TLDR**: We propose to use adversarial additions and deletions to cause model failure in knowledge graph embedding models.

- [Locke’s Holiday: Belief Bias in Machine Reading](https://aclanthology.org/2021.emnlp-main.649)
  - Anders Søgaard
  - **TLDR**: We show how machine reading systems fail to answer questions when contexts do not align with commonly shared beliefs.

- [Sequence Length is a Domain: Length-based Overfitting in Transformer Models](https://aclanthology.org/2021.emnlp-main.650)
  - Dusan Varis, Ondřej Bojar
  - **TLDR**: We show that Transformer-based sequence-to-sequence architectures, while achieving state-of-the-art results on a large number of NLP tasks, can still suffer from overfitting during training.

- [Contrasting Human- and Machine-Generated Word-Level Adversarial Examples for Text Classification](https://aclanthology.org/2021.emnlp-main.651)
  - Maximilian Mozes, Max Bartolo, Pontus Stenetorp, Bennett Kleinberg, Lewis Griffin
  - **TLDR**: We present a new method for generating adversarial examples using semantics-preserving word substitutions and demonstrate that humans are capable of generating a substantial amount of adversarial example using semantics preserving word substitution.

- [Is Information Density Uniform in Task-Oriented Dialogues?](https://aclanthology.org/2021.emnlp-main.652)
  - Mario Giulianelli, Arabella Sinclair, Raquel Fernández
  - **TLDR**: We show that the Uniform Information Density principle holds in task-oriented dialogues and show that information content increases particularly within topically and referentially related contextual units.

- [On Homophony and Rényi Entropy](https://aclanthology.org/2021.emnlp-main.653)
  - Tiago Pimentel, Clara Meister, Simone Teufel, Ryan Cotterell
  - **TLDR**: We propose a new quantification of a language’s homophony and use it to revisit Trott and Bergen’ claims.

- [Synthetic Textual Features for the Large-Scale Detection of Basic-level Categories in English and Mandarin](https://aclanthology.org/2021.emnlp-main.654)
  - Yiwen Chen, Simone Teufel
  - **TLDR**: We present the first method for the detection of BLC at scale that makes use of Rosch-style semantic features.

- [TimeTraveler: Reinforcement Learning for Temporal Knowledge Graph Forecasting](https://aclanthology.org/2021.emnlp-main.655)
  - Haohai Sun, Jialun Zhong, Yunpu Ma, Zhen Han, Kun He
  - **TLDR**: We propose the first reinforcement learning method for temporal knowledge graph reasoning at future timestamps.

- [Code-switched inspired losses for spoken dialog representations](https://aclanthology.org/2021.emnlp-main.656)
  - Pierre Colombo, Emile Chapuis, Matthieu Labeau, Chloé Clavel
  - **TLDR**: Spoken dialogue systems need to be able to handle both multiple languages and multilinguality inside a conversation (

- [BiQUE: Biquaternionic Embeddings of Knowledge Graphs](https://aclanthology.org/2021.emnlp-main.657)
  - Jia Guo, Stanley Kok
  - **TLDR**: We propose BiQUE, a novel model that employs geometric operations to model multi-relational knowledge graphs.

- [Learning Neural Ordinary Equations for Forecasting Future Links on Temporal Knowledge Graphs](https://aclanthology.org/2021.emnlp-main.658)
  - Zhen Han, Zifeng Ding, Yunpu Ma, Yujia Gu, Volker Tresp
  - **TLDR**: We propose a novel continuum model for temporal knowledge graphs that captures the dynamic graph data and enables inferring future links on temporal knowledge graph data.

- [RAP: Robustness-Aware Perturbations for Defending against Backdoor Attacks on NLP Models](https://aclanthology.org/2021.emnlp-main.659)
  - Wenkai Yang, Yankai Lin, Peng Li, Jie Zhou, Xu Sun
  - **TLDR**: We propose an efficient online defense mechanism based on robustness-aware perturbations to defend against backdoor attacks on natural language processing (NLP) models.

- [FAME: Feature-Based Adversarial Meta-Embeddings for Robust Input Representations](https://aclanthology.org/2021.emnlp-main.660)
  - Lukas Lange, Heike Adel, Jannik Strötgen, Dietrich Klakow
  - **TLDR**: Feature-based adversarial meta-embeddings for POS tagging and sentence classification.

- [A Strong Baseline for Query Efficient Attacks in a Black Box Setting](https://aclanthology.org/2021.emnlp-main.661)
  - Rishabh Maheshwary, Saket Maheshwary, Vikram Pudi
  - **TLDR**: We propose a query efficient attack strategy to generate plausible adversarial examples on text classification and entailment tasks.

- [Machine Translation Decoding beyond Beam Search](https://aclanthology.org/2021.emnlp-main.662)
  - Rémi Leblond, Jean-Baptiste Alayrac, Laurent Sifre, Miruna Pislar, Lespiau Jean-Baptiste, Ioannis Antonoglou, Karen Simonyan, Oriol Vinyals
  - **TLDR**: We present a new metric-driven algorithm for decoding auto-regressive machine translation models and show its competitiveness against beam search.

- [Document Graph for Neural Machine Translation](https://aclanthology.org/2021.emnlp-main.663)
  - Mingzhou Xu, Liangyou Li, Derek F. Wong, Qun Liu, Lidia S. Chao
  - **TLDR**: We propose a graph-based document graph for neural machine translation that captures discourse phenomena and improves the translation quality.

- [An Empirical Investigation of Word Alignment Supervision for Zero-Shot Multilingual Neural Machine Translation](https://aclanthology.org/2021.emnlp-main.664)
  - Alessandro Raganato, Raúl Vázquez, Mathias Creutz, Jörg Tiedemann
  - **TLDR**: We show that simply supervising one cross attention head to focus both on word alignments and language labels reduces the bias towards translating into the wrong language, improving the zero-shot performance overall.

- [Graph Algorithms for Multiparallel Word Alignment](https://aclanthology.org/2021.emnlp-main.665)
  - Ayyoob ImaniGooghari, Masoud Jalili Sabet, Lutfi Kerem Senel, Philipp Dufter, François Yvon, Hinrich Schütze
  - **TLDR**: We exploit the multiparallelity of corpora by representing an initial set of bilingual alignments as a graph and then predicting additional edges in the graph.

- [Improving the Quality Trade-Off for Neural Machine Translation Multi-Domain Adaptation](https://aclanthology.org/2021.emnlp-main.666)
  - Eva Hasler, Tobias Domhan, Jonay Trenous, Ke Tran, Bill Byrne, Felix Hieber
  - **TLDR**: We show that combining Elastic Weight Consolidation and Elastic Weight Mixture improves performance on adaptation tasks.

- [Language Modeling, Lexical Translation, Reordering: The Training Process of NMT through the Lens of Classical SMT](https://aclanthology.org/2021.emnlp-main.667)
  - Elena Voita, Rico Sennrich, Ivan Titov
  - **TLDR**: We show that neural machine translation models acquire different competences over the course of training, and show how this mirrors the different models in traditional SMT.

- [Effective Fine-Tuning Methods for Cross-lingual Adaptation](https://aclanthology.org/2021.emnlp-main.668)
  - Tao Yu, Shafiq Joty
  - **TLDR**: We propose a novel fine-tuning method based on co-training that aims to learn more generalized semantic equivalences as a complementary to multilingual language modeling using the unlabeled data in the target language.

- [Rethinking Data Augmentation for Low-Resource Neural Machine Translation: A Multi-Task Learning Approach](https://aclanthology.org/2021.emnlp-main.669)
  - Víctor M. Sánchez-Cartagena, Miquel Esplà-Gomis, Juan Antonio Pérez-Ortiz, Felipe Sánchez-Martínez
  - **TLDR**: We propose a multi-task DA approach in which we generate new sentence pairs with transformations, such as reversing the order of the target sentence, which produce unfluent target sentences.

- [Wino-X: Multilingual Winograd Schemas for Commonsense Reasoning and Coreference Resolution](https://aclanthology.org/2021.emnlp-main.670)
  - Denis Emelin, Rico Sennrich
  - **TLDR**: We present Wino-X, a parallel dataset of German, French, and Russian schemas, aligned with their English counterparts, for evaluating coreference resolution and commonsense reasoning capabilities of neural machine translation models.

- [One Source, Two Targets: Challenges and Rewards of Dual Decoding](https://aclanthology.org/2021.emnlp-main.671)
  - Jitao Xu, François Yvon
  - **TLDR**: We present a new method for generating matched, rather than independent, translations from two text sources.

- [Discrete and Soft Prompting for Multilingual Models](https://aclanthology.org/2021.emnlp-main.672)
  - Mengjie Zhao, Hinrich Schütze
  - **TLDR**: We show that discrete and soft prompting perform better than finetuning in multilingual cases: Crosslingual transfer and in-language training of multilingual natural language inference.

- [Vision Matters When It Should: Sanity Checking Multimodal Machine Translation Models](https://aclanthology.org/2021.emnlp-main.673)
  - Jiaoda Li, Duygu Ataman, Rico Sennrich
  - **TLDR**: We present a qualitative study that examines the role of datasets in stimulating the leverage of visual modality in MMT models and propose methods to highlight the importance of visual signals in the datasets which demonstrate improvements in reliance of models on the source images.

- [Efficient Inference for Multilingual Neural Machine Translation](https://aclanthology.org/2021.emnlp-main.674)
  - Alexandre Berard, Dain Lee, Stephane Clinchant, Kweonwoo Jung, Vassilina Nikoulina
  - **TLDR**: We propose a new way to make multilingual NMT faster at inference without degrading its quality.

- [Role of Language Relatedness in Multilingual Fine-tuning of Language Models: A Case Study in Indo-Aryan Languages](https://aclanthology.org/2021.emnlp-main.675)
  - Tejas Dhamecha, Rudra Murthy, Samarth Bharadwaj, Karthik Sankaranarayanan, Pushpak Bhattacharyya
  - **TLDR**: We explore the impact of leveraging the relatedness of languages that belong to the same family in NLP models using multilingual fine-tuning.

- [Comparing Feature-Engineering and Feature-Learning Approaches for Multilingual Translationese Classification](https://aclanthology.org/2021.emnlp-main.676)
  - Daria Pylypenko, Kwabena Amponsah-Kaakyire, Koel Dutta Chowdhury, Josef van Genabith, Cristina España-Bonet
  - **TLDR**: We compare neural architectures with hand-crafted translationese features and show that neural architectures outperform neural models in both monolingual and multilingual settings.

- [Multi-Sentence Resampling: A Simple Approach to Alleviate Dataset Length Bias and Beam-Search Degradation](https://aclanthology.org/2021.emnlp-main.677)
  - Ivan Provilkov, Andrey Malinin
  - **TLDR**: We show that dataset length-bias is a factor that causes large beam-search problem in neural machine translation and propose a new data augmentation technique to mitigate this issue.

- [Cross-Policy Compliance Detection via Question Answering](https://aclanthology.org/2021.emnlp-main.678)
  - Marzieh Saeidi, Majid Yazdani, Andreas Vlachos
  - **TLDR**: We propose to address policy compliance detection via question answering, where questions check whether the conditions stated in the policy apply to the scenario, and an expression tree combines the answers to obtain the label.

- [Meta-LMTC: Meta-Learning for Large-Scale Multi-Label Text Classification](https://aclanthology.org/2021.emnlp-main.679)
  - Ran Wang, Xi’ao Su, Siyu Long, Xinyu Dai, Shujian Huang, Jiajun Chen
  - **TLDR**: Meta-learning for multi-label text classification.

- [Unsupervised Multi-View Post-OCR Error Correction With Language Models](https://aclanthology.org/2021.emnlp-main.680)
  - Harsh Gupta, Luciano Del Corro, Samuel Broscheit, Johannes Hoffart, Eliot Brenner
  - **TLDR**: Pretrained language models can be used to reconcile different OCR views of the same document and improve their quality in realistic scenarios.

- [Parallel Refinements for Lexically Constrained Text Generation with BART](https://aclanthology.org/2021.emnlp-main.681)
  - Xingwei He
  - **TLDR**: We propose Constrained BART for lexically constrained text generation and show that it can generate plausible text with high quality and diversity while largely accelerating inference.

- [BERT-Beta: A Proactive Probabilistic Approach to Text Moderation](https://aclanthology.org/2021.emnlp-main.682)
  - Fei Tan, Yifan Hu, Kevin Yen, Changwei Hu
  - **TLDR**: We propose a novel approach to text moderation by augmenting reactive reviews with proactive forecasting and propose a new concept text toxicity propensity to characterize the extent to which a text tends to attract toxic comments.

- [STaCK: Sentence Ordering with Temporal Commonsense Knowledge](https://aclanthology.org/2021.emnlp-main.683)
  - Deepanway Ghosal, Navonil Majumder, Rada Mihalcea, Soujanya Poria
  - **TLDR**: We propose a novel graph neural network based sentence order prediction framework based on graph neural networks and temporal commonsense knowledge.

- [Preventing Author Profiling through Zero-Shot Multilingual Back-Translation](https://aclanthology.org/2021.emnlp-main.684)
  - David Adelani, Miaoran Zhang, Xiaoyu Shen, Ali Davody, Thomas Kleinbauer, Dietrich Klakow
  - **TLDR**: We propose a novel approach to effectively lower the risk of author profiling through multilingual back-translation using off-the-shelf translation models.

- [CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation](https://aclanthology.org/2021.emnlp-main.685)
  - Yue Wang, Weishi Wang, Shafiq Joty, Steven C.H. Hoi
  - **TLDR**: We present CodeT5, a unified pre-trained encoder-decoder Transformer model that better leverages the code semantics conveyed from the developer-assigned identifiers.

- [Detect and Classify – Joint Span Detection and Classification for Health Outcomes](https://aclanthology.org/2021.emnlp-main.686)
  - Micheal Abaho, Danushka Bollegala, Paula Williamson, Susanna Dodd
  - **TLDR**: We propose a novel method for health outcome detection that uses both word-level and sentence-level information to simultaneously perform outcome span detection and outcome type classification.

- [Multi-Class Grammatical Error Detection for Correction: A Tale of Two Systems](https://aclanthology.org/2021.emnlp-main.687)
  - Zheng Yuan, Shiva Taslimipoor, Christopher Davis, Christopher Bryant
  - **TLDR**: We show how a multi-class grammatical error detection system can be used to improve grammatical accuracy correction (GEC) for English.

- [Towards Zero-shot Commonsense Reasoning with Self-supervised Refinement of Language Models](https://aclanthology.org/2021.emnlp-main.688)
  - Tassilo Klein, Moin Nabi
  - **TLDR**: We propose a novel self-supervised language model refinement method for Winograd Schema Challenge that allows for zero-shot commonsense reasoning.

- [To Share or not to Share: Predicting Sets of Sources for Model Transfer Learning](https://aclanthology.org/2021.emnlp-main.689)
  - Lukas Lange, Jannik Strötgen, Heike Adel, Dietrich Klakow
  - **TLDR**: We propose a new approach to automatically determine which and how many sources should be exploited in low-resource settings and show that it can improve performance by up to 24 F1 points.

- [Self-Supervised Detection of Contextual Synonyms in a Multi-Class Setting: Phenotype Annotation Use Case](https://aclanthology.org/2021.emnlp-main.690)
  - Jingqing Zhang, Luis Bolanos Trujillo, Tong Li, Ashwani Tanwar, Guilherme Freire, Xian Yang, Julia Ive, Vibhor Gupta, Yike Guo
  - **TLDR**: We propose a new SOTA for the unsupervised phenotype concept annotation on clinical text on F1 and F2 benchmarks, outperforming the previous SOTA with a gain of up to 4.5 and 4.0 absolute points, respectively.

- [ClauseRec: A Clause Recommendation Framework for AI-aided Contract Authoring](https://aclanthology.org/2021.emnlp-main.691)
  - Vinay Aggarwal, Aparna Garimella, Balaji Vasan Srinivasan, Anandhavelu N, Rajiv Jain
  - **TLDR**: We propose a two-staged pipeline to first predict if a specific clause type is relevant to be added in a contract, and then recommend the top clauses for the given type based on the contract context.

- [Finnish Dialect Identification: The Effect of Audio and Text](https://aclanthology.org/2021.emnlp-main.692)
  - Mika Hämäläinen, Khalid Alnajjar, Niko Partanen, Jack Rueter
  - **TLDR**: We present the first approach to automatically detect the dialect of a speaker based on a dialect transcript and transcript with audio recording in a dataset consisting of 23 different dialects.

- [English Machine Reading Comprehension Datasets: A Survey](https://aclanthology.org/2021.emnlp-main.693)
  - Daria Dzendzik, Jennifer Foster, Carl Vogel
  - **TLDR**: We survey 60 English Machine Reading Comprehension datasets and show that Wikipedia is by far the most common data source and that there is a relative lack of why, when, and where questions across datasets.

- [Expanding End-to-End Question Answering on Differentiable Knowledge Graphs with Intersection](https://aclanthology.org/2021.emnlp-main.694)
  - Priyanka Sen, Armin Oliya, Amir Saffari
  - **TLDR**: We propose a new intersection operation for end-to-end question answering using a differentiable knowledge graph that improves performance on multiple-entity questions by over 14% on WebQuestionsSP and by 19% on ComplexWebQuestions.

- [Structured Context and High-Coverage Grammar for Conversational Question Answering over Knowledge Graphs](https://aclanthology.org/2021.emnlp-main.695)
  - Pierre Marion, Pawel Nowak, Francesco Piccinno
  - **TLDR**: We tackle the problem of weakly-supervised conversational Question Answering over large Knowledge Graphs using a neural semantic parsing approach.

- [Improving Question Answering Model Robustness with Synthetic Adversarial Data Generation](https://aclanthology.org/2021.emnlp-main.696)
  - Max Bartolo, Tristan Thrush, Robin Jia, Sebastian Riedel, Pontus Stenetorp, Douwe Kiela
  - **TLDR**: Synthetic adversarial data generation improves question answering models by improving generalisation and adversarial robustness.

- [BeliefBank: Adding Memory to a Pre-Trained Language Model for a Systematic Notion of Belief](https://aclanthology.org/2021.emnlp-main.697)
  - Nora Kassner, Oyvind Tafjord, Hinrich Schütze, Peter Clark
  - **TLDR**: We propose a new way to embed a PTLM in a broader system that also includes an evolving, symbolic memory of beliefs, improving both the accuracy and consistency of its answers over time.

- [MLEC-QA: A Chinese Multi-Choice Biomedical Question Answering Dataset](https://aclanthology.org/2021.emnlp-main.698)
  - Jing Li, Shangping Zhong, Kaizhi Chen
  - **TLDR**: We present MLEC-QA, the largest-scale Chinese multi-choice biomedical QA dataset, collected from the National Medical Licensing Examination in China.

- [IndoNLG: Benchmark and Resources for Evaluating Indonesian Natural Language Generation](https://aclanthology.org/2021.emnlp-main.699)
  - Samuel Cahyawijaya, Genta Indra Winata, Bryan Wilie, Karissa Vincentio, Xiaohong Li, Adhiguna Kuncoro, Sebastian Ruder, Zhi Yuan Lim, Syafri Bahar, Masayu Khodra, Ayu Purwarianti, Pascale Fung
  - **TLDR**: We present IndoNLG, a new benchmark for natural language generation in low-resource languages of Indonesia.

- [Is Multi-Hop Reasoning Really Explainable? Towards Benchmarking Reasoning Interpretability](https://aclanthology.org/2021.emnlp-main.700)
  - Xin Lv, Yixin Cao, Lei Hou, Juanzi Li, Zhiyuan Liu, Yichi Zhang, Zelin Dai
  - **TLDR**: We propose a unified framework to quantitatively evaluate the interpretability of multi-hop reasoning models so as to advance their development.

- [Global Explainability of BERT-Based Evaluation Metrics by Disentangling along Linguistic Factors](https://aclanthology.org/2021.emnlp-main.701)
  - Marvin Kaster, Wei Zhao, Steffen Eger
  - **TLDR**: We show that the different metrics for evaluation of text generation quality are all substantially sensitive to lexical overlap, just like BLEU and ROUGE.

- [Exploring Underexplored Limitations of Cross-Domain Text-to-SQL Generalization](https://aclanthology.org/2021.emnlp-main.702)
  - Yujian Gan, Xinyun Chen, Matthew Purver
  - **TLDR**: We investigate the robustness of text-to-SQL models when the questions require rarely observed domain knowledge.

- [What happens if you treat ordinal ratings as interval data? Human evaluations in NLP are even more under-powered than you think](https://aclanthology.org/2021.emnlp-main.703)
  - David M. Howcroft, Verena Rieser
  - **TLDR**: We show that ordinal mixed effects models are better able to detect small differences between models, especially in high variance settings common in evaluations of generated texts.

- [NeuTral Rewriter: A Rule-Based and Neural Approach to Automatic Rewriting into Gender Neutral Alternatives](https://aclanthology.org/2021.emnlp-main.704)
  - Eva Vanmassenhove, Chris Emmery, Dimitar Shterionov
  - **TLDR**: We present a rule-based and a neural approach to gender-neutral rewriting for English along with manually curated synthetic data (WinoBias+) and natural data (OpenSubtitles and Reddit) benchmarks.

- [Benchmarking Commonsense Knowledge Base Population with an Effective Evaluation Dataset](https://aclanthology.org/2021.emnlp-main.705)
  - Tianqing Fang, Weiqi Wang, Sehyun Choi, Shibo Hao, Hongming Zhang, Yangqiu Song, Bin He
  - **TLDR**: We present a new large-scale dataset for commonsense reasoning over knowledge bases and a novel inductive commonsense model that reasons over graphs.

- [Enhancing the Context Representation in Similarity-based Word Sense Disambiguation](https://aclanthology.org/2021.emnlp-main.706)
  - Ming Wang, Jianzhang Zhang, Yinglin Wang
  - **TLDR**: We investigate the contribution of both word-level and sense-level global context of an ambiguous word for disambiguation.

- [Data Augmentation with Hierarchical SQL-to-Question Generation for Cross-domain Text-to-SQL Parsing](https://aclanthology.org/2021.emnlp-main.707)
  - Kun Wu, Lijie Wang, Zhenghua Li, Ao Zhang, Xinyan Xiao, Hua Wu, Min Zhang, Haifeng Wang
  - **TLDR**: We present a simple yet effective data augmentation framework for cross-domain text-to-SQL parsing.

- [SPARQLing Database Queries from Intermediate Question Decompositions](https://aclanthology.org/2021.emnlp-main.708)
  - Irina Saparina, Anton Osokin
  - **TLDR**: We present a novel query-to-query pipeline based on grounded in databases intermediate question representations.

- [Time-aware Graph Neural Network for Entity Alignment between Temporal Knowledge Graphs](https://aclanthology.org/2021.emnlp-main.709)
  - Chengjin Xu, Fenglong Su, Jens Lehmann
  - **TLDR**: We propose a novel Time-aware Entity Alignment approach based on Graph Neural Networks and use GNNs to learn entity representations.

- [Cross-Domain Label-Adaptive Stance Detection](https://aclanthology.org/2021.emnlp-main.710)
  - Momchil Hardalov, Arnav Arora, Preslav Nakov, Isabelle Augenstein
  - **TLDR**: We propose an end-to-end unsupervised framework for out-of-domain prediction of unseen, user-defined labels.

- [Text AutoAugment: Learning Compositional Augmentation Policy for Text Classification](https://aclanthology.org/2021.emnlp-main.711)
  - Shuhuai Ren, Jinchao Zhang, Lei Li, Xu Sun, Jie Zhou
  - **TLDR**: We propose a compositional and learnable paradigm for data augmentation and show that it significantly improves the generalization capability of models.

- [Distilling Relation Embeddings from Pretrained Language Models](https://aclanthology.org/2021.emnlp-main.712)
  - Asahi Ushio, Jose Camacho-Collados, Steven Schockaert
  - **TLDR**: We present a method for extracting relation embeddings from pre-trained language models that are highly competitive on analogy and relation classification benchmarks.

- [Avoiding Inference Heuristics in Few-shot Prompt-based Finetuning](https://aclanthology.org/2021.emnlp-main.713)
  - Prasetya Utama, Nafise Sadat Moosavi, Victor Sanh, Iryna Gurevych
  - **TLDR**: We show that few-shot finetuning can be destructive to useful knowledge learned during the pretraining.

- [A Differentiable Relaxation of Graph Segmentation and Alignment for AMR Parsing](https://aclanthology.org/2021.emnlp-main.714)
  - Chunchuan Lyu, Shay B. Cohen, Ivan Titov
  - **TLDR**: We introduce a differentiable relaxation of the segmentation and alignment problems in a sentence meaning representation model and show that inducing segmentation yields substantial gains over using a ‘greedy’ segmentation heuristic.

- [Integrating Personalized PageRank into Neural Word Sense Disambiguation](https://aclanthology.org/2021.emnlp-main.715)
  - Ahmed El Sheikh, Michele Bevilacqua, Roberto Navigli
  - **TLDR**: We improve a classification model by recomputing logits as a function of both the vanilla independently produced logits and the global WordNet graph.

- [Cross-lingual Sentence Embedding using Multi-Task Learning](https://aclanthology.org/2021.emnlp-main.716)
  - Koustava Goswami, Sourav Dutta, Haytham Assem, Theodorus Fransen, John P. McCrae
  - **TLDR**: We propose a novel sentence embedding framework based on an unsupervised loss function for generating effective multilingual sentence embeddings, eliminating the need for parallel corpora.

- [NB-MLM: Efficient Domain Adaptation of Masked Language Models for Sentiment Analysis](https://aclanthology.org/2021.emnlp-main.717)
  - Nikolay Arefyev, Dmitrii Kharchev, Artem Shelmanov
  - **TLDR**: We propose a new method for efficient adaptation of the domain or task-specific domain objective in Masked Language Models that focuses on predicting words with large weights of the Naive Bayes classifier trained for the task at hand, which are likely more relevant than the most frequent words.

- [Revisiting Self-training for Few-shot Learning of Language Model](https://aclanthology.org/2021.emnlp-main.718)
  - Yiming Chen, Yan Zhang, Chen Zhang, Grandee Lee, Ran Cheng, Haizhou Li
  - **TLDR**: We present a prompt-based few-shot learner for language model fine-tuning that outperforms other state-of-the-art supervised and semi-supervised counterparts on six sentence classification and six sentence-pair classification benchmarking tasks.

- [Bridging Perception, Memory, and Inference through Semantic Relations](https://aclanthology.org/2021.emnlp-main.719)
  - Johanna Björklund, Adam Dahlgren Lindström, Frank Drewes
  - **TLDR**: We propose a new approach to language understanding that combines the strengths of neural and symbolic methods.

- [Unimodal and Crossmodal Refinement Network for Multimodal Sequence Fusion](https://aclanthology.org/2021.emnlp-main.720)
  - Xiaobao Guo, Adams Kong, Huan Zhou, Xianfeng Wang, Min Wang
  - **TLDR**: Unimodal and crossmodal representation refinement network for multimodal sequence fusion.

- [YASO: A Targeted Sentiment Analysis Evaluation Dataset for Open-Domain Reviews](https://aclanthology.org/2021.emnlp-main.721)
  - Matan Orbach, Orith Toledo-Ronen, Artem Spector, Ranit Aharonov, Yoav Katz, Noam Slonim
  - **TLDR**: We present YASO – a new TSA evaluation dataset of open-domain user reviews.

- [An Empirical Study on Leveraging Position Embeddings for Target-oriented Opinion Words Extraction](https://aclanthology.org/2021.emnlp-main.722)
  - Samuel Mensah, Kai Sun, Nikolaos Aletras
  - **TLDR**: We present a variety of text encoders based on pretrained word embeddings or language models that leverage part-of-speech and position embeddins to extract opinion words for a given aspect in text.

- [Improving Multimodal Fusion with Hierarchical Mutual Information Maximization for Multimodal Sentiment Analysis](https://aclanthology.org/2021.emnlp-main.723)
  - Wei Han, Hui Chen, Soujanya Poria
  - **TLDR**: We propose a framework for multimodal sentiment analysis that hierarchically maximizes the Mutual Information (MI) in unimodal input pairs (inter-modality) and between multimodally fusion result and unimodally input in order to maintain task-related information through multimodALF.

- [BERT4GCN: Using BERT Intermediate Layers to Augment GCN for Aspect-based Sentiment Classification](https://aclanthology.org/2021.emnlp-main.724)
  - Zeguan Xiao, Jiarun Wu, Qingliang Chen, Congjian Deng
  - **TLDR**: We propose a novel graph-based Aspect-based Sentiment Classification model that integrates grammatical sequential features from pre-training language models and syntactic knowledge from dependency graphs for the downstream classification.

- [Does Social Pressure Drive Persuasion in Online Fora?](https://aclanthology.org/2021.emnlp-main.725)
  - Ayush Jain, Shashank Srivastava
  - **TLDR**: We propose that social features in online forums are predictive of persuasion and that social pressure might be a causal factor for persuasion.

- [Aspect Sentiment Quad Prediction as Paraphrase Generation](https://aclanthology.org/2021.emnlp-main.726)
  - Wenxuan Zhang, Yang Deng, Xin Li, Yifei Yuan, Lidong Bing, Wai Lam
  - **TLDR**: We propose a novel Aspect-based sentiment analysis task, which can reveal a more comprehensive and complete aspect-level sentiment structure.

- [Cross-lingual Aspect-based Sentiment Analysis with Aspect Term Code-Switching](https://aclanthology.org/2021.emnlp-main.727)
  - Wenxuan Zhang, Ruidan He, Haiyun Peng, Lidong Bing, Wai Lam
  - **TLDR**: We propose an alignment-free label projection method for the unsupervised cross-lingual transfer for the Aspect-based sentiment analysis task.

- [Towards Label-Agnostic Emotion Embeddings](https://aclanthology.org/2021.emnlp-main.728)
  - Sven Buechel, Luise Modersohn, Udo Hahn
  - **TLDR**: We propose a new training scheme for emotion analysis that learns a shared latent representation of emotion independent from different label formats, natural languages, and even disparate model architectures.

- [Collaborative Learning of Bidirectional Decoders for Unsupervised Text Style Transfer](https://aclanthology.org/2021.emnlp-main.729)
  - Yun Ma, Yangbin Chen, Xudong Mao, Qing Li
  - **TLDR**: We propose a collaborative learning framework for unsupervised text style transfer using a pair of bidirectional decoders, one decoding from left to right while the other decoding from right to left.

- [Exploring Non-Autoregressive Text Style Transfer](https://aclanthology.org/2021.emnlp-main.730)
  - Yun Ma, Qing Li
  - **TLDR**: We propose a base NAR model for unsupervised text style transfer and propose three techniques for improving it.

- [PASTE: A Tagging-Free Decoding Framework Using Pointer Networks for Aspect Sentiment Triplet Extraction](https://aclanthology.org/2021.emnlp-main.731)
  - Rajdeep Mukherjee, Tapas Nayak, Yash Butala, Sourangshu Bhattacharya, Pawan Goyal
  - **TLDR**: We present a tagging-free solution for the task of extracting opinion triplets, consisting of an opinion target or aspect, its associated sentiment, and the corresponding opinion term/span explaining the rationale behind the sentiment.

- [Adaptive Proposal Generation Network for Temporal Sentence Localization in Videos](https://aclanthology.org/2021.emnlp-main.732)
  - Daizong Liu, Xiaoye Qu, Jianfeng Dong, Pan Zhou
  - **TLDR**: We propose an adaptive proposal generation network for temporal sentence localization in videos.

- [Progressively Guide to Attend: An Iterative Alignment Framework for Temporal Sentence Grounding](https://aclanthology.org/2021.emnlp-main.733)
  - Daizong Liu, Xiaoye Qu, Pan Zhou
  - **TLDR**: We propose an iterative alignment network for temporal sentence grounding task, which iteratively interacts inter- and intra-modal features within multiple steps for more accurate grounding.

- [Language Models are Few-Shot Butlers](https://aclanthology.org/2021.emnlp-main.734)
  - Vincent Micheli, Francois Fleuret
  - **TLDR**: We show that language models fine-tuned with only 1.2% of the expert demonstrations and a simple reinforcement learning algorithm achieve a 51% absolute improvement in success rate over existing methods in the ALFWorld environment.

- [Rˆ3Net:Relation-embedded Representation Reconstruction Network for Change Captioning](https://aclanthology.org/2021.emnlp-main.735)
  - Yunbin Tu, Liang Li, Chenggang Yan, Shengxiang Gao, Zhengtao Yu
  - **TLDR**: We propose a novel change captioning method that explicitly distinguishes the real change from the large amount of clutter and irrelevant changes.

- [Looking for Confirmations: An Effective and Human-Like Visual Dialogue Strategy](https://aclanthology.org/2021.emnlp-main.736)
  - Alberto Testoni, Raffaella Bernardi
  - **TLDR**: We present Confirm-it, a model based on a beam search re-ranking algorithm that guides an effective goal-oriented strategy by asking questions that confirm the model’s conjecture about the referent.

- [A Unified Speaker Adaptation Approach for ASR](https://aclanthology.org/2021.emnlp-main.737)
  - Yingzhu Zhao, Chongjia Ni, Cheung-Chi Leung, Shafiq Joty, Eng Siong Chng, Bin Ma
  - **TLDR**: We propose a unified speaker adaptation approach consisting of feature adaptation and model adaptation.

- [Caption Enriched Samples for Improving Hateful Memes Detection](https://aclanthology.org/2021.emnlp-main.738)
  - Efrat Blaier, Itzik Malkiel, Lior Wolf
  - **TLDR**: We propose a captioning tool for image captioning that captures the first contrast between the image content and the overlayed text.

- [Sparsity and Sentence Structure in Encoder-Decoder Attention of Summarization Systems](https://aclanthology.org/2021.emnlp-main.739)
  - Potsawee Manakul, Mark Gales
  - **TLDR**: We show that there is a sparse sentence structure in document summarization that can be exploited by constraining the attention mechanism to a subset of input sentences, whilst maintaining system performance.

- [BARThez: a Skilled Pretrained French Sequence-to-Sequence Model](https://aclanthology.org/2021.emnlp-main.740)
  - Moussa Kamal Eddine, Antoine Tixier, Michalis Vazirgiannis
  - **TLDR**: We present a large-scale pretrained seq2seq model for French language models that is competitive with state-of-the-art BERT-based French language language models such as CamemBERT and FlauBERT.

- [ARMAN: Pre-training with Semantically Selecting and Reordering of Sentences for Persian Abstractive Summarization](https://aclanthology.org/2021.emnlp-main.741)
  - Alireza Salemi, Emad Kebriaei, Ghazal Neisi Minaei, Azadeh Shakery
  - **TLDR**: We propose ARMAN, a Transformer-based encoder-decoder model pre-trained with three novel objectives to address this issue.

- [Models and Datasets for Cross-Lingual Summarisation](https://aclanthology.org/2021.emnlp-main.742)
  - Laura Perez-Beltrachini, Mirella Lapata
  - **TLDR**: We present a cross-lingual summarisation corpus with long documents in a source language associated with multi-sentence summaries in a target language.

- [Learning Opinion Summarizers by Selecting Informative Reviews](https://aclanthology.org/2021.emnlp-main.743)
  - Arthur Bražinskas, Mirella Lapata, Ivan Titov
  - **TLDR**: We propose a novel method for summarizing user-written summaries paired with user reviews and training a summarizer.

- [Enriching and Controlling Global Semantics for Text Summarization](https://aclanthology.org/2021.emnlp-main.744)
  - Thong Nguyen, Anh Tuan Luu, Truc Lu, Tho Quan
  - **TLDR**: We propose a novel method for summarization of text that captures global semantics of text and uses them to improve the quality of the text.

- [Revisiting Tri-training of Dependency Parsers](https://aclanthology.org/2021.emnlp-main.745)
  - Joachim Wagner, Jennifer Foster
  - **TLDR**: We compare two orthogonal semi-supervised learning techniques, namely tri-training and pretrained word embeddings, in the task of dependency parsing.

- [Bridge to Target Domain by Prototypical Contrastive Learning and Label Confusion: Re-explore Zero-Shot Learning for Slot Filling](https://aclanthology.org/2021.emnlp-main.746)
  - Liwen Wang, Xuefeng Li, Jiachi Liu, Keqing He, Yuanmeng Yan, Weiran Xu
  - **TLDR**: We propose a novel approach based on prototypical contrastive learning with a dynamic label confusion strategy for zero-shot cross-domain slot filling alleviates the data dependence in the case of data scarcity in the target domain.

- [Neuralizing Regular Expressions for Slot Filling](https://aclanthology.org/2021.emnlp-main.747)
  - Chengyue Jiang, Zijian Jin, Kewei Tu
  - **TLDR**: We study the integration of the two approaches for the slot filling task by converting regular expressions into neural networks.

- [Causal Direction of Data Collection Matters: Implications of Causal and Anticausal Learning for NLP](https://aclanthology.org/2021.emnlp-main.748)
  - Zhijing Jin, Julius von Kügelgen, Jingwei Ni, Tejas Vaidhya, Ayush Kaushal, Mrinmaya Sachan, Bernhard Schoelkopf
  - **TLDR**: We propose a causal inference principle for NLP tasks that can explain a number of published NLP findings, such as differences in semi-supervised learning (SSL) and domain adaptation (DA) performance across different settings.

- [Raise a Child in Large Language Model: Towards Effective and Generalizable Fine-tuning](https://aclanthology.org/2021.emnlp-main.749)
  - Runxin Xu, Fuli Luo, Zhiyuan Zhang, Chuanqi Tan, Baobao Chang, Songfang Huang, Fei Huang
  - **TLDR**: We propose a simple yet effective fine-tuning technique for large language models by strategically masking out gradients of the non-child network during the backward process.

- [Knowledge Graph Representation Learning using Ordinary Differential Equations](https://aclanthology.org/2021.emnlp-main.750)
  - Mojtaba Nayyeri, Chengjin Xu, Franca Hoffmann, Mirza Mohtashim Alam, Jens Lehmann, Sahar Vahdati
  - **TLDR**: We propose a neuro differential KGE that embeds nodes of a knowledge graph on the trajectories of Ordinary Differential Equations (ODEs) and use the trajectory to encode heterogeneous subgraphs.

- [KnowMAN: Weakly Supervised Multinomial Adversarial Networks](https://aclanthology.org/2021.emnlp-main.751)
  - Luisa März, Ehsaneddin Asgari, Fabienne Braune, Franziska Zimmermann, Benjamin Roth
  - **TLDR**: We propose KnowMAN, an adversarial scheme that enables to control influence of signals associated with specific labeling functions.

- [ONION: A Simple and Effective Defense Against Textual Backdoor Attacks](https://aclanthology.org/2021.emnlp-main.752)
  - Fanchao Qi, Yangyi Chen, Mukai Li, Yuan Yao, Zhiyuan Liu, Maosong Sun
  - **TLDR**: We propose a simple and effective textual backdoor defense named ONION, which is based on outlier word detection and, to the best of our knowledge, is the first method that can handle all the textual backdoor attack situations.

- [Value-aware Approximate Attention](https://aclanthology.org/2021.emnlp-main.753)
  - Ankit Gupta, Jonathan Berant
  - **TLDR**: We propose a value-aware objective for attention sub-layer, and show that an optimal approximation of a value aware objective substantially outperforms an optimal approximate objective that ignores values, in the context of language modeling.

- [Contrastive Domain Adaptation for Question Answering using Limited Text Corpora](https://aclanthology.org/2021.emnlp-main.754)
  - Zhenrui Yue, Bernhard Kratzwald, Stefan Feuerriegel
  - **TLDR**: We propose a novel framework for domain adaptation for question answering that combines techniques from question generation and domain-invariant learning to answer out-of-domain questions in settings with limited text corpora.

- [Case-based Reasoning for Natural Language Queries over Knowledge Bases](https://aclanthology.org/2021.emnlp-main.755)
  - Rajarshi Das, Manzil Zaheer, Dung Thai, Ameya Godbole, Ethan Perez, Jay Yoon Lee, Lizhen Tan, Lazaros Polymenakos, Andrew McCallum
  - **TLDR**: We propose a neuro-symbolic CBR approach for question answering over large knowledge bases.

- [Distantly-Supervised Dense Retrieval Enables Open-Domain Question Answering without Evidence Annotation](https://aclanthology.org/2021.emnlp-main.756)
  - Chen Zhao, Chenyan Xiong, Jordan Boyd-Graber, Hal Daumé III
  - **TLDR**: We propose a novel approach to learn to find evidence from a large corpus by alternately finding evidence from the up-to-date model and encouraging the model to learn the most likely evidence.

- [What’s in a Name? Answer Equivalence For Open-Domain Question Answering](https://aclanthology.org/2021.emnlp-main.757)
  - Chenglei Si, Chen Zhao, Jordan Boyd-Graber
  - **TLDR**: We propose a method for mining alias entities from knowledge bases and using them as additional gold answers (i.e., equivalent answers) for QA evaluation and training.

- [Evaluation Paradigms in Question Answering](https://aclanthology.org/2021.emnlp-main.758)
  - Pedro Rodriguez, Jordan Boyd-Graber
  - **TLDR**: We identify two evaluation paradigms for question answering and show how they differ.

- [Numerical reasoning in machine reading comprehension tasks: are we there yet?](https://aclanthology.org/2021.emnlp-main.759)
  - Hadeel Al-Negheimish, Pranava Madhyastha, Alessandra Russo
  - **TLDR**: We present a controlled study on some of the top-performing model architectures for the task of numerical reasoning based machine reading comprehension.

- [Set Generation Networks for End-to-End Knowledge Base Population](https://aclanthology.org/2021.emnlp-main.760)
  - Dianbo Sui, Chenhao Wang, Yubo Chen, Kang Liu, Jun Zhao, Wei Bi
  - **TLDR**: We propose a new approach to solve end-to-end knowledge base population task by generating facts directly from unordered sentences.

- [Knowing False Negatives: An Adversarial Training Method for Distantly Supervised Relation Extraction](https://aclanthology.org/2021.emnlp-main.761)
  - Kailong Hao, Botao Yu, Wei Hu
  - **TLDR**: We propose a novel approach to address the false negative problem in relation extraction by leveraging the memory mechanism of deep neural networks.

- [Progressive Adversarial Learning for Bootstrapping: A Case Study on Entity Set Expansion](https://aclanthology.org/2021.emnlp-main.762)
  - Lingyong Yan, Xianpei Han, Le Sun
  - **TLDR**: We propose a new learning method for bootstrapping which jointly models the bootstrapped process and the boundary learning process in a GAN framework.

- [Uncovering Main Causalities for Long-tailed Information Extraction](https://aclanthology.org/2021.emnlp-main.763)
  - Guoshun Nan, Jiaqi Zeng, Rui Qiao, Zhijiang Guo, Wei Lu
  - **TLDR**: We propose counterfactual IE, a novel framework that aims to uncover the main causalities behind data in the view of causal inference.

- [Maximal Clique Based Non-Autoregressive Open Information Extraction](https://aclanthology.org/2021.emnlp-main.764)
  - Bowen Yu, Yucheng Wang, Tingwen Liu, Hongsong Zhu, Limin Sun, Bin Wang
  - **TLDR**: We propose MacroIE, a novel non-autoregressive framework for Open Information Extraction, which directly outputs the final set of facts in one go, thus getting rid of the burden of predicting fact order, as well as the error propagation between facts.

- [A Relation-Oriented Clustering Method for Open Relation Extraction](https://aclanthology.org/2021.emnlp-main.765)
  - Jun Zhao, Tao Gui, Qi Zhang, Yaqian Zhou
  - **TLDR**: We propose a relation-oriented clustering model for unsupervised relation discovery and show that it reduces the error rate by 29.2% and 15.7%, on two datasets respectively, compared with current SOTA methods.

- [Exploring Methods for Generating Feedback Comments for Writing Learning](https://aclanthology.org/2021.emnlp-main.766)
  - Kazuaki Hanawa, Ryo Nagata, Kentaro Inui
  - **TLDR**: We investigate three different architectures for comment generation and show that pointer-generator-based generation methods outperform neural-retrieval-based methods and retrieve-and-edit methods outperformed neural-seq2seq methods.

- [A Role-Selected Sharing Network for Joint Machine-Human Chatting Handoff and Service Satisfaction Analysis](https://aclanthology.org/2021.emnlp-main.767)
  - Jiawei Liu, Kaisong Song, Yangyang Kang, Guoxiu He, Zhuoren Jiang, Changlong Sun, Wei Lu, Xiaozhong Liu
  - **TLDR**: We propose a novel model, Role-Selected Sharing Network (RSSN), which integrates both dialogue satisfaction estimation and handoff prediction in one multi-task learning framework.

- [Meta Distant Transfer Learning for Pre-trained Language Models](https://aclanthology.org/2021.emnlp-main.768)
  - Chengyu Wang, Haojie Pan, Minghui Qiu, Jun Huang, Fei Yang, Yin Zhang
  - **TLDR**: Meta Distant Transfer Learning for Pre-trained Language Models.

- [UniKER: A Unified Framework for Combining Embedding and Definite Horn Rule Reasoning for Knowledge Graph Inference](https://aclanthology.org/2021.emnlp-main.769)
  - Kewei Cheng, Ziqing Yang, Ming Zhang, Yizhou Sun
  - **TLDR**: We propose a novel framework UniKER to address these challenges by restricting logical rules to be definite Horn rules, which can fully exploit the knowledge in logical rules and enable the mutual enhancement of logical rule-based reasoning and KGE in an extremely efficient way.

- [Wasserstein Selective Transfer Learning for Cross-domain Text Mining](https://aclanthology.org/2021.emnlp-main.770)
  - Lingyun Feng, Minghui Qiu, Yaliang Li, Haitao Zheng, Ying Shen
  - **TLDR**: We propose a Wasserstein-based method for transfer learning that improves the transfer learning of a data-scarce target domain by using information from source data and improves the performance of the target domain.

- [Jointly Learning to Repair Code and Generate Commit Message](https://aclanthology.org/2021.emnlp-main.771)
  - Jiaqi Bai, Long Zhou, Ambrosio Blanco, Shujie Liu, Furu Wei, Ming Zhou, Zhoujun Li
  - **TLDR**: We propose a novel task of jointly repairing program codes and generating commit messages.

- [Inflate and Shrink:Enriching and Reducing Interactions for Fast Text-Image Retrieval](https://aclanthology.org/2021.emnlp-main.772)
  - Haoliang Liu, Tan Yu, Ping Li
  - **TLDR**: We propose an inflating and shrinking approach to further boost the efficiency and accuracy of cross-interaction methods.

- [On Pursuit of Designing Multi-modal Transformer for Video Grounding](https://aclanthology.org/2021.emnlp-main.773)
  - Meng Cao, Long Chen, Mike Zheng Shou, Can Zhang, Yuexian Zou
  - **TLDR**: We propose a novel end-to-end multi-modal Transformer model for video grounding, which is capable of predicting the referential segment boundaries of untrimmed videos.

- [COVR: A Test-Bed for Visually Grounded Compositional Generalization with Real Images](https://aclanthology.org/2021.emnlp-main.774)
  - Ben Bogin, Shivanshu Gupta, Matt Gardner, Jonathan Berant
  - **TLDR**: We propose a new test-bed for visually-grounded compositional generalization with real images.

- [Vision-and-Language or Vision-for-Language? On Cross-Modal Influence in Multimodal Transformers](https://aclanthology.org/2021.emnlp-main.775)
  - Stella Frank, Emanuele Bugliarello, Desmond Elliott
  - **TLDR**: We propose a diagnostic method based on cross-modal input ablation to assess the extent to which these models actually integrate cross-Modal information.

- [HypMix: Hyperbolic Interpolative Data Augmentation](https://aclanthology.org/2021.emnlp-main.776)
  - Ramit Sawhney, Megh Thakkar, Shivam Agarwal, Di Jin, Diyi Yang, Lucie Flek
  - **TLDR**: We propose HypMix, a novel model-, data-, and modality-agnostic interpolative data augmentation technique operating in the hyperbolic space, which captures the complex geometry of input and hidden state hierarchies better than its contemporaries.

- [Integrating Deep Event-Level and Script-Level Information for Script Event Prediction](https://aclanthology.org/2021.emnlp-main.777)
  - Long Bai, Saiping Guan, Jiafeng Guo, Zixuan Li, Xiaolong Jin, Xueqi Cheng
  - **TLDR**: We propose a Transformer-based model, called MCPredictor, which integrates deep event-level and script-level information for script event prediction.

- [QA-Align: Representing Cross-Text Content Overlap by Aligning Question-Answer Propositions](https://aclanthology.org/2021.emnlp-main.778)
  - Daniela Brook Weiss, Paul Roit, Ayal Klein, Ori Ernst, Ido Dagan
  - **TLDR**: We propose to model redundant content overlap in multi-texts by using predicate-argument relations, providing a potential scaffold for information consolidation.

- [PICARD: Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models](https://aclanthology.org/2021.emnlp-main.779)
  - Torsten Scholak, Nathan Schucher, Dzmitry Bahdanau
  - **TLDR**: We propose PICARD, a method for constraining auto-regressive language models through incremental parsing.

- [Exploiting Twitter as Source of Large Corpora of Weakly Similar Pairs for Semantic Sentence Embeddings](https://aclanthology.org/2021.emnlp-main.780)
  - Marco Di Giovanni, Marco Brambilla
  - **TLDR**: We propose a language-independent approach to build large datasets of pairs of informal texts weakly similar, without manual human effort, exploiting Twitter's intrinsic powerful signals of relatedness: replies and quotes of tweets.

- [Guilt by Association: Emotion Intensities in Lexical Representations](https://aclanthology.org/2021.emnlp-main.781)
  - Shahab Raji, Gerard de Melo
  - **TLDR**: We explore the role of linguistic models in generating emotion intensity scores for specific emotions.

- [Using Sociolinguistic Variables to Reveal Changing Attitudes Towards Sexuality and Gender](https://aclanthology.org/2021.emnlp-main.782)
  - Sky CH-Wang, David Jurgens
  - **TLDR**: We study the role of language in changing attitudes towards sexuality and gender in the United States.

- [Identifying Morality Frames in Political Tweets using Relational Learning](https://aclanthology.org/2021.emnlp-main.783)
  - Shamik Roy, Maria Leonor Pacheco, Dan Goldwasser
  - **TLDR**: We propose a relational learning model to predict moral attitudes towards entities and moral foundations jointly.

- [Measuring Sentence-Level and Aspect-Level (Un)certainty in Science Communications](https://aclanthology.org/2021.emnlp-main.784)
  - Jiaxin Pei, David Jurgens
  - **TLDR**: We show that both the overall certainty and individual aspects of scientific findings can be predicted with pre-trained language models, providing a more complete picture of the author’s intended communication.

- [Assessing the Reliability of Word Embedding Gender Bias Measures](https://aclanthology.org/2021.emnlp-main.785)
  - Yupei Du, Qixiang Fang, Dong Nguyen
  - **TLDR**: We assess the reliability of word embedding gender bias measures and propose new measures for measuring gender bias.

- [Rumor Detection on Twitter with Claim-Guided Hierarchical Graph Attention Networks](https://aclanthology.org/2021.emnlp-main.786)
  - Hongzhan Lin, Jing Ma, Mingfei Cheng, Zhiwei Yang, Liangliang Chen, Guang Chen
  - **TLDR**: We present a new method for detecting rumors on Twitter by learning to infer the target claims from the interaction of user opinions.

- [Learning Bill Similarity with Annotated and Augmented Corpora of Bills](https://aclanthology.org/2021.emnlp-main.787)
  - Jiseon Kim, Elden Griggs, In Song Kim, Alice Oh
  - **TLDR**: We propose a 5-class classification task for bill generation that captures the similarities across legal documents at various levels of aggregation.

- [SWEAT: Scoring Polarization of Topics across Different Corpora](https://aclanthology.org/2021.emnlp-main.788)
  - Federico Bianchi, Marco Marelli, Paolo Nicoli, Matteo Palmonari
  - **TLDR**: We propose a novel statistical measure to measure the relative polarization of topical wordsets across two distributional representations.

- [“So You Think You’re Funny?”: Rating the Humour Quotient in Standup Comedy](https://aclanthology.org/2021.emnlp-main.789)
  - Anirudh Mittal, Pranav Jeevan P, Prerak Gandhi, Diptesh Kanojia, Pushpak Bhattacharyya
  - **TLDR**: We present a novel scoring mechanism to score the humour quotient of a multi-modal humour-annotated dataset using the audience's laughter.

- [“Was it “stated” or was it “claimed”?: How linguistic bias affects generative language models](https://aclanthology.org/2021.emnlp-main.790)
  - Roma Patel, Ellie Pavlick
  - **TLDR**: People use language in subtle and nuanced ways to convey their beliefs.

- [PAUSE: Positive and Annealed Unlabeled Sentence Embedding](https://aclanthology.org/2021.emnlp-main.791)
  - Lele Cao, Emil Larsson, Vilhelm von Ehrenheim, Dhiana Deva Cavalcanti Rocha, Anna Martin, Sonja Horn
  - **TLDR**: We propose a generic and end-to-end approach for sentence embedding that achieves state-of-the-art results using only a small fraction of labeled sentence pairs on various benchmark tasks.

- [A Simple Geometric Method for Cross-Lingual Linguistic Transformations with Pre-trained Autoencoders](https://aclanthology.org/2021.emnlp-main.792)
  - Maarten De Raedt, Fréderic Godin, Pieter Buteneers, Chris Develder, Thomas Demeester
  - **TLDR**: We propose a new method for transforming linguistic properties into vector representations without tuning sentence encoders or decoders.

- [An Information-Theoretic Characterization of Morphological Fusion](https://aclanthology.org/2021.emnlp-main.793)
  - Neil Rathi, Michael Hahn, Richard Futrell
  - **TLDR**: We present an information theoretic measure for the degree of fusion of a given set of morphological features in a surface form, which naturally provides such a graded scale.

- [The Effect of Efficient Messaging and Input Variability on Neural-Agent Iterated Language Learning](https://aclanthology.org/2021.emnlp-main.794)
  - Yuchen Lian, Arianna Bisazza, Tessa Verhoef
  - **TLDR**: We show that neural agents in language learning with neural network agents mainly strive to maintain the utterance type distribution observed during learning, instead of developing a more efficient or systematic language.

- [On Classifying whether Two Texts are on the Same Side of an Argument](https://aclanthology.org/2021.emnlp-main.795)
  - Erik Körner, Gregor Wiedemann, Ahmad Dawar Hakimi, Gerhard Heyer, Martin Potthast
  - **TLDR**: We present a transformer-based approach for same side stance classification, which is proposed to solve the task of argument stance classification.

- [Chinese Opinion Role Labeling with Corpus Translation: A Pivot Study](https://aclanthology.org/2021.emnlp-main.796)
  - Ranran Zhen, Rui Wang, Guohong Fu, Chengguo Lv, Meishan Zhang
  - **TLDR**: We present the first work of Chinese opinion role labeling and investigate the effectiveness of cross-lingual transfer methods.

- [MassiveSumm: a very large-scale, very multilingual, news summarisation dataset](https://aclanthology.org/2021.emnlp-main.797)
  - Daniel Varab, Natalie Schluter
  - **TLDR**: We present a large-scale multilingual summarisation dataset containing articles in 92 languages, spread across 28.8 million articles, in more than 35 writing scripts.

- [AUTOSUMM: Automatic Model Creation for Text Summarization](https://aclanthology.org/2021.emnlp-main.798)
  - Sharmila Reddy Nangi, Atharv Tyagi, Jay Mundra, Sagnik Mukherjee, Raj Snehal, Niyati Chhaya, Aparna Garimella
  - **TLDR**: We propose methods to automatically create deep learning models for text generation tasks using knowledge-based architecture search and compression.

- [Investigating the Helpfulness of Word-Level Quality Estimation for Post-Editing Machine Translation Output](https://aclanthology.org/2021.emnlp-main.799)
  - Raksha Shenoy, Nico Herbig, Antonio Krüger, Josef van Genabith
  - **TLDR**: We present a new analysis of word-level quality estimation in post-editing machine translation output and show that word-quality estimation is not yet good enough to support human translation.

- [UNKs Everywhere: Adapting Multilingual Language Models to New Scripts](https://aclanthology.org/2021.emnlp-main.800)
  - Jonas Pfeiffer, Ivan Vulić, Iryna Gurevych, Sebastian Ruder
  - **TLDR**: We propose a series of novel data-efficient methods for adapting multilingual BERT models to languages with unseen scripts.

- [Neural Machine Translation Quality and Post-Editing Performance](https://aclanthology.org/2021.emnlp-main.801)
  - Vilém Zouhar, Martin Popel, Ondřej Bojar, Aleš Tamchyna
  - **TLDR**: We test the natural expectation that using neural MT in professional translation saves human processing time and quality.

- [XTREME-R: Towards More Challenging and Nuanced Multilingual Evaluation](https://aclanthology.org/2021.emnlp-main.802)
  - Sebastian Ruder, Noah Constant, Jan Botha, Aditya Siddhant, Orhan Firat, Jinlan Fu, Pengfei Liu, Junjie Hu, Dan Garrette, Graham Neubig, Melvin Johnson
  - **TLDR**: We present a new multilingual cross-lingual transfer learning benchmark and a new diagnostic suite for machine learning models.

- [Contrastive Conditioning for Assessing Disambiguation in MT: A Case Study of Distilled Bias](https://aclanthology.org/2021.emnlp-main.803)
  - Jannis Vamvas, Rico Sennrich
  - **TLDR**: We propose contrastive conditioning as a reference-free black-box method for detecting disambiguation errors in translation systems.

- [Measuring Association Between Labels and Free-Text Rationales](https://aclanthology.org/2021.emnlp-main.804)
  - Sarah Wiegreffe, Ana Marasović, Noah A. Smith
  - **TLDR**: We investigate the extent to which the labels and rationales predicted by these models are associated, a necessary property of faithful explanation.

- [Discretized Integrated Gradients for Explaining Language Models](https://aclanthology.org/2021.emnlp-main.805)
  - Soumya Sanyal, Xiang Ren
  - **TLDR**: We propose Discretized Integrated Gradients, a novel attribution-based explanation algorithm that allows effective attribution along non-linear interpolation paths.

- [Putting Words in BERT’s Mouth: Navigating Contextualized Vector Spaces with Pseudowords](https://aclanthology.org/2021.emnlp-main.806)
  - Taelin Karidi, Yichu Zhou, Nathan Schneider, Omri Abend, Vivek Srikumar
  - **TLDR**: We present a method for exploring regions around individual points in a contextualized vector space (particularly, BERT space), as a way to investigate how these regions correspond to word senses.

- [Rationales for Sequential Predictions](https://aclanthology.org/2021.emnlp-main.807)
  - Keyon Vafa, Yuntian Deng, David Blei, Alexander Rush
  - **TLDR**: We propose a combinatorial algorithm for finding sequential rationales that can explain individual model predictions.

- [FastIF: Scalable Influence Functions for Efficient Model Interpretation and Debugging](https://aclanthology.org/2021.emnlp-main.808)
  - Han Guo, Nazneen Rajani, Peter Hase, Mohit Bansal, Caiming Xiong
  - **TLDR**: We present FastIF, a set of simple modifications to influence functions that significantly improves their run-time and improve model accuracy.

- [Studying word order through iterative shuffling](https://aclanthology.org/2021.emnlp-main.809)
  - Nikolay Malkin, Sameera Lanka, Pranav Goel, Nebojsa Jojic
  - **TLDR**: We show that word order is not encoded in the syntax of neural language models and show that shuffling inference procedures can improve word order in many cases.

- [Distantly-Supervised Named Entity Recognition with Noise-Robust Learning and Language Model Augmented Self-Training](https://aclanthology.org/2021.emnlp-main.810)
  - Yu Meng, Yunyi Zhang, Jiaxin Huang, Xuan Wang, Yu Zhang, Heng Ji, Jiawei Han
  - **TLDR**: We propose a novel noise-robust learning scheme for named entity recognition using only distantly-labeled data, and a self-training method that uses contextualized augmentations created by pre-trained language models to improve the generalization ability of the NER model.

- [Open Knowledge Graphs Canonicalization using Variational Autoencoders](https://aclanthology.org/2021.emnlp-main.811)
  - Sarthak Dash, Gaetano Rossiello, Nandana Mihindukulasooriya, Sugato Bagchi, Alfio Gliozzo
  - **TLDR**: We propose Canonicalizing Using Variational AutoEncoders and Side Information (CUVA), a joint model to learn both embeddings and cluster assignments in an end-to-end approach, which leads to a better vector representation for the noun and relation phrases.

- [HittER: Hierarchical Transformers for Knowledge Graph Embeddings](https://aclanthology.org/2021.emnlp-main.812)
  - Sanxing Chen, Xiaodong Liu, Jianfeng Gao, Jian Jiao, Ruofei Zhang, Yangfeng Ji
  - **TLDR**: We propose HittER, a Hierarchical Transformer model to jointly learn Entity-relation composition and Relational contextualization based on a source entity's neighborhood.

- [Few-Shot Named Entity Recognition: An Empirical Baseline Study](https://aclanthology.org/2021.emnlp-main.813)
  - Jiaxin Huang, Chunyuan Li, Krishan Subudhi, Damien Jose, Shobana Balakrishnan, Weizhu Chen, Baolin Peng, Jianfeng Gao, Jiawei Han
  - **TLDR**: We present a new method for building named entity recognition systems when there is a limited amount of labeled data available.

- [XLEnt: Mining a Large Cross-lingual Entity Dataset with Lexical-Semantic-Phonetic Word Alignment](https://aclanthology.org/2021.emnlp-main.814)
  - Ahmed El-Kishky, Adithya Renduchintala, James Cross, Francisco Guzmán, Philipp Koehn
  - **TLDR**: We propose Lexical-Semantic-Phonetic Align, a technique to automatically mine cross-lingual entity lexica from mined web data.

- [Utilizing Relative Event Time to Enhance Event-Event Temporal Relation Extraction](https://aclanthology.org/2021.emnlp-main.815)
  - Haoyang Wen, Heng Ji
  - **TLDR**: We propose a new model for event-event temporal relation extraction and an auxiliary task, relative event time prediction, which predicts the event time as real numbers.

- [Separating Retention from Extraction in the Evaluation of End-to-end Relation Extraction](https://aclanthology.org/2021.emnlp-main.816)
  - Bruno Taillé, Vincent Guigue, Geoffrey Scoutheeten, Patrick Gallinari
  - **TLDR**: We propose two experiments confirming that retention of known facts is a key factor of performance on standard benchmarks.

- [Automatic Text Evaluation through the Lens of Wasserstein Barycenters](https://aclanthology.org/2021.emnlp-main.817)
  - Pierre Colombo, Guillaume Staerman, Chloé Clavel, Pablo Piantanida
  - **TLDR**: A new metric BaryScore to evaluate text generation based on deep contextualized embeddings (

- [Visually Grounded Reasoning across Languages and Cultures](https://aclanthology.org/2021.emnlp-main.818)
  - Fangyu Liu, Emanuele Bugliarello, Edoardo Maria Ponti, Siva Reddy, Nigel Collier, Desmond Elliott
  - **TLDR**: We present a new protocol for multilingual reasoning over vision and language that uses native speaker annotations to construct a new multilingual dataset and a new multi-lingual dataset for cross-linguistic reasoning over visual and language transfer.

- [Back to Square One: Artifact Detection, Training and Commonsense Disentanglement in the Winograd Schema](https://aclanthology.org/2021.emnlp-main.819)
  - Yanai Elazar, Hongming Zhang, Yoav Goldberg, Dan Roth
  - **TLDR**: We propose a new evaluation method for evaluating commonsense reasoning in language models and show that the observed improvement in WS is mostly due to the use of supervision in training WS models.

- [Robustness Evaluation of Entity Disambiguation Using Prior Probes: the Case of Entity Overshadowing](https://aclanthology.org/2021.emnlp-main.820)
  - Vera Provatorova, Samarth Bhargav, Svitlana Vakulenko, Evangelos Kanoulas
  - **TLDR**: We present a new benchmark for entity disambiguation and show that prior probability bias and overshadowing can significantly affect the accuracy of EL systems.

- [IndoNLI: A Natural Language Inference Dataset for Indonesian](https://aclanthology.org/2021.emnlp-main.821)
  - Rahmad Mahendra, Alham Fikri Aji, Samuel Louvan, Fahrurrozi Rahman, Clara Vania
  - **TLDR**: We present IndoNLI, the first human-elicited NLI dataset for Indonesian.

- [Agreeing to Disagree: Annotating Offensive Language Datasets with Annotators’ Disagreement](https://aclanthology.org/2021.emnlp-main.822)
  - Elisa Leonardelli, Stefano Menini, Alessio Palmero Aprosio, Marco Guerini, Sara Tonelli
  - **TLDR**: We present a new study on the impact of different levels of agreement among annotators on offensive language detection and propose a new way to train more robust and accurate classifiers.

- [A Root of a Problem: Optimizing Single-Root Dependency Parsing](https://aclanthology.org/2021.emnlp-main.823)
  - Miloš Stanojević, Shay B. Cohen
  - **TLDR**: We describe two approaches to single-root dependency parsing that yield significant speed ups in such parsing.

- [Efficient Sampling of Dependency Structure](https://aclanthology.org/2021.emnlp-main.824)
  - Ran Zmigrod, Tim Vieira, Ryan Cotterell
  - **TLDR**: We present a novel algorithm for sampling spanning trees in directed graphs without replacement.

- [Reducing Discontinuous to Continuous Parsing with Pointer Network Reordering](https://aclanthology.org/2021.emnlp-main.825)
  - Daniel Fernández-González, Carlos Gómez-Rodríguez
  - **TLDR**: We propose to reduce discontinuous parsing to a continuous problem, which can then be directly solved by any off-the-shelf continuous parser.

- [A New Representation for Span-based CCG Parsing](https://aclanthology.org/2021.emnlp-main.826)
  - Yoshihide Kato, Shigeki Matsubara
  - **TLDR**: We propose a new representation for CCG derivations that prevents span-based parsing models from violating the rule schemata.

- [What to Pre-Train on? Efficient Intermediate Task Selection](https://aclanthology.org/2021.emnlp-main.827)
  - Clifton Poth, Jonas Pfeiffer, Andreas Rücklé, Iryna Gurevych
  - **TLDR**: We provide a comprehensive comparison of different methods for efficiently identifying beneficial tasks for intermediate transfer learning.

- [PermuteFormer: Efficient Relative Position Encoding for Long Sequences](https://aclanthology.org/2021.emnlp-main.828)
  - Peng Chen
  - **TLDR**: We propose PermuteFormer, a Performer-based model with relative position encoding that scales linearly on long sequences.

- [Block Pruning For Faster Transformers](https://aclanthology.org/2021.emnlp-main.829)
  - François Lagunas, Ella Charlaix, Victor Sanh, Alexander Rush
  - **TLDR**: We propose a new block pruning approach for pre-training that learns to prune out full components of the underlying model, such as attention heads.

- [Finetuning Pretrained Transformers into RNNs](https://aclanthology.org/2021.emnlp-main.830)
  - Jungo Kasai, Hao Peng, Yizhe Zhang, Dani Yogatama, Gabriel Ilharco, Nikolaos Pappas, Yi Mao, Weizhu Chen, Noah A. Smith
  - **TLDR**: We propose a new method to convert a pretrained transformer into its efficient recurrent counterpart, improving efficiency while maintaining accuracy.

- [How to Train BERT with an Academic Budget](https://aclanthology.org/2021.emnlp-main.831)
  - Peter Izsak, Moshe Berchansky, Omer Levy
  - **TLDR**: We present a recipe for pretraining a masked language model in 24 hours using a single low-end deep learning server.

- [Beyond Preserved Accuracy: Evaluating Loyalty and Robustness of BERT Compression](https://aclanthology.org/2021.emnlp-main.832)
  - Canwen Xu, Wangchunshu Zhou, Tao Ge, Ke Xu, Julian McAuley, Furu Wei
  - **TLDR**: We propose label loyalty and probability loyalty metrics for evaluating the effect of compression on training language models.

- [IndoBERTweet: A Pretrained Language Model for Indonesian Twitter with Effective Domain-Specific Vocabulary Initialization](https://aclanthology.org/2021.emnlp-main.833)
  - Fajri Koto, Jey Han Lau, Timothy Baldwin
  - **TLDR**: We present IndoBERTweet, the first large-scale pretrained model for Indonesian Twitter that is trained by extending a monolingually-trained Indonesian BERT model with additive domain-specific vocabulary.

- [Pushing on Text Readability Assessment: A Transformer Meets Handcrafted Linguistic Features](https://aclanthology.org/2021.emnlp-main.834)
  - Bruce W. Lee, Yoo Sung Jang, Jason Lee
  - **TLDR**: We present novel features in advanced semantics and novel transformers for readability assessment.

- [Types of Out-of-Distribution Texts and How to Detect Them](https://aclanthology.org/2021.emnlp-main.835)
  - Udit Arora, William Huang, He He
  - **TLDR**: We show that the two major approaches to OOD detection, calibration and density estimation, have distinct behavior on these types of OOD data.

- [Self-training with Few-shot Rationalization](https://aclanthology.org/2021.emnlp-main.836)
  - Meghana Moorthy Bhat, Alessandro Sordoni, Subhabrata Mukherjee
  - **TLDR**: We develop a multi-task teacher-student framework based on self-training pre-trained language models with limited task-specific labels and rationales and judicious sample selection to learn from informative pseudo-labeled examples.

- [MTAdam: Automatic Balancing of Multiple Training Loss Terms](https://aclanthology.org/2021.emnlp-main.837)
  - Itzik Malkiel, Lior Wolf
  - **TLDR**: We generalize the Adam optimization algorithm to handle multiple loss terms and show that training with the new method leads to fast recovery from suboptimal initial loss weighting and to training outcomes that match or improve conventional training with hyperparameters of each method.

- [Softmax Tree: An Accurate, Fast Classifier When the Number of Classes Is Large](https://aclanthology.org/2021.emnlp-main.838)
  - Arman Zharmagambetov, Magzhan Gabidolla, Miguel A. Carreira-Perpinan
  - **TLDR**: We propose a new classifier for NLP problems with thousands of classes, which is faster than a softmax and more accurate than other classifiers.

- [Improving Distantly-Supervised Named Entity Recognition with Self-Collaborative Denoising Learning](https://aclanthology.org/2021.emnlp-main.839)
  - Xinghua Zhang, Bowen Yu, Tingwen Liu, Zhenyu Zhang, Jiawei Sheng, Xue Mengge, Hongbo Xu
  - **TLDR**: We propose a robust learning paradigm for learning noisy label refinery by learning two teacher-student networks in a mutually-beneficial manner to iteratively perform noisy label refining.

- [Multivalent Entailment Graphs for Question Answering](https://aclanthology.org/2021.emnlp-main.840)
  - Nick McKenna, Liane Guillou, Mohammad Javad Hosseini, Sander Bijl de Vroe, Mark Johnson, Mark Steedman
  - **TLDR**: We propose a new theory for entailment between open-domain natural language predicates and show that directional entailment is more helpful for inference than non-directional similarity on questions of fine-grained semantics.

- [Is Everything in Order? A Simple Way to Order Sentences](https://aclanthology.org/2021.emnlp-main.841)
  - Somnath Basu Roy Chowdhury, Faeze Brahman, Snigdha Chaturvedi
  - **TLDR**: We present Reorder-BART, a Transformer-based sentence order generator that achieves state-of-the-art performance across 7 datasets in Perfect Match Ratio, Perfect Match ratio, Kendall's tau, and Kendall's Tau.

- [VeeAlign: Multifaceted Context Representation Using Dual Attention for Ontology Alignment](https://aclanthology.org/2021.emnlp-main.842)
  - Vivek Iyer, Arvind Agarwal, Harshit Kumar
  - **TLDR**: We propose VeeAlign, a Deep Learning based model that uses a novel dual-attention mechanism to compute the contextualized representation of a concept which, in turn, is used to discover alignments.

- [Finding needles in a haystack: Sampling Structurally-diverse Training Sets from Synthetic Data for Compositional Generalization](https://aclanthology.org/2021.emnlp-main.843)
  - Inbar Oren, Jonathan Herzig, Jonathan Berant
  - **TLDR**: We propose a novel approach to improve compositional generalization in semantic parsing by generating synthetic utterance-program pairs that are structurally diverse.

- [GeneSis: A Generative Approach to Substitutes in Context](https://aclanthology.org/2021.emnlp-main.844)
  - Caterina Lacerra, Rocco Tripodi, Roberto Navigli
  - **TLDR**: We present a novel approach to lexical substitution that uses seq2seq to generate substitutes for a target word in context, attaining state-of-the-art results on different benchmarks.

- [Semi-Supervised Exaggeration Detection of Health Science Press Releases](https://aclanthology.org/2021.emnlp-main.845)
  - Dustin Wright, Isabelle Augenstein
  - **TLDR**: We present a formalization of and study into the problem of exaggeration detection in science communication.

- [Phrase-BERT: Improved Phrase Embeddings from BERT with an Application to Corpus Exploration](https://aclanthology.org/2021.emnlp-main.846)
  - Shufan Wang, Laure Thompson, Mohit Iyyer
  - **TLDR**: We propose a new phrase embedding objective that enables BERT to produce more powerful phrase embeddings.

- [Detecting Contact-Induced Semantic Shifts: What Can Embedding-Based Methods Do in Practice?](https://aclanthology.org/2021.emnlp-main.847)
  - Filip Miletic, Anne Przewozny-Desriaux, Ludovic Tanguy
  - **TLDR**: We present a new 80-item test set for semantic change detection in Quebec English and show that the methods can be applied to contact-induced semantic shifts observed in synchrony.
