---
title: matryoshka embeddings?
updated: 2025-11-20
---

# what is this

this is a working note where i write down some stuff i explored regarding matryoshka embeddings.
it's mostly random stuff, if you find errors or something unclear, feel free to reach out.


# notes

## training pairs of mrl and non-mrl encoders

there are many mrl models but there are not many pairs of models that are trained from the same plm but one with standard way and another with mrl.
this makes fair analysis difficult, so i started to train small encoders in this setup.
hopefully, i can test questions listed below using these models.

the code i used to train models is [here](https://github.com/sobamchan/mrl_train/) and i am putting trained models [here](https://huggingface.co/collections/sobamchan/mrl).


## questions

some questions i have regarding mrl encoders.
i am first training models.

### do we lose something if we train with mrl?

mrl is simple enough so the implementation is simple and not so much of compute overhead.
but does it really come for free?

### differences in geometric properties of embeddings

what happens to embeddings as vectors if we do mrl?
i want to measure isotropy, dimensional collapse, outlier dimensions, intrinsic dimensions in embeddings produced by mrl encoders.

### differences in training dynamics

are there differences during training, non-mrl vs mrl?

### differences in model weights

are models (non-mrl, mrl) different if we see their weights? can we use [model diffing](https://transformer-circuits.pub/2024/model-diffing/) to see this?


# papers

- [\[2205.13147\] Matryoshka Representation Learning](https://arxiv.org/abs/2205.13147)
- [SMEC:Rethinking Matryoshka Representation Learning for Retrieval Embedding Compression - ACL Anthology](https://aclanthology.org/2025.emnlp-main.1332/)
- [\[2402.14776\] 2D Matryoshka Sentence Embeddings](https://arxiv.org/abs/2402.14776)
- [\[2410.13230\] Starbucks-v2: Improved Training for 2D Matryoshka Embeddings](https://arxiv.org/abs/2410.13230)
